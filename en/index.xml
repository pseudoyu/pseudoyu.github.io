<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:webfeeds="http://webfeeds.org/rss/1.0">
  <channel>
    <title>Pseudoyu</title>
    <link>https://www.pseudoyu.com/en/</link>
    <description>Recent content on Pseudoyu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 28 Mar 2021 16:30:17 +0800</lastBuildDate>
    
    <atom:link href="https://www.pseudoyu.com/en/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://www.pseudoyu.com/en/about/</link>
      <pubDate>Thu, 04 Mar 2021 16:03:46 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/about/</guid>
      
        <description>&lt;h2 id=&#34;hi-i-am-yu-zhanghttpswwwpseudoyucom&#34;&gt;Hi, I am &lt;a href=&#34;https://www.pseudoyu.com&#34;&gt;Yu Zhang&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am currently studying my master degree in Department of Computer Science @ The University of Hong Kong (HKU).&lt;/p&gt;
&lt;p&gt;I want to learn things and become a better person. I enjoy reading, thinking and writing in my leisure time.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/dino.gif&#34; alt=&#34;picture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;my-goals&#34;&gt;My Goals&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About my life&lt;/strong&gt;&lt;/em&gt;, I hope I can establish a life-long friendship with my best friends, keep close relationship with my families, and face future challenges with my beloved. Also, I hope to meet interesting friends of diverse background.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About my career&lt;/strong&gt;&lt;/em&gt;, I hope I could always be learning and growing during my life and play an active role in the open source software movement.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Economically&lt;/strong&gt;&lt;/em&gt;, I hope to be able to choose what to do and shape my own the lifestyle freely.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;About the society&lt;/strong&gt;&lt;/em&gt;, I hope to have the opportunity to participate in some public welfare or other form of kindness to contribute to the world.&lt;/p&gt;
&lt;h2 id=&#34;about-pseudoyu&#34;&gt;About Pseudoyu&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; is my first website. I mainly write about my daily life, study and thoughts here. This blog was initially created on my personal web server using WordPress, and I moved to WeChat Official Account (the same name). Due to the consideration of stability and customization need, I decided to build a new site on GitHub Page with the domain name &lt;a href=&#34;https://www.pseudoyu.com/en&#34;&gt;pseudoyu.com&lt;/a&gt; and use a static site generator (Hugo) to generate the content.&lt;/p&gt;
&lt;p&gt;I named &lt;strong&gt;Pseudoyu&lt;/strong&gt; as my blog name quite by chance. I&amp;rsquo;m stuck for the choice of my HKU uid because my name is really common(but I still want a special one for my further use). Inspired by Rachel, I found a prefix &lt;a href=&#34;https://www.oxfordlearnersdictionaries.com/definition/english/pseudo&#34;&gt;&lt;em&gt;pseudo&lt;/em&gt;&lt;/a&gt;, the word &lt;a href=&#34;https://www.oxfordlearnersdictionaries.com/definition/english/pseudonym&#34;&gt;pseudonym&lt;/a&gt; means a name that is not real, the item &lt;a href=&#34;https://www.lexico.com/definition/pseudocode&#34;&gt;pseudocode&lt;/a&gt; means a notation resembling a simplified programming language in Computer Science world. And one of my favorite cartoons &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%81%BD%E7%89%A9%E8%AA%9E&#34;&gt;&lt;em&gt;Nisemonogatari&lt;/em&gt;&lt;/a&gt; also focuses on the concept of &lt;em&gt;&lt;strong&gt;pseudo&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;real&lt;/strong&gt;&lt;/em&gt;. So, why there can&amp;rsquo;t be a pseudo - yu (me)?&lt;/p&gt;
&lt;p&gt;I always fall into self-doubt. Whenever I&amp;rsquo;m talking with my best friend, if the topics are about &lt;em&gt;initials&lt;/em&gt; or &lt;em&gt;meanings&lt;/em&gt;, I&amp;rsquo;ll choose to escape. It&amp;rsquo;s difficult for me to feel the simple joy or satisfaction emotions even if I made some achievements and praised by others. I used to regard everything in my life is meaningless. As time goes by, I begin to understand more about it. I wrote a paragh in my another article &lt;a href=&#34;https://www.pseudoyu.com/en/2020/06/06/23%E5%B2%81%E7%9A%84%E8%87%AA%E7%99%BD%E5%8E%BB%E8%BF%BD%E5%AF%BB%E6%84%8F%E4%B9%89/&#34;&gt;&lt;em&gt;Dear Yu, Are you ready for 23?&lt;/em&gt;&lt;/a&gt;, &lt;em&gt;&lt;strong&gt;&amp;ldquo;Perhaps, thinking about meaning itself is also a process of constructing meanings. I decide to give up the previous illusion of an &amp;lsquo;Aha moment&amp;rsquo; and just continue moving forward to experience my own life.&amp;quot;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The name &lt;strong&gt;Pseudoyu&lt;/strong&gt; also tells myself that I should never constantly struggle with what meaning is anymore. Instead, I will continue to learn, experience and challenge new things. And I can finally accept other&amp;rsquo;s judgement or complain about me like &amp;ldquo;&lt;strong&gt;You changed&lt;/strong&gt;&amp;rdquo; with pressure.&lt;/p&gt;
&lt;p&gt;I hope I can acquire more inputs like new knowledge and ideas, and write more short articles as outputs.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS文件存储模式详解</title>
      <link>https://www.pseudoyu.com/en/2021/03/28/blockchain_note_ipfs_model/</link>
      <pubDate>Sun, 28 Mar 2021 16:30:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/03/28/blockchain_note_ipfs_model/</guid>
      
        <description>&lt;h2 id=&#34;ipfs文件存储模式详解&#34;&gt;IPFS文件存储模式详解&lt;/h2&gt;
&lt;h3 id=&#34;cid-content-id&#34;&gt;CID (Content-ID)&lt;/h3&gt;
&lt;p&gt;CID是类似IPFS分布式文件系统中标准的文件寻址格式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内容寻址&lt;/li&gt;
&lt;li&gt;加密散列算法&lt;/li&gt;
&lt;li&gt;自我描述&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;目前在IPFS用base58btc对multihashes进行编码，在开发IPLD（InterPlanetary Linked Data，内容可寻址的数据模型，主要用来定义数据，给数据建模）过程中遇到了很多与数据格式相关的棘手问题，CID的出现让管理不同格式的数据成为了可能。&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;描述&#34;&gt;描述&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;CID是一种自描述式的内容寻址的识别符，必须使用加密散列函数来得到内容的地址&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;使用了很多multiformats实现灵活的自描述&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用multihash得到哈希值&lt;/li&gt;
&lt;li&gt;multicodec-packed用于描述内容类型，类似于文件后缀，表示数据的格式，但其是数据标识符的一部分，用户不能随意修改，且支持的格式有限
&lt;ul&gt;
&lt;li&gt;原生protobuf格式&lt;/li&gt;
&lt;li&gt;IPLD CBOR格式&lt;/li&gt;
&lt;li&gt;git&lt;/li&gt;
&lt;li&gt;比特币对象&lt;/li&gt;
&lt;li&gt;以太坊对象&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;multibase将CID本身编码成字符串&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;特点&#34;&gt;特点&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;压缩：CID二进制的特性使其压缩效率非常高，可作为URL的一部分&lt;/li&gt;
&lt;li&gt;传输友好：以multibase编码来方便传输，如以base58btc编码的CID将长度缩短&lt;/li&gt;
&lt;li&gt;多变：CID可以表示任意格式，任何哈希函数的结果&lt;/li&gt;
&lt;li&gt;避免内容锁：防止受限于历史内容&lt;/li&gt;
&lt;li&gt;可升级：CID的编码版本可升级&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;版本&#34;&gt;版本&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;v0版本的CID由V0Builder生成，以Qm字符串开头，向后兼容&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;multibase&lt;/code&gt;一直为base58btc&lt;/li&gt;
&lt;li&gt;&lt;code&gt;multicodec&lt;/code&gt;一直为protobuf-mdag&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cid-version&lt;/code&gt;一直为cidv0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;multihash&lt;/code&gt;表示为&lt;code&gt;cidv0 ::= &amp;lt;multihash-content-address&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;v1版本的CID由V1Builder生成&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Codec：表示内容的编码类型，如DagProtobuf, DagCBOR等&lt;/li&gt;
&lt;li&gt;MhType：哈希算法，如SHA2_256, SHA2_512, SHA3_256, SHA3_512等&lt;/li&gt;
&lt;li&gt;MhLength：生成哈希的长度&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Cid&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;str&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;V0Builder&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;V1Builder&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;Codec&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;MhType&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;MhLength&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Default: -1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;cidv1&amp;gt; ::= &amp;lt;mb&amp;gt;&amp;lt;version&amp;gt;&amp;lt;mcp&amp;gt;&amp;lt;mh&amp;gt;
# or, expanded:
&amp;lt;cidv1&amp;gt; ::= &amp;lt;multibase-prefix&amp;gt;&amp;lt;cid-version&amp;gt;&amp;lt;multicodec-packed-content-type&amp;gt;&amp;lt;multihash-content-address&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;multibase-prefix&amp;gt;&lt;/code&gt;是一个multibase编码（1-2字节），便于将CID编码成不同的格式&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;cid-version&amp;gt;&lt;/code&gt;是一个表示CID版本的变量，便于以后升级&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;multicodec-packed-content-type&amp;gt;&lt;/code&gt;是一种用multicodec-packed编码表示内容的类型/数据的格式&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;multihash-content-address&amp;gt;&lt;/code&gt;是一个multihash值，表示了内容的加密哈希值，让CID可以使用不同的加密哈希散列函数&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ipfs文件存储&#34;&gt;IPFS文件存储&lt;/h3&gt;
&lt;h4 id=&#34;存储步骤&#34;&gt;存储步骤&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;把单个文件拆分成若干个256KB的block
&lt;ul&gt;
&lt;li&gt;小文件（小于1KB）会直接和Hash一起上传至IPFS，不会额外占用一个block大小&lt;/li&gt;
&lt;li&gt;对大文件进行数据追加，如果新增了一个1KB文件，未变化的大文件内容部分并不会分配新的空间，只会为追加部分分配一个新block，再重新上传Hash&lt;/li&gt;
&lt;li&gt;即使是不同文件的相同部分也只会存储一份，很多文件的索引会指向同一个block，构成MerkleDAG数据结构&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;逐个block计算块block哈希值&lt;/li&gt;
&lt;li&gt;将所有的blockhash值合成一个数组，计算得到最终文件Hash&lt;/li&gt;
&lt;li&gt;将文件Hash和blockhash数组组合称为一个对象，形成索引结构&lt;/li&gt;
&lt;li&gt;把block、索引结构全部上传至IPFS节点，文件同步至IPFS网络&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;存储结构&#34;&gt;存储结构&lt;/h4&gt;
&lt;p&gt;IPFS采用的索引结构是DHT（分布式哈希表）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_dht.png&#34; alt=&#34;ipfs_dht&#34;&gt;&lt;/p&gt;
&lt;p&gt;数据结构是MerkleDAG（Merkle有向无环图）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内容寻址
&lt;ul&gt;
&lt;li&gt;使用多重哈希来唯一识别一个数据块的内容&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;防篡改
&lt;ul&gt;
&lt;li&gt;可以方便的检查哈希值来确认数据是否被篡改，如果数据被篡改或损坏，IPFS会检测到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;去重
&lt;ul&gt;
&lt;li&gt;由于内容相同的数据块哈希是相同的，可以很容去掉重复的数据，节省存储空间&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ipfs组件&#34;&gt;IPFS组件&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_components.png&#34; alt=&#34;ipfs_components&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pining
&lt;ul&gt;
&lt;li&gt;负责固定文件和文件块的CID，Pin添加到块不会被GC&lt;/li&gt;
&lt;li&gt;上传文件最后的文件CID都会被Pin，防止被GC&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Blockstore
&lt;ul&gt;
&lt;li&gt;GCBlockstore类型&lt;/li&gt;
&lt;li&gt;组合Blockstore和GCLocker两个组件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BaseBlocks
&lt;ul&gt;
&lt;li&gt;原始Blockstore&lt;/li&gt;
&lt;li&gt;提供对Block的Get/Put/Has/DeleteBlock等操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GCLocker
&lt;ul&gt;
&lt;li&gt;锁住Blockstore，防止GC&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Blocks
&lt;ul&gt;
&lt;li&gt;提供Block服务&lt;/li&gt;
&lt;li&gt;组合Blockstore组件&lt;/li&gt;
&lt;li&gt;提供GetBlock/GetBlocks, AddBlock/AddBlocks, DeleteBlock操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DAG
&lt;ul&gt;
&lt;li&gt;IPFS的MerkleDAG服务&lt;/li&gt;
&lt;li&gt;组合BlockService组件，提供Get/GetMany, Add/AddMany, Remove/RemoveMany等操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ipfs目录结构&#34;&gt;IPFS目录结构&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;.
├── api
├── blocks
│   ├── 2G
│   ├── 2I
│   ├── 2J
│   ├── ...
│   ├── SD
│   ├── SHARDING
│   ├── SP
│   ├── SU
│   ├── SX
│   ├── ...
│   ├── ZZ
│   ├── _README
│   └── diskUsage.cache
├── config
├── datastore
│   ├── 000045.ldb
│   ├── 000050.ldb
│   ├── 000051.log
│   ├── CURRENT
│   ├── CURRENT.bak
│   ├── LOCK
│   ├── LOG
│   └── MANIFEST-000052
├── datastore_spec
├── keystore
├── repo.lock
└── version
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;blocks为文件存储的目录&lt;/li&gt;
&lt;li&gt;datastore为leveldb的数据库，存储了文件系统的根哈希等&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据对象格式&#34;&gt;数据对象格式&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;IPFSObject&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;links&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;IPFSLink&lt;/span&gt;      &lt;span class=&#34;c1&#34;&gt;// link数组
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;           &lt;span class=&#34;c1&#34;&gt;// 数据内容
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;IPFSLink&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;           &lt;span class=&#34;c1&#34;&gt;// link的名字
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;Hash&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Multihash&lt;/span&gt;        &lt;span class=&#34;c1&#34;&gt;// 数据的加密哈希值
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;Size&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;              &lt;span class=&#34;c1&#34;&gt;// 数据大小
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;特点-1&#34;&gt;特点&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;存储格式为MerkleDAG&lt;/li&gt;
&lt;li&gt;每一层Links大小为174个，超过了则会重新调整&lt;/li&gt;
&lt;li&gt;存储过程中有多个Datastore进行组合与封装，每个Datastore功能单一
&lt;ul&gt;
&lt;li&gt;各个组件功能明确
&lt;ul&gt;
&lt;li&gt;arccache：Block缓存&lt;/li&gt;
&lt;li&gt;VerifBS：CID校验&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;调用深度比较深，内部都用interface，不便于阅读&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ipfs存储应用场景&#34;&gt;IPFS存储应用场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;互联网内容分发&lt;/li&gt;
&lt;li&gt;企业分布式存储服务
&lt;ul&gt;
&lt;li&gt;容易进行存储的动态扩容&lt;/li&gt;
&lt;li&gt;结合节点认证机制和DHT查找内容的剥离&lt;/li&gt;
&lt;li&gt;配合区块链技术，通过链上链下协同技术，很容易解决存储容量不足的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS分布式文件存储入门</title>
      <link>https://www.pseudoyu.com/en/2021/03/25/blockchain_note_ipfs/</link>
      <pubDate>Thu, 25 Mar 2021 18:46:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/03/25/blockchain_note_ipfs/</guid>
      
        <description>&lt;h2 id=&#34;ipfs分布式文件存储入门&#34;&gt;IPFS分布式文件存储入门&lt;/h2&gt;
&lt;h3 id=&#34;ipfs简介&#34;&gt;IPFS简介&lt;/h3&gt;
&lt;p&gt;IPFS (InterPlanetary File System) 星际文件系统，是一个面向全球的、点对点的分布式文件存储系统，目标是为了补充（甚至是取代）目前统治互联网的超文本传输协议(HTTP)，将所有具有相同文件系统的计算设备连接在一起，使数据访问的速度更快、更安全、更健壮、更持久。项目由Juan Benet在2014年5月发起。&lt;/p&gt;
&lt;p&gt;IPFS的愿景是构建一个全世界的分布式网络，用来替代传统中心化的服务器模式，所有的IPFS节点组成一个分布式网络，每个节点都可以存储文件，用户可以从IPFS构建的网络中以DHT(Distributed Hash Table，分布式哈希表) 的方式获取文件，从而实现了新一代的完全去中心化的网络，旨在取代现有的万维网。&lt;/p&gt;
&lt;p&gt;一句话概括：IPFS是一种点对点的超媒体文件存储、索引、交换协议。&lt;/p&gt;
&lt;h4 id=&#34;传统http存在的问题&#34;&gt;传统HTTP存在的问题&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;内容无法永久保存&lt;/li&gt;
&lt;li&gt;非常浪费资源&lt;/li&gt;
&lt;li&gt;安全问题
&lt;ul&gt;
&lt;li&gt;DDoS&lt;/li&gt;
&lt;li&gt;XSS&lt;/li&gt;
&lt;li&gt;CSRF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;工作原理&#34;&gt;工作原理&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;现在的网络服务里，内容是基于位置（IP）寻址的，就是在查找内容的时候，需要先找到内容所在的服务器（根据IP），然后再在服务器上找对应的内容。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在IPFS的网络里，是根据内容寻址，每一个‍‍上传到IPFS上面去的文件、文件夹，都是以Qm为开头字母的哈希值，无需知道文件存储在哪里，通过哈希值就能够找到这个文件，这种方式叫内容寻址。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在IPFS系统中，内容会分块存放（如果内容很小就会直接存在DHT中），并分散存储在IPFS网络中的节点上（不过目前的IPFS实现，一个节点会完整保存内容的所有区块）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;系统会给内容的每一个块计算哈希值，然后把所有块的哈希值拼凑起来，再计算一次哈希值，从而得到最终的哈希值&lt;/li&gt;
&lt;li&gt;同时每个节点会维护一张DHT（分布式哈希表），包含数据块与目标节点的映射关系&lt;/li&gt;
&lt;li&gt;在IPFS中是通过哈希去请求文件的，它就会使用这个分布式哈希表找到文件所在的节点，取回文件根据哈希重新组合文件（同样也会验证文件）&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;ipfs特点&#34;&gt;IPFS特点&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;内容可寻址，并且可以确保内容不被篡改（微小的改变也会造成哈希值变得截然不同）&lt;/li&gt;
&lt;li&gt;因为IPFS是统一的网络，文件不会重复存储（文件名不影响哈希值），节约整体存储空间，网络更加高效&lt;/li&gt;
&lt;li&gt;文件永久保存（如节点达到一定规模，即使部分节点离线也不会影响读取）&lt;/li&gt;
&lt;li&gt;IPFS采用分布式存储网络，文件被被存储在不同的网络节点，避免DDoS等网络攻击&lt;/li&gt;
&lt;li&gt;点对点媒体存储，同一个文件可以从多个节点下载，提高了通信效率&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;ipfs功能&#34;&gt;IPFS功能&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;DHT组网&lt;/li&gt;
&lt;li&gt;文件存储&lt;/li&gt;
&lt;li&gt;Bitswap文件交换&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ipfs应用场景&#34;&gt;IPFS应用场景&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在/ipfs和/ipns下挂在全球文件系统&lt;/li&gt;
&lt;li&gt;挂载的个人同步文件夹，拥有版本管理功能&lt;/li&gt;
&lt;li&gt;可用于所有软件的带版本的包管理器&lt;/li&gt;
&lt;li&gt;可以作为数据库&lt;/li&gt;
&lt;li&gt;可以做（加密）通讯平台&lt;/li&gt;
&lt;li&gt;各种类型CDN&lt;/li&gt;
&lt;li&gt;永久Web（不存在失效链接）&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ipns&#34;&gt;IPNS&lt;/h3&gt;
&lt;p&gt;IPFS中文件内容的改变会造成其哈希值的变化，确保内容不被篡改，提升数据安全性。&lt;/p&gt;
&lt;p&gt;但网站等需要版本更新迭代的应用则需要一个映射方案以保证用户体验，IPFS提供了IPNS(Inter-Planetary Naming System)，提供了一个被私钥限定的哈希ID（通常是PeerID），用来指向具体的IPFS文件，文件更新且自动更新哈希ID的指向。&lt;/p&gt;
&lt;p&gt;IPNS同样兼容DNS，使用DNS TXT记录域名对应的IPNS哈希ID，就可以域名来替换IPNS哈希ID来进行访问。从而实现更容易读写和记忆。&lt;/p&gt;
&lt;h3 id=&#34;ipfs入门&#34;&gt;IPFS入门&lt;/h3&gt;
&lt;h4 id=&#34;安装macos-1123&#34;&gt;安装（macOS 11.2.3）&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;wget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_darwin-amd64.tar.gz
tar -xvzf go-ipfs_v0.8.0_darwin-amd64.tar.gz
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; go-ipfs
./install.sh
ipfs --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;启动&#34;&gt;启动&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动节点&lt;/span&gt;
ipfs init

&lt;span class=&#34;c1&#34;&gt;# 上传文件&lt;/span&gt;
ipfs add ipfs_init_readme.png

&lt;span class=&#34;c1&#34;&gt;# 上传文件并且只输出哈希值&lt;/span&gt;
ipfs add -q ipfs_init_readme.png

&lt;span class=&#34;c1&#34;&gt;# 上传目录&lt;/span&gt;
ipfs add -r &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查看文件&lt;/span&gt;
ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme
ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/quick-start

&lt;span class=&#34;c1&#34;&gt;# 查看自己上传的文件&lt;/span&gt;
ipfs cat QmaP3QS6ZfBoEaUJZ3ZfRKoBm3GGuhQSnUWtkVCNc8ZLTj

&lt;span class=&#34;c1&#34;&gt;# 查看图片并输出到文件&lt;/span&gt;
ipfs cat QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH &amp;gt; ipfsTest.png

&lt;span class=&#34;c1&#34;&gt;# 下载文件&lt;/span&gt;
ipfs get QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH -o ipfsTest.png

&lt;span class=&#34;c1&#34;&gt;# 压缩并下载文件&lt;/span&gt;
ipfs get QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH -Cao ipfsTest.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_init_readme.png&#34; alt=&#34;ipfs_init_readme&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;开启加入服务&#34;&gt;开启/加入服务&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看当前节点信息 &lt;/span&gt;
ipfs id

&lt;span class=&#34;c1&#34;&gt;# 查看IPFS配置信息&lt;/span&gt;
ipfs config show

&lt;span class=&#34;c1&#34;&gt;# 开启节点服务器&lt;/span&gt;
ipfs daemon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;API服务，默认在5001端口，可以通过 http://localhost:5001/webui 进行访问&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_webui.png&#34; alt=&#34;ipfs_webui&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关服务，默认在8080端口，在浏览器里访问文件需要借助于IPFS提供的网关服务，由浏览器先访问到网关，网关去获取IPFS网络杀过了的文件。通过 http://localhost:8080/ipfs/[File Hash] 来访问上传到ipfs的文件&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;文件操作&#34;&gt;文件操作&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 列出文件&lt;/span&gt;
ipfs files ls

&lt;span class=&#34;c1&#34;&gt;# 创建目录&lt;/span&gt;
ipfs files mkdir

&lt;span class=&#34;c1&#34;&gt;# 删除文件&lt;/span&gt;
ipfs files rm

&lt;span class=&#34;c1&#34;&gt;# 拷贝文件&lt;/span&gt;
ipfs files cp &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; /&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dest Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 移动文件&lt;/span&gt;
ipfs files mv &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; /&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dest Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 状态&lt;/span&gt;
ipfs files stat

&lt;span class=&#34;c1&#34;&gt;# 读取&lt;/span&gt;
ipfs files &lt;span class=&#34;nb&#34;&gt;read&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;使用ipns来解决文件更新问题&#34;&gt;使用IPNS来解决文件更新问题&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 使用IPNS发布内容以自动更新&lt;/span&gt;
ipfs name publish &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查询节点id指向的Hash&lt;/span&gt;
ipfs name resolve

&lt;span class=&#34;c1&#34;&gt;# 有多个站点需要更新，可以新产生一个秘钥对，使用新的key发布&lt;/span&gt;
ipfs key gen --type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;rsa --size&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2048&lt;/span&gt; mykey
ipfs name publish --key&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mykey  &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;pinning&#34;&gt;Pinning&lt;/h4&gt;
&lt;p&gt;当我们向IPFS网络请求文件时，IPFS会把内容先同步的本地提供服务，使用Cache机制处理文件以防止存储空间不断增长，如果文件一段时间未被使用则会被“回收”，Pining的作用就是确保文件在本地不被“回收”。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# pin一个文件&lt;/span&gt;
ipfs pin add &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查询某一个Hash是否被pin&lt;/span&gt;
ipfs pin ls &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 删除pin的状态&lt;/span&gt;
ipfs pin rm -r &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# GC操作&lt;/span&gt;
ipfs repo gc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 3 Clustering</title>
      <link>https://www.pseudoyu.com/en/2021/03/18/comp7103_topic3/</link>
      <pubDate>Thu, 18 Mar 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/03/18/comp7103_topic3/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-3-clustering&#34;&gt;Topic 3 Clustering&lt;/h2&gt;
&lt;h3 id=&#34;cluster-analysis&#34;&gt;Cluster Analysis&lt;/h3&gt;
&lt;p&gt;Finding groups of objects such that the objects in a group will be similar (or related) to one another and different from (or unrelated to) the objects in other groups&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/cluster_analysis.png&#34; alt=&#34;cluster_analysis&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;application&#34;&gt;Application&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Understanding
&lt;ul&gt;
&lt;li&gt;Group related documents for browsing, group genes and proteins that have similar functionality, or group stocks with similar price fluctuations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Summarization
&lt;ul&gt;
&lt;li&gt;Reduce size of large data sets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;types-of-clusterings&#34;&gt;Types of Clusterings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partitional Clustering
&lt;ul&gt;
&lt;li&gt;A division data objects into non-overlapping subsets (clusters) such that each data object is in exactly one subset
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/partitional_clustering.png&#34; alt=&#34;partitional_clustering&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hierarchical clustering
&lt;ul&gt;
&lt;li&gt;A set of nested clusters organized as a hierarchical tree
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hierarchical_clustering.png&#34; alt=&#34;hierarchical_clustering&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other Distinctions Between Sets of Clusters
&lt;ul&gt;
&lt;li&gt;Exclusive versus non-exclusive
&lt;ul&gt;
&lt;li&gt;In non-exclusive clusterings, points may belong to multiple clusters&lt;/li&gt;
&lt;li&gt;Can represent multiple classes or &amp;lsquo;border&amp;rsquo; points&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fuzzy versus non-fuzzy
&lt;ul&gt;
&lt;li&gt;In fuzzy clustering, a point belongs to every cluster with some weight between 0 and 1&lt;/li&gt;
&lt;li&gt;Weights must sum to 1&lt;/li&gt;
&lt;li&gt;Probabilistic clustering has similar characteristics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Partial versus complete
&lt;ul&gt;
&lt;li&gt;In some cases, we only want to cluster some of the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Heterogeneous versus homogeneous
&lt;ul&gt;
&lt;li&gt;Cluster of widely different sizes, shapes, and densities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;well-separated-clusters&#34;&gt;Well-separated clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of points such that any point in a cluster is closer (or more similar) to every other point in the cluster than to any point not in the cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/wellseparated_clusters.png&#34; alt=&#34;wellseparated_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;center-based-clusters&#34;&gt;Center-based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of objects such that an object in a cluster is closer (more similar) to the “center” of a cluster, than to the center of any other cluster&lt;/p&gt;
&lt;p&gt;The center of a cluster is often a centroid, the average of all the points in the cluster, or a medoid, the most “representative” point of a cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/center_based_clusters.png&#34; alt=&#34;center_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;contiguity-based-clusters&#34;&gt;Contiguity-Based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of points such that a point in a cluster is closer (or more similar) to one or more other points in the cluster than to any point not in the cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/contiguity_based_clusters.png&#34; alt=&#34;contiguity_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;density-based-clusters&#34;&gt;Density-based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a dense region of points, which is separated by low-density regions, from other regions of high density&lt;/p&gt;
&lt;p&gt;Used when the clusters are irregular or intertwined, and when noise and outliers are present&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/density_based_clusters.png&#34; alt=&#34;density_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;conceptual-clusters&#34;&gt;Conceptual Clusters&lt;/h4&gt;
&lt;p&gt;Finds clusters that share some common property or represent a particular concept&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/conceptual_clusters.png&#34; alt=&#34;conceptual_clusters&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-means&#34;&gt;K-means&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Input
&lt;ul&gt;
&lt;li&gt;integer k&amp;gt;0, set S of points in the euclidean space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Output
&lt;ul&gt;
&lt;li&gt;A (partitional) clustering of S&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Step&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select k points in S as the initial centroids&lt;/li&gt;
&lt;li&gt;Repeat until the centroids do not change
&lt;ul&gt;
&lt;li&gt;Form k clusters by assigning points to the closest centroids&lt;/li&gt;
&lt;li&gt;For each cluster recompute its centroid&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Feature&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial centroids are often chosen randomly&lt;/li&gt;
&lt;li&gt;Centroids are often the mean of the points in the cluster&lt;/li&gt;
&lt;li&gt;&amp;lsquo;Closeness&amp;rsquo; is measured by Euclidean distance, cosine similarity, correlation, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;importance-of-choosing-initial-centroids&#34;&gt;Importance of Choosing Initial Centroids&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids.png&#34; alt=&#34;choosing_Initial_centroids&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids_2.png&#34; alt=&#34;choosing_Initial_centroids_2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids_3.png&#34; alt=&#34;choosing_Initial_centroids_3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;evaluating-k-means-clusterings&#34;&gt;Evaluating K-means Clusterings&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Most common measure is Sum of Squared Error (SSE)
&lt;ul&gt;
&lt;li&gt;Given two clusterings, we can choose the one with smallest error&lt;/li&gt;
&lt;li&gt;Decreasing K might decrease SSE&lt;/li&gt;
&lt;li&gt;However, good clusterings with small K might have a lower SSE than poor clusterings with higher K&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;k-means-always-terminates&#34;&gt;K-Means Always Terminates&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Theorem
&lt;ul&gt;
&lt;li&gt;K-means with Euclidean distance as distance always terminates&lt;/li&gt;
&lt;li&gt;Proof follows from the following lemmas&lt;/li&gt;
&lt;li&gt;We cannot obtain the same clustering more than once, otherwise we get the same SSE value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 1
&lt;ul&gt;
&lt;li&gt;The point y that minimizes the SSE in a cluster C is the mean of all points in C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 2
&lt;ul&gt;
&lt;li&gt;SSE strictly decreases.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 3&lt;/li&gt;
&lt;li&gt;The total number of possible clusterings is finite (&amp;lt; n^k).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;solutions-to-initial-centroids-problem&#34;&gt;Solutions to Initial Centroids Problem&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Multiple runs (helps but low success probability)&lt;/li&gt;
&lt;li&gt;Sample and use hierarchical clustering to determine initial centroids&lt;/li&gt;
&lt;li&gt;Select more than k initial centroids and then select among these initial centroids&lt;/li&gt;
&lt;li&gt;Postprocessing&lt;/li&gt;
&lt;li&gt;K-Means++&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;handling-empty-clusters&#34;&gt;Handling Empty Clusters&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Basic K-means algorithm can yield less than k clusters (so called empty clusters)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pick the points that contributes most to SSE and move them to empty cluster&lt;/li&gt;
&lt;li&gt;Pick the points from the cluster with the highest SSE&lt;/li&gt;
&lt;li&gt;If there are several empty clusters, the above can be repeated several times&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;updating-centers-incrementally&#34;&gt;Updating Centers Incrementally&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In the basic K-means algorithm, centroids are updated after all points are assigned to a centroid&lt;/li&gt;
&lt;li&gt;An alternative is to update the centroids after each assignment (incremental approach)&lt;/li&gt;
&lt;li&gt;More precisely, let C1 ,C2 ,&amp;hellip;,C k be the current clusters. Reassign all points one by one to the best cluster. Let p in C i be the current point and suppose we re-assign it to Cj . Then, after that, recompute the centroid of C i and Cj
&lt;ul&gt;
&lt;li&gt;Never get an empty cluster&lt;/li&gt;
&lt;li&gt;Introduces an order dependency&lt;/li&gt;
&lt;li&gt;More expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pre-processing-and-post-processing&#34;&gt;Pre-processing and Post-processing&lt;/h4&gt;
&lt;p&gt;Pre-processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalize the data&lt;/li&gt;
&lt;li&gt;Eliminate outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Post-processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eliminate small clusters that may represent outliers&lt;/li&gt;
&lt;li&gt;Split &amp;lsquo;loose&amp;rsquo; clusters, i.e., clusters with relatively high SSE&lt;/li&gt;
&lt;li&gt;Merge clusters that are ‘close’ and that have relatively low SSE&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;limitations-of-k-means&#34;&gt;Limitations of K-means&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means has problems when clusters are of differing
&lt;ul&gt;
&lt;li&gt;Sizes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations.png&#34; alt=&#34;kmeans_limitations&#34;&gt;&lt;/li&gt;
&lt;li&gt;Densities
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations_density.png&#34; alt=&#34;kmeans_limitations_density&#34;&gt;&lt;/li&gt;
&lt;li&gt;Non-globular shapes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations_globular.png&#34; alt=&#34;kmeans_limitations_globular&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;K-means has problems when the data contains outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;overcoming-k-means-limitations&#34;&gt;Overcoming K-means Limitations&lt;/h4&gt;
&lt;p&gt;Use many clusters, find parts of clusters, but need to put together&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overcome_kmeans_limitations_1.png&#34; alt=&#34;overcome_kmeans_limitations_1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overcome_kmeans_limitations_2.png&#34; alt=&#34;overcome_kmeans_limitations_2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hierarchical-clustering&#34;&gt;Hierarchical clustering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Produces a set of nested clusters organized as a hierarchical tree&lt;/li&gt;
&lt;li&gt;Can be visualized as a dendrogram
&lt;ul&gt;
&lt;li&gt;A tree like diagram that records the sequences of merges or splits
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hierarchical_clustering_dendrogram.png&#34; alt=&#34;hierarchical_clustering_dendrogram&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;strengths-of-hierarchical-clustering&#34;&gt;Strengths of Hierarchical Clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Do not have to assume any particular number of clusters
&lt;ul&gt;
&lt;li&gt;Any desired number of clusters can be obtained by ‘cutting’ the dendogram at the proper level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;They may correspond to meaningful taxonomies
&lt;ul&gt;
&lt;li&gt;Example in biological sciences (e.g., animal kingdom, phylogeny reconstruction, …)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;two-main-types-of-hierarchical-clustering&#34;&gt;Two main types of hierarchical clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Agglomerative
&lt;ul&gt;
&lt;li&gt;Start with the points as individual clusters&lt;/li&gt;
&lt;li&gt;At each step, merge the closest pair of clusters until only one cluster (or k clusters) left&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Divisive
&lt;ul&gt;
&lt;li&gt;Start with one, all-inclusive cluster&lt;/li&gt;
&lt;li&gt;At each step, split a cluster until each cluster contains a point (or there are k clusters)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Traditional hierarchical algorithms use a similarity or distance matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Merge or split one cluster at a time&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;agglomerative-clustering-algorithm&#34;&gt;Agglomerative Clustering Algorithm&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Most popular hierarchical clustering technique&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let each data point be a cluster&lt;/li&gt;
&lt;li&gt;Compute the distance matrix n x n&lt;/li&gt;
&lt;li&gt;Repeat
&lt;ul&gt;
&lt;li&gt;Merge the two closest clusters&lt;/li&gt;
&lt;li&gt;Update distance matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Until only a single cluster remains&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Procedure&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Start with clusters of individual points and a distance matrix n x n
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_1.png&#34; alt=&#34;agglomerative_clustering_algorithm_1&#34;&gt;&lt;/li&gt;
&lt;li&gt;After some merging steps, we have some clusters
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_2.png&#34; alt=&#34;agglomerative_clustering_algorithm_2&#34;&gt;&lt;/li&gt;
&lt;li&gt;We want to merge the two closest clusters (C2 and C5) and update the distance matrix
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_3.png&#34; alt=&#34;agglomerative_clustering_algorithm_3&#34;&gt;&lt;/li&gt;
&lt;li&gt;The question is “How do we update the distance matrix
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_4.png&#34; alt=&#34;agglomerative_clustering_algorithm_4&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;how-to-define-inter-cluster-similarity&#34;&gt;How to Define Inter-Cluster Similarity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;MIN
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_1.png&#34; alt=&#34;inter_cluster_similarity_1&#34;&gt;&lt;/li&gt;
&lt;li&gt;MAX
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_2.png&#34; alt=&#34;inter_cluster_similarity_2&#34;&gt;&lt;/li&gt;
&lt;li&gt;Group Average
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_3.png&#34; alt=&#34;inter_cluster_similarity_3&#34;&gt;&lt;/li&gt;
&lt;li&gt;Distance Between Centroids
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_4.png&#34; alt=&#34;inter_cluster_similarity_4&#34;&gt;&lt;/li&gt;
&lt;li&gt;Other methods driven by an objective function
&lt;ul&gt;
&lt;li&gt;Ward’s Method uses squared error&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;problems-and-limitations&#34;&gt;Problems and Limitations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Once a decision is made to combine two clusters, it cannot be undone&lt;/li&gt;
&lt;li&gt;No objective function is directly minimized&lt;/li&gt;
&lt;li&gt;Different schemes have problems with one or more of the following
&lt;ul&gt;
&lt;li&gt;Sensitivity to noise and outliers&lt;/li&gt;
&lt;li&gt;Difficulty handling different sized clusters and convex shapes&lt;/li&gt;
&lt;li&gt;Breaking large clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cluster-validity&#34;&gt;Cluster Validity&lt;/h3&gt;
&lt;p&gt;Numerical measures that are applied to judge various aspects of cluster validity, are classified into the following three types&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;External Index
&lt;ul&gt;
&lt;li&gt;Used to measure the extent to which cluster labels match externally supplied class labels
&lt;ul&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Internal Index
&lt;ul&gt;
&lt;li&gt;Used to measure the goodness of a clustering structure without respect to external information
&lt;ul&gt;
&lt;li&gt;Sum of Squared Error (SSE)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relative Index
&lt;ul&gt;
&lt;li&gt;To compare two different clusterings or clusters
&lt;ul&gt;
&lt;li&gt;An external or internal index is used for this function, e.g., SSE or entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;internal-measures-sse&#34;&gt;Internal Measures: SSE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Clusters in more complicated figures aren’t well separated&lt;/li&gt;
&lt;li&gt;SSE is good for comparing two clusterings or two clusters (average SSE)&lt;/li&gt;
&lt;li&gt;Can also be used to estimate the number of clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/internal_measures_SSE.png&#34; alt=&#34;internal_measures_SSE&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;external-measures-of-cluster-validity-entropy&#34;&gt;External Measures of Cluster Validity: Entropy&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Definition: Entropy
&lt;ul&gt;
&lt;li&gt;Entropy measure how uncertain is an event, the larger the entropy the more uncertain is the event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/external_measures_of_cluster_validity_Entropy.png&#34; alt=&#34;external_measures_of_cluster_validity_Entropy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;The validation of clustering structures is the most difficult and frustrating part of cluster analysis. Without a strong effort in this direction, cluster analysis will remain a black art accessible only to those true believers who have experience and great courage.&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-means-1&#34;&gt;K-means++&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the centroids as in Algorithm 1&lt;/li&gt;
&lt;li&gt;Run K-means algorithm to improve the clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_plus_plus_algorithm1.png&#34; alt=&#34;kmeans_plus_plus_algorithm1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-comparison&#34;&gt;Algorithm Comparison&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means
&lt;ul&gt;
&lt;li&gt;No guarantees on the quality of the solution&lt;/li&gt;
&lt;li&gt;It always terminates&lt;/li&gt;
&lt;li&gt;Running time could be exponential but it is OK in practice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;K-means++
&lt;ul&gt;
&lt;li&gt;It always terminates&lt;/li&gt;
&lt;li&gt;O(log k)-approximation on the quality of the solution&lt;/li&gt;
&lt;li&gt;In practice the advantage is noticeable for large k&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 4 Top-k</title>
      <link>https://www.pseudoyu.com/en/2021/03/06/comp7801_topic4/</link>
      <pubDate>Sat, 06 Mar 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/03/06/comp7801_topic4/</guid>
      
        <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;multidimensional-data&#34;&gt;Multidimensional Data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Flat relational tables&lt;/li&gt;
&lt;li&gt;Multimedia feature vectors&lt;/li&gt;
&lt;li&gt;Data warehouse data&lt;/li&gt;
&lt;li&gt;Spatial data&lt;/li&gt;
&lt;li&gt;Text documents&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;attribute-types&#34;&gt;Attribute Types&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Attributes of multidimensional tuples may have variable types
&lt;ul&gt;
&lt;li&gt;Ordinal (e.g., age, salary)&lt;/li&gt;
&lt;li&gt;Nominal categorical values (e.g., color, religion)&lt;/li&gt;
&lt;li&gt;Binary (e.g., gender, owns_property)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Basic queries: range, NN, similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-queries&#34;&gt;Basic Queries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;(Range) selection query
&lt;ul&gt;
&lt;li&gt;Returns the records that qualify a (multidimensional) range predicate&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Return the employees of age between 45 and 50 and salary above $100,000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distance (similarity) query
&lt;ul&gt;
&lt;li&gt;Returns the records that are within a distance from a reference record.&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Find images with feature vectors of Euclidean distance at most ε with the feature vector of a given image&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nearest neighbor (similarity) query
&lt;ul&gt;
&lt;li&gt;Replaces distance bound by ranking predicate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;top-k-search-methods&#34;&gt;Top-k Search Methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Rank aggregation&lt;/li&gt;
&lt;li&gt;Index-based methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query&#34;&gt;Top-k Query&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of objects (e.g., relational tuples),&lt;/li&gt;
&lt;li&gt;Returns the k objects with the highest combined score, based on an aggregate function f.&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Relational table containing information about restaurants, with attributes(e.g. price, quality, location)&lt;/li&gt;
&lt;li&gt;f: sum(-price, quality, -dist(location,my_hotel))‏&lt;/li&gt;
&lt;li&gt;attribute value ranges are usually normalized
&lt;ul&gt;
&lt;li&gt;E.g., all values in a (0,1) range&lt;/li&gt;
&lt;li&gt;otherwise some attribute may be favored in f&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query-variants&#34;&gt;Top-k Query Variants&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Apply on single table, or ranked lists of tuples ordered by individual attributes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_1.jpg&#34; alt=&#34;Top_k_Query_Variants_1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ranked inputs in the same or different servers (centralized or distributed data)
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_2.jpg&#34; alt=&#34;Top_k_Query_Variants_1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Standalone query or operator in a more complex query plan
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_3.jpg&#34; alt=&#34;Top_k_Query_Variants_3&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Incremental retrieval of objects with highest scores (k is not predefined)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Top-k joins&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;House&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;School&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;location&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;location&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;∗&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tuition&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;LIMIT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Probabilistic/approximate top-k retrieval&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random and/or sorted accesses at ranked inputs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query-evaluation&#34;&gt;Top-k Query Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Most solutions assume distributive, monotone aggregate functions (e.g. f=sum)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;distributive: f(x,y,z,w)= f(f(x,y),f(z,w))
&lt;ul&gt;
&lt;li&gt;e.g., A+B+C+D = (A+B) + (C+D)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;monotone: if x&amp;lt;y and z&amp;lt;w, then f(x,z)&amp;lt;f(y,w)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions based on 1-D ordering and merging sorted lists (rank aggregation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions based on multidimensional indexing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rank-aggregation&#34;&gt;Rank Aggregation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Solutions based on 1-D ordering and merging sorted lists (rank aggregation)&lt;/li&gt;
&lt;li&gt;Assume that there is a total ranking of theobjects for each attributethat can be used in top-kqueries&lt;/li&gt;
&lt;li&gt;These sorted inputs canbe accessed sequentiallyand/or by random accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Rank_Aggregation.jpg&#34; alt=&#34;Rank_Aggregation&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;advantages-and-drawbacks&#34;&gt;Advantages and Drawbacks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Advantages：
&lt;ul&gt;
&lt;li&gt;can be applied on any subset of inputs (arbitrary subspace)&lt;/li&gt;
&lt;li&gt;appropriate for distributed data&lt;/li&gt;
&lt;li&gt;appropriate for top-k joins&lt;/li&gt;
&lt;li&gt;easy to understand and implement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Drawbacks:
&lt;ul&gt;
&lt;li&gt;slower than index-based methods&lt;/li&gt;
&lt;li&gt;require inputs to be sorted&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ta-threshold-algorithm&#34;&gt;TA: Threshold Algorithm&lt;/h3&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Iteratively retrieves objects and their atomic scores from the ranked inputs in a round-robin fashion.&lt;/li&gt;
&lt;li&gt;For each encountered object x, perform random accesses to the inputs where x has not been seen.&lt;/li&gt;
&lt;li&gt;Maintain top-k objects seen so far.&lt;/li&gt;
&lt;li&gt;T = f($l_1$, . . . , $l_m$) is the score derived when applying the aggregation function to the last atomic scores seen at each input. If the score of the k-th object is no smaller than T, terminate.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-of-tak1fsum&#34;&gt;Example of TA(k=1,f=sum)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 1&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is c, with score 2.0&lt;/li&gt;
&lt;li&gt;T=sum(0.9,0.9,0.9)=2.7&lt;/li&gt;
&lt;li&gt;T&amp;gt;top-1, we proceed to another round of accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_1.jpg&#34; alt=&#34;TA_Step_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 2&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is b, with score 2.2&lt;/li&gt;
&lt;li&gt;T=sum(0.8,0.8,0.9)=2.5&lt;/li&gt;
&lt;li&gt;T&amp;gt;top-1, we proceed to another round of accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_2.jpg&#34; alt=&#34;TA_Step_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 3&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is b, with score 2.2&lt;/li&gt;
&lt;li&gt;T=sum(0.6,0.6,0.8)=2.0&lt;/li&gt;
&lt;li&gt;T≤top-1, terminate and output (b,2.2)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_3.jpg&#34; alt=&#34;TA_Step_3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;properties-of-ta&#34;&gt;Properties of TA&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Used as a standard module for merging ranked lists in many applications&lt;/li&gt;
&lt;li&gt;Usually finds the result quickly&lt;/li&gt;
&lt;li&gt;Depends on random accesses, which can be expensive&lt;/li&gt;
&lt;li&gt;random accesses are impossible in some cases
&lt;ul&gt;
&lt;li&gt;e.g., an API allows to access objects incrementally by ranking score, but does not provide the score of a given object&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nra-no-random-accesses&#34;&gt;NRA: No Random Accesses&lt;/h3&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Iteratively retrieves objects and their atomic scores from the ranked inputs in a round-robin fashion.&lt;/li&gt;
&lt;li&gt;For each object x seen so far at any input maintain:
&lt;ul&gt;
&lt;li&gt;f_x_ub: upper bound for x’s aggregate score (f_x)&lt;/li&gt;
&lt;li&gt;f_x_lb: lower bound for x’s aggregate score (f_x)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;W_k = k objects with the largest f^lb.&lt;/li&gt;
&lt;li&gt;If the smallest f^lb in W_k is at least the largest f_x_ub of any object x not in W_k, then terminate and report W_k as top-k result.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-of-nrak1fsum&#34;&gt;Example of NRA(k=1,f=sum)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 1&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_1.jpg&#34; alt=&#34;NRA_Step_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_2.jpg&#34; alt=&#34;NRA_Step_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 3&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_3.jpg&#34; alt=&#34;NRA_Step_3&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 4&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_4.jpg&#34; alt=&#34;NRA_Step_4&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;nra-properties&#34;&gt;NRA Properties&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;More generic than TA, since it does not depend on random accesses&lt;/li&gt;
&lt;li&gt;Can be cheaper than TA, if random accesses are very expensive&lt;/li&gt;
&lt;li&gt;NRA accesses objects sequentially from all inputs and updates the upper bounds for all objects seen so far unconditionally.
&lt;ul&gt;
&lt;li&gt;Cost: O(n) per access (the expected distinct number of objects accessed so far is O(n))&lt;/li&gt;
&lt;li&gt;No input list is pruned until the algorithm terminates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lara-lattice-based-rank-aggregation&#34;&gt;LARA: LAttice-based Rank Aggregation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LARA: An efficient NRA implementation&lt;/li&gt;
&lt;li&gt;Based on 3 observations about the top-k candidates&lt;/li&gt;
&lt;li&gt;Operates differently in the two (growing, shrinking) phases&lt;/li&gt;
&lt;li&gt;Takes its name from the lattice used in the shrinking phase&lt;/li&gt;
&lt;li&gt;Extendable to various top-k query variants&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 3 Spatial Networks</title>
      <link>https://www.pseudoyu.com/en/2021/02/27/comp7801_topic3/</link>
      <pubDate>Sat, 27 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/02/27/comp7801_topic3/</guid>
      
        <description>&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;h4 id=&#34;network-distance&#34;&gt;Network Distance&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In many real applications accessibility of objects is restricted by a spatial network
&lt;ul&gt;
&lt;li&gt;Examples
&lt;ul&gt;
&lt;li&gt;Driver looking for nearest gas station&lt;/li&gt;
&lt;li&gt;Mobile user looking for nearest restaurant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shortest path distance&lt;/strong&gt; used instead of Euclidean distance&lt;/li&gt;
&lt;li&gt;SP(a,b) = path between a and b with the minimum accumulated length&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;challenges&#34;&gt;Challenges&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Euclidean distance is no longer relevant
&lt;ul&gt;
&lt;li&gt;R-tree may not be useful, when search is based on shortest path distance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph cannot be flattened to a one-dimensional space
&lt;ul&gt;
&lt;li&gt;Special storage and indexing techniques for graphs are required&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph properties may vary
&lt;ul&gt;
&lt;li&gt;directed vs. undirected&lt;/li&gt;
&lt;li&gt;length, time, etc. as edge weights&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;modeling-and-storing-spatial-networks&#34;&gt;Modeling and Storing Spatial Networks&lt;/h3&gt;
&lt;h4 id=&#34;modeling-spatial-networks&#34;&gt;Modeling Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Adjacency matrix only appropriate for dense graphs&lt;/li&gt;
&lt;li&gt;Spatial networks are sparse: use adjacency lists instead&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Modeling_Spatial_Networks.png&#34; alt=&#34;Modeling_Spatial_Networks&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;storing-large-spatial-networks&#34;&gt;Storing Large Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Problem: adjacency lists representation may not fit in memory if graph is large&lt;/li&gt;
&lt;li&gt;Solution:
&lt;ul&gt;
&lt;li&gt;partition adjacency lists to disk blocks (based on proximity)&lt;/li&gt;
&lt;li&gt;create B+-tree index on top of partitions (based on node-id)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Storing_Large_Spatial_Network.png&#34; alt=&#34;Storing_Large_Spatial_Network&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;shortest-path-search&#34;&gt;Shortest Path Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given a graph G(V,E), and two nodes s,t in V, find the shortest path from s to t&lt;/li&gt;
&lt;li&gt;A classic algorithmic problem&lt;/li&gt;
&lt;li&gt;Studied extensively since the 1950’s&lt;/li&gt;
&lt;li&gt;Several methods:
&lt;ul&gt;
&lt;li&gt;Dijkstra’s algorithm&lt;/li&gt;
&lt;li&gt;A*-search&lt;/li&gt;
&lt;li&gt;Bi-directional search&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dijkstras-shortest-path-search&#34;&gt;Dijkstra’s Shortest Path Search&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;idea: incrementally explore the graph around s, visitingnodes in distance order to suntil t is found (like NN)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_1.png&#34; alt=&#34;Dijkstra_1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_2.png&#34; alt=&#34;Dijkstra_2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_Algorithm.png&#34; alt=&#34;Dijkstra_Algorithm&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;example&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_Example.png&#34; alt=&#34;Dijkstra_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the shortest path between a and b.&lt;/li&gt;
&lt;li&gt;Worst-case performance O(|E| + |V|log|V| )&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-search&#34;&gt;A*-search&lt;/h3&gt;
&lt;h4 id=&#34;description&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dijkstra’s search explores nodes around s without a specific search direction until t is found&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Idea: improve Dijkstra’s algorithm by directing search towards t&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Due to triangular inequality, Euclidean distance is a lower bound of network distance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Euclidean distance to lower bound network distance based on known information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nodes are visited in increasing SPD(s,v)+dist(v,t) order
&lt;ul&gt;
&lt;li&gt;SPD(s,v): shortest path distance from s to v (computed by Dijkstra)&lt;/li&gt;
&lt;li&gt;dist(v,t): Euclidean distance between v and t&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Original Dijkstra visits nodes in increasing SPD(s,v) order&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/A_Star_1.png&#34; alt=&#34;A_Star_1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;example-1&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/A_Star_Example.png&#34; alt=&#34;A_Star_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating-1&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the shortest path between s and t.
&lt;ul&gt;
&lt;li&gt;f(p) = Dijkstra_dist(s, p) + Euclidean_dist(p, t)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bi-directional-search&#34;&gt;Bi-directional search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra’s search explores nodes around s without a specific search direction until t is found&lt;/li&gt;
&lt;li&gt;Idea: search can be performed concurrently from s and from t (backwards)&lt;/li&gt;
&lt;li&gt;The shortest path tree of s and the (backward) shortest path tree of t are computed in concurrently
&lt;ul&gt;
&lt;li&gt;One queue Q_s for forward and one queue Q_t for backward search&lt;/li&gt;
&lt;li&gt;Node visits are prioritized based on min(SPD(s,v), SPD(v,t))&lt;/li&gt;
&lt;li&gt;If v already visited from s and v is in Qt, then candidate shortest path: p(s,v)+p(v,t)  (if v already visited from t and v in Q_s symmetric)&lt;/li&gt;
&lt;li&gt;If v is visited by both s and t terminate search; report best candidate shortest path&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-2&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Bi_Directional_Example.png&#34; alt=&#34;Bi_Directional_Example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;discussions&#34;&gt;Discussions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A* and bi-directional search can be combined to powerful search techniques&lt;/li&gt;
&lt;li&gt;A* can only be applied if lower distance bounds are available&lt;/li&gt;
&lt;li&gt;All versions of Dijkstra’s search require non-negative edge weights
&lt;ul&gt;
&lt;li&gt;Bellman-Ford is an algorithm for arbitrary negative edges&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spatial-queries-over-spatial-networks&#34;&gt;Spatial queries over spatial networks&lt;/h2&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;h4 id=&#34;sourcedestination-on-edges&#34;&gt;Source/Destination on Edges&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;We have assumed that points s and t are nodes of the network&lt;/li&gt;
&lt;li&gt;In practice s and t could be arbitrary points on edges
&lt;ul&gt;
&lt;li&gt;Mobile user locations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solve problem by introducing 2 more nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Source_Destination_on_Edges.png&#34; alt=&#34;Source_Destination_on_Edges&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;spatial-queries-over-spatial-networks-1&#34;&gt;Spatial Queries over Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data:
&lt;ul&gt;
&lt;li&gt;A (static) spatial network (e.g., city map)&lt;/li&gt;
&lt;li&gt;A (dynamic) set of spatial objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial queries based on network distance:
&lt;ul&gt;
&lt;li&gt;Selections. Ex: find gas stations within 10km driving distance from here&lt;/li&gt;
&lt;li&gt;Nearest neighbor search. Ex: find k nearest restaurants from present position&lt;/li&gt;
&lt;li&gt;Joins. Ex: find pairs of restaurants and hotels at most 100m from each other&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Spatial_Queries_over_Spatial_Networks.png&#34; alt=&#34;Spatial_Queries_over_Spatial_Networks&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;methodology&#34;&gt;Methodology&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Store (and index) the spatial network
&lt;ul&gt;
&lt;li&gt;Graph component (indexes connectivity information)&lt;/li&gt;
&lt;li&gt;Spatial component (indexes coordinates of nodes, edges, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Store (and index) the sets of spatial objects
&lt;ul&gt;
&lt;li&gt;Ex., one spatial relation for restaurants, one spatial relation for hotels, one relation for mobile users, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Given a spatial location p, use spatial component of network to find the network edge containing p&lt;/li&gt;
&lt;li&gt;Given a network edge, use network component to traverse neighboring edges&lt;/li&gt;
&lt;li&gt;Given a neighboring edge, use spatial indexes to find objects on them&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-of-spatial-selections-1&#34;&gt;Evaluation of Spatial Selections (1)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find all objects in spatial relation R, within network distance ε from location q&lt;/li&gt;
&lt;li&gt;Method:
&lt;ul&gt;
&lt;li&gt;Use spatial index of network (R-tree indexing network edges) to find edge n_1n_2, which includes q&lt;/li&gt;
&lt;li&gt;Use adjacency index of network (graph component) and apply Dijkstra’s algorithm to progressively retrieve edges that are within network distance ε from location q&lt;/li&gt;
&lt;li&gt;For all these edges apply a spatial selection on the R-tree that indexes R to find the results&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-3&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example: Find restaurants at most distance 10 from q&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 1: find network edge which contains q&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_1.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: traverse network to find all edges (or parts of them within distance 10 from q)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_2.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: find restaurants that intersect the subnetwork computed at step 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_3.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_3&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluation-of-spatial-selections-2&#34;&gt;Evaluation of Spatial Selections (2)&lt;/h3&gt;
&lt;h4 id=&#34;description-1&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Query: find all objects in spatial relation R, within network distance ε from location q&lt;/li&gt;
&lt;li&gt;Alternative method based on Euclidean bounds:
&lt;ul&gt;
&lt;li&gt;Assumption: Euclidean distance is a lower-bound of network distance:
&lt;ul&gt;
&lt;li&gt;dist(v,u) ≤ SPD(v,u), for any v,u&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use R-tree on R to find set S of objects such that for each o in S: dist(q,o) ≤ ε&lt;/li&gt;
&lt;li&gt;For each o in S:
&lt;ul&gt;
&lt;li&gt;find where o is located in the network (use Network R-tree)&lt;/li&gt;
&lt;li&gt;compute SPD(q,o) (e.g. use A*)&lt;/li&gt;
&lt;li&gt;If SPD(q,o) ≤ ε then output o&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-4&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example: Find restaurants at most distance 10 from q&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 1: find restaurants for which the Euclidean distance to q is at most 10: S={r1,r2,r3}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_Example_1.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_Example_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: for each restaurant in S, compute SPD to q and verify if it is indeed a correct result&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_Example_2.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_Example_2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluation-of-nn-search-1&#34;&gt;Evaluation of NN search (1)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find in spatial relation R the nearest object to a given location q&lt;/li&gt;
&lt;li&gt;Method:
&lt;ul&gt;
&lt;li&gt;Use spatial index of network (R-tree indexing network edges) to find edge n_1n_2, which includes q&lt;/li&gt;
&lt;li&gt;Use adjacency index of network (graph component) and apply Dijkstra’s algorithm to progressively retrieve edges in order of their distance to q&lt;/li&gt;
&lt;li&gt;For each edge apply a spatial selection on the R-tree that indexes R to find any objects&lt;/li&gt;
&lt;li&gt;Keep track of nearest object found so far; use its shortest path distance to terminate network browsing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-5&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Example: Find nearest restaurant to q&lt;/li&gt;
&lt;li&gt;Step: in ppt 31&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-of-nn-search-2&#34;&gt;Evaluation of NN search (2)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find in spatial relation R the nearest object to a given location q&lt;/li&gt;
&lt;li&gt;Alternative method based on Euclidean bounds:
&lt;ul&gt;
&lt;li&gt;Assumption: Euclidean distance lower-bounds network distance:
&lt;ul&gt;
&lt;li&gt;dist(v,u) ≤ SPD(v,u), for any v,u&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_NN_search.png&#34; alt=&#34;Evaluation_of_NN_search&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;spatial-join-queries&#34;&gt;Spatial Join Queries&lt;/h3&gt;
&lt;h4 id=&#34;description-2&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Query: find pairs (r,s), such that r in relation R, s in relation S, and SPD(r,s)≤ε&lt;/li&gt;
&lt;li&gt;Methods:
&lt;ul&gt;
&lt;li&gt;For each r in R, do an ε-distance selection queries for objects in S (Index Nested Loops)&lt;/li&gt;
&lt;li&gt;For each pair (r,s), such that Euclidean dist(r,s)≤ε compute SPD(r,s) and verify SPD(r,s)≤ε&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;notes-on-query-evaluation-based-on-network-distance&#34;&gt;Notes on Query Evaluation based on Network Distance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;For each query type, there are methods based on network browsing and methods based on Euclidean bounds&lt;/li&gt;
&lt;li&gt;Network browsing methods are fast if network edges are densely populated with points of interest
&lt;ul&gt;
&lt;li&gt;A limited network traversal can find the result fast&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Methods based on Euclidean bounds are good if the searched POIs are sparsely distributed in the network
&lt;ul&gt;
&lt;li&gt;Few verifications with exact SP searches are required&lt;/li&gt;
&lt;li&gt;Directed SP search (e.g. using A*) avoids visiting empty parts of the network&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;advanced-indexing-techniques-for-spatial-networks&#34;&gt;Advanced indexing techniques for spatial networks&lt;/h2&gt;
&lt;h3 id=&#34;shortest-path-materialization-and-indexing-in-large-graphs&#34;&gt;Shortest Path Materialization and Indexing in Large Graphs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra’s algorithm and related methods could be very expensive on very large graphs&lt;/li&gt;
&lt;li&gt;(Partial) materialization of shortest paths in static graphs can accelerate search&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Shortest_Path_Materialization_and_Indexing_in_Large_Graphs.png&#34; alt=&#34;Shortest_Path_Materialization_and_Indexing_in_Large_Graphs.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hierarchical-path-materialization&#34;&gt;Hierarchical Path Materialization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Idea: Partition graph G into G_1,G_2,G_3,… based on connectivity and proximity of nodes&lt;/li&gt;
&lt;li&gt;Every edge of G goes to exactly one G_i&lt;/li&gt;
&lt;li&gt;Border nodes belong to more than one G_i’s&lt;/li&gt;
&lt;li&gt;For each G_i compute and materialize SPs between every pair of nodes in G_i (matrix M_i)
&lt;ul&gt;
&lt;li&gt;Partitions are small enough for materialization space overhead to be low&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute and materialize SPs between every pair of border nodes (matrix B)
&lt;ul&gt;
&lt;li&gt;If border nodes too many, hierarchically partition them into 2nd-level partitions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization.png&#34; alt=&#34;Hierarchical_Path_Materialization&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-1&#34;&gt;algorithm&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization_algorithm.png&#34; alt=&#34;Hierarchical_Path_Materialization_algorithm&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating-2&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Good partitioning if:
&lt;ul&gt;
&lt;li&gt;small partitions&lt;/li&gt;
&lt;li&gt;few combinations examined for SP search&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Real road networks:
&lt;ul&gt;
&lt;li&gt;Non-highway nodes in local partitions&lt;/li&gt;
&lt;li&gt;Highway nodes become border nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization_Illustration.png&#34; alt=&#34;Hierarchical_Path_Materialization_Illustration&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;compressing-materialized-paths&#34;&gt;Compressing Materialized Paths&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Distance matrix with successors has O(n_2) space cost&lt;/li&gt;
&lt;li&gt;Motivation: reduce space by grouping targets based on common successors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Compressing_Materialized_Paths.png&#34; alt=&#34;Compressing_Materialized_Paths&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-2&#34;&gt;algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Create and encode one space partitioning defined by targets of the same successor&lt;/li&gt;
&lt;li&gt;For each node s, index Is a set of &amp;lt;succ,R&amp;gt; pairs:
&lt;ul&gt;
&lt;li&gt;succ: a successor of s&lt;/li&gt;
&lt;li&gt;R: a continuous region, such that for each t in R, the successor of s in SP(s,t) is succ&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Compressing_Materialized_Paths_Algorithm.png&#34; alt=&#34;Compressing_Materialized_Paths_Algorithm&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To compute SP(s,t) for a given s, t:
&lt;ol&gt;
&lt;li&gt;SP=s&lt;/li&gt;
&lt;li&gt;Use spatial index Is to find &amp;lt;succ,R&amp;gt;, such that t in R&lt;/li&gt;
&lt;li&gt;SP = SP + (s,succ)&lt;/li&gt;
&lt;li&gt;If succ = t, report SP and terminate&lt;/li&gt;
&lt;li&gt;Otherwise s=succ; Goto step 2&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Indexing and search of spatial networks is different than spatial indexing
&lt;ul&gt;
&lt;li&gt;Shortest path distance is used instead of Euclidean distance, to define range queries, nearest neighbor search, and spatial joins&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial networks could be too large to fit in memory
&lt;ul&gt;
&lt;li&gt;Disk-based index for adjacency lists is used&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Several shortest path algorithms&lt;/li&gt;
&lt;li&gt;Spatial queries can be evaluated using Euclidean bounds&lt;/li&gt;
&lt;li&gt;Advanced indexing methods for shortest path search on large graphs&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 2 Association Rules</title>
      <link>https://www.pseudoyu.com/en/2021/02/25/comp7103_topic2/</link>
      <pubDate>Thu, 25 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/02/25/comp7103_topic2/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-2-association-rules&#34;&gt;Topic 2 Association Rules&lt;/h2&gt;
&lt;h3 id=&#34;market-basket-model&#34;&gt;Market-Basket Model&lt;/h3&gt;
&lt;p&gt;A general many-many mapping (association) between two kinds of things&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A large set of items, e.g., things sold in a supermarket&lt;/li&gt;
&lt;li&gt;A large set of baskets, each of which is a small set of the items, e.g., the things one customer buys on one day&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;frequent-itemsets&#34;&gt;Frequent Itemsets&lt;/h3&gt;
&lt;h4 id=&#34;support&#34;&gt;Support&lt;/h4&gt;
&lt;p&gt;Support for itemset I (s(I)) = the number of baskets containing all items in I&lt;/p&gt;
&lt;p&gt;Given a support threshold s, sets of items that appear in at least s baskets are called frequent itemsets&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/frequent_itemsets.png&#34; alt=&#34;frequent_itemsets&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;monotonicity&#34;&gt;Monotonicity&lt;/h4&gt;
&lt;p&gt;For any sets of items I and any set of items J, it holds that&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_monotonicity.png&#34; alt=&#34;association_rules_monotonicity&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;applications&#34;&gt;Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;given that many people buy beer and diapers together
&lt;ul&gt;
&lt;li&gt;Run a sale on diapers; raise price of beer&lt;/li&gt;
&lt;li&gt;Only useful if many buy diapers &amp;amp; beer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Items that appear together too often could represent plagiarism&lt;/li&gt;
&lt;li&gt;Unusual words appearing together in a large number of documents&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;association-rules&#34;&gt;Association Rules&lt;/h3&gt;
&lt;p&gt;If-then rules I → j about the contents of baskets, I is a set of items and j is an item&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i → j means
&lt;ul&gt;
&lt;li&gt;if a basket contains all the items in I then it is likely to contain j&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;confidence&#34;&gt;Confidence&lt;/h4&gt;
&lt;p&gt;The probability of j given I&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_confidence.png&#34; alt=&#34;association_rules_confidence&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_confidence_example.png&#34; alt=&#34;association_rules_confidence_example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;finding-association-rules&#34;&gt;Finding Association Rules&lt;/h4&gt;
&lt;p&gt;find all association rules with support ≥ s and confidence ≥ c&lt;/p&gt;
&lt;h4 id=&#34;computation-model&#34;&gt;Computation Model&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data is kept in raw files rather than in a database system
&lt;ul&gt;
&lt;li&gt;Stored on disk&lt;/li&gt;
&lt;li&gt;Stored basket-by-basket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The true cost of mining disk-resident data is usually the number of disk I/O’s&lt;/li&gt;
&lt;li&gt;In practice, association-rule algorithms read data in passes – all baskets read in turn&lt;/li&gt;
&lt;li&gt;we measure the cost by the number of passes an algorithm takes&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;association-rules-algorithms&#34;&gt;Association Rules Algorithms&lt;/h3&gt;
&lt;h4 id=&#34;naïve-algorithm&#34;&gt;Naïve Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Read file once, counting in main memory the occurrences of each pair
&lt;ul&gt;
&lt;li&gt;From each basket of n items, generate its n (n -1)/2 pairs by two nested loops&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fails if (#items)^2 exceeds main memory&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-priori-algorithm&#34;&gt;A-Priori Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A two-pass approach called a-priori limits the need for main memory&lt;/li&gt;
&lt;li&gt;Key idea: monotonicity
&lt;ul&gt;
&lt;li&gt;If a set of items appears at least s times, so does every subset&lt;/li&gt;
&lt;li&gt;For pairs: if item i does not appear in s baskets, then no pair including i can appear in s baskets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Read baskets and count in main memory the occurrences of each item (Requires only memory proportional to #items)
&lt;ul&gt;
&lt;li&gt;Items that appear at least s times are the frequent items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Read baskets again and count in main memory only those pairs both of which were found in pass 1 to be frequent
&lt;ul&gt;
&lt;li&gt;To count number of item pairs use a hash function&lt;/li&gt;
&lt;li&gt;Requires memory proportional to square of frequent items only, plus a list of the frequent items, plus space for hashing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/APriori_Algorithm.png&#34; alt=&#34;APriori_Algorithm&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One pass for each k&lt;/li&gt;
&lt;li&gt;Needs room in main memory to count each candidate k -set&lt;/li&gt;
&lt;li&gt;For typical market-basket data and reasonable support (e.g., 1%), k = 2 requires the most memory&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pcy-algorithm&#34;&gt;PCY Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Main observation: during pass 1 of A-priori, most memory is idle&lt;/li&gt;
&lt;li&gt;Use that memory to keep additional info to improve storage during pass 2 of A-priori&lt;/li&gt;
&lt;li&gt;Passes &amp;gt; 2 are the same as in A-Priori&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Use a hash function which bucketizes item pairs, that is, maps them to integers in [1,k]&lt;/li&gt;
&lt;li&gt;Each bucket i in [1,k] is associated with a counter ci&lt;/li&gt;
&lt;li&gt;During pass 1, as we examine a basket (e.g. {m,b,d,o})
&lt;ul&gt;
&lt;li&gt;update counters of single items&lt;/li&gt;
&lt;li&gt;Generate all item pairs for that basket, hash each of them and add 1 to the corr. counter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Count all pairs {i, j } that meet the conditions for being a candidate pair
&lt;ul&gt;
&lt;li&gt;Both i and j are frequent items&lt;/li&gt;
&lt;li&gt;The pair {i, j }, hashes to a frequent bucket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ignore all pairs belonging to non-frequent buckets (do not use a counter for them)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;simple-algorithm&#34;&gt;Simple Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Take a random sample of the market baskets
&lt;ul&gt;
&lt;li&gt;give a full pass on the data and keep a basket in main memory with probability p&lt;/li&gt;
&lt;li&gt;A random sample is the best representative of a dataset&lt;/li&gt;
&lt;li&gt;Keeping only the first baskets might not contain iPhones for example&lt;/li&gt;
&lt;li&gt;If we cannot have a sample large enough then
&lt;ul&gt;
&lt;li&gt;Remove false positives with one more pass&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Run A-priori or one of its improvements in main memory, so you don’t pay for disk I/O each time you give a pass on the data
&lt;ul&gt;
&lt;li&gt;Be sure you leave enough space for counts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adjust the support threshold s accordingly&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;son-algorithm&#34;&gt;SON Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Two passes&lt;/li&gt;
&lt;li&gt;No false positives or false negatives&lt;/li&gt;
&lt;li&gt;Divide the dataset into chunks, where each chunk contains a subset of baskets&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Divide the dataset into chunks, where each chunk contains a subset of baskets&lt;/li&gt;
&lt;li&gt;Let pi such that the ith chunk contains a fraction pi of the dataset&lt;/li&gt;
&lt;li&gt;For each chunk i compute all frequent itemsets with support p i x s and store them on disk. This is the set of candidates for next pass&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Read all frequent itemsets found in the previous pass (candidates)&lt;/li&gt;
&lt;li&gt;For each of them count the number of occurrences and output only those with support at least s&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>用OKR的方式梳理自己的学习计划</title>
      <link>https://www.pseudoyu.com/en/2021/02/11/learning_plan_okr/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/02/11/learning_plan_okr/</guid>
      
        <description>&lt;h2 id=&#34;用一句话形容理想情况下自己想要达到的状态&#34;&gt;用一句话形容理想情况下，自己想要达到的状态&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;具体目标范围&lt;/strong&gt;：提升编程技术能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时间周期&lt;/strong&gt;：2个月&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;描述&lt;/strong&gt;：我想要成为一名具备过硬的编程能力的开发者，并对技术有持续学习的开放心态 &lt;em&gt;&lt;strong&gt;— 目标O&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;寻找关键词拆解状态为目标&#34;&gt;寻找关键词，拆解状态为目标&lt;/h2&gt;
&lt;h3 id=&#34;我需要提升解决的部分&#34;&gt;我需要提升解决的部分&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;过硬的编程能力&lt;/li&gt;
&lt;li&gt;持续学习的开放心态&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;想要达到的程度&#34;&gt;想要达到的程度&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;能够通过技术创造价值&lt;/li&gt;
&lt;li&gt;对技术有热爱和追求&lt;/li&gt;
&lt;li&gt;B站Up主“是落拓呀”的持续学习状态&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;制定每一个关键词目标的指标&#34;&gt;制定每一个关键词/目标的指标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;过硬的编程能力&lt;/strong&gt;：能够满足目前香港/内地区块链公司，如蚂蚁链、腾讯区块链、杭州趣链科技等目标公司的技术面试要求，并主导完成1-2个完整的项目，深入技术细节 &lt;strong&gt;— KR1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持续学习的开放心态&lt;/strong&gt;：提升对于热门区块链技术平台（Ethereum、Hyperledger）与Java后端技术的理解与学习，并完成多篇原创技术博客 &lt;strong&gt;— KR2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;填充每一个关键指标的todo-list&#34;&gt;填充每一个关键指标的todo list&lt;/h2&gt;
&lt;h3 id=&#34;过硬的编程能力&#34;&gt;过硬的编程能力&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;每天按照分类与难度刷LeetCode算法题
&lt;ol&gt;
&lt;li&gt;白天刷5-10题&lt;/li&gt;
&lt;li&gt;晚上按照节奏复习之前刷过的题的思路&lt;/li&gt;
&lt;li&gt;看关于算法框架思路的书籍，完善&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;完成区块链音乐版权项目毕业设计
&lt;ol&gt;
&lt;li&gt;每天至少2小时学习Ethereum智能合约编写相关&lt;/li&gt;
&lt;li&gt;按照项目进度进行开发&lt;/li&gt;
&lt;li&gt;与导师和同学定期交流，优化项目&lt;/li&gt;
&lt;li&gt;调研市场上区块链产品，思考运营与商业化相关&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;完成开源项目RPC框架的学习
&lt;ol&gt;
&lt;li&gt;每天至少1小时学习课程并实践代码&lt;/li&gt;
&lt;li&gt;撰写关于RPC框架原理和核心知识点的技术博文&lt;/li&gt;
&lt;li&gt;将此作为亮点项目，添加至简历并与同学进行模拟面试&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;针对GitHub与一些书籍的面试经验，学习掌握计算机基础面试知识，和同学每周模拟面试，现场写算法题并讲解，找到问题并提出建议&lt;/li&gt;
&lt;li&gt;参加春招面试，积攒面试经验查漏补缺，总结心得&lt;/li&gt;
&lt;li&gt;和落拓学长交流区块链学习心得和路径，寻求建议&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;持续学习的开放心态&#34;&gt;持续学习的开放心态&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;完成学校COMP7408区块链与分布式账本课程（共计30学时，每周一节3小时的课程）
&lt;ol&gt;
&lt;li&gt;每周一晚上参加线下课程&lt;/li&gt;
&lt;li&gt;课程第二天花3-6小时整理当周课程的知识点与拓展部分&lt;/li&gt;
&lt;li&gt;每周2-3小时将课程中的理论部分通过代码实践&lt;/li&gt;
&lt;li&gt;每天至少3天对之前所有知识点进行复习和查漏补缺（每次30分钟左右）&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Udacity 区块链开发课程并整理笔记（共计约40学时）
&lt;ol&gt;
&lt;li&gt;每天至少2小时学习课程并实践代码&lt;/li&gt;
&lt;li&gt;每天至少3天对之前所有知识点进行复习和查漏补缺（每次30分钟左右）&lt;/li&gt;
&lt;li&gt;阶段性对课程里的项目进行详细整理，添加至简历并针对面试进行准备&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;每天学习间隙整理基础理论知识，并了解一些前沿技术和产品&lt;/li&gt;
&lt;li&gt;完成CSDN关于Spring Boot和其他框架的入门视频并整理&lt;/li&gt;
&lt;li&gt;完成Udacity关于Java开发相关框架的介绍并进行项目实践&lt;/li&gt;
&lt;li&gt;结合自己的理解与学习笔记，撰写针对特定技术的原创博客&lt;/li&gt;
&lt;li&gt;定期和目前从事区块链的同学进行交流讨论，补充项目经验至简历与面试准备&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 2 Spatial Data Management</title>
      <link>https://www.pseudoyu.com/en/2021/02/06/comp7801_topic2/</link>
      <pubDate>Sat, 06 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/02/06/comp7801_topic2/</guid>
      
        <description>&lt;h2 id=&#34;spatial-data-management&#34;&gt;Spatial Data Management&lt;/h2&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Spatial Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Location data
&lt;ul&gt;
&lt;li&gt;Check-in service&lt;/li&gt;
&lt;li&gt;Online Maps&lt;/li&gt;
&lt;li&gt;Location-based services&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Location tracking&lt;/li&gt;
&lt;li&gt;Traffic Data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spatial Databases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PostgreSQL with PostGIS&lt;/li&gt;
&lt;li&gt;Neo4J-spatial&lt;/li&gt;
&lt;li&gt;HadoopGIS&lt;/li&gt;
&lt;li&gt;Ingres&lt;/li&gt;
&lt;li&gt;GeoMesa&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spatial Data Management&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spatial Database Systems
&lt;ul&gt;
&lt;li&gt;Manage large collections of multidimensional objects (2D/3D)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A spatial object
&lt;ul&gt;
&lt;li&gt;Contains (at least) one spatial attributes that describes its location and/or geometry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A spatial relation
&lt;ul&gt;
&lt;li&gt;Is an organized collection of spatial objects of the same entity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-data&#34;&gt;Spatial Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Representation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Points (Cities in large-scale map)&lt;/li&gt;
&lt;li&gt;Extent (rivers, forest, etc.)
&lt;ul&gt;
&lt;li&gt;Vector (approximation by geometric objects)&lt;/li&gt;
&lt;li&gt;Raster (A set of pixels in the grid)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Application&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spatial data
&lt;ul&gt;
&lt;li&gt;GIS&lt;/li&gt;
&lt;li&gt;Segemented images&lt;/li&gt;
&lt;li&gt;Components of CAD constructs or VLSI circuit&lt;/li&gt;
&lt;li&gt;Stars on the sky&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial database
&lt;ul&gt;
&lt;li&gt;Users of mobile devices&lt;/li&gt;
&lt;li&gt;Geographers, life scientists&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;features-of-spatial&#34;&gt;Features of spatial&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Dimensionality
&lt;ul&gt;
&lt;li&gt;There is no total ordering of objects in the multidimensional space that preserves spatial proximity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Complex spatial extent&lt;/li&gt;
&lt;li&gt;No standard definitions of spatial operations and algebra&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Relationa indexes (like B+ trees) and query processing methods (sort-merge join, hash-join) are not applicable&lt;/p&gt;
&lt;p&gt;Spatial access methods (SAMs) for spatial data have to be defined&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Index spatial objects&lt;/li&gt;
&lt;li&gt;Facilitate efficient processing of simple spatial query types (e.g. range queries)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-relationships&#34;&gt;Spatial Relationships&lt;/h3&gt;
&lt;p&gt;A spatial relationship associates two objects according to their relative location and extent in space. Sometimes also called &amp;ldquo;spatial relations&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Can refer to a database relation which stores spatial objects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topological relationships&lt;/li&gt;
&lt;li&gt;Distance relationships&lt;/li&gt;
&lt;li&gt;Directional relationships&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;topological-relationships&#34;&gt;Topological relationships&lt;/h4&gt;
&lt;p&gt;Each object is characterized by the space it occupies in the universe (A set of pixels).&lt;/p&gt;
&lt;p&gt;A set of relationsips between their boundaries and interiors&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boundary&lt;/li&gt;
&lt;li&gt;Interior (some may not have, points, line segments, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A hierarchy of relations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intersect (or overlaps)
&lt;ul&gt;
&lt;li&gt;equals&lt;/li&gt;
&lt;li&gt;inside&lt;/li&gt;
&lt;li&gt;contains&lt;/li&gt;
&lt;li&gt;adjacent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;disjoint&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distance-relationships&#34;&gt;Distance relationships&lt;/h4&gt;
&lt;p&gt;Associate two objects based on their geometric (Euclidean distance), and it&amp;rsquo;s usually abstracted into human mind.&lt;/p&gt;
&lt;p&gt;Distance relationships are expressed either explicitly or by some abstract distance class.&lt;/p&gt;
&lt;h4 id=&#34;directional-relationships&#34;&gt;Directional relationships&lt;/h4&gt;
&lt;p&gt;Associates two object based on their relative orientation according to a global reference system.&lt;/p&gt;
&lt;h3 id=&#34;spatial-queries&#34;&gt;Spatial Queries&lt;/h3&gt;
&lt;p&gt;Applied on one (or more) spatial relations to retrieve objects staisfying some spatial relationships&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nearest neighbor query&lt;/li&gt;
&lt;li&gt;Spatial join&lt;/li&gt;
&lt;li&gt;Range query
&lt;ul&gt;
&lt;li&gt;Spatial selction&lt;/li&gt;
&lt;li&gt;window query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-query-processing&#34;&gt;Spatial Query Processing&lt;/h3&gt;
&lt;p&gt;Evaluating spatial relationships on geometric data is slow.&lt;/p&gt;
&lt;p&gt;A spatial object is approximated by its minimum bounding rectangle (MBR)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Filter: The MBR is tested against the query predicate&lt;/li&gt;
&lt;li&gt;Refinement: The exact geometry of objects that pass the filter step is tested for qualification&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;spatial-access-methods-sams&#34;&gt;Spatial Access Methods (SAMs)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The problem of indexing spatial data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No dynamic access method with good theoretical worst-case guarantees for range queries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SAMs aim at the minimization of the expected cost.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Indexing of multidimensional points&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;point-access-methods&#34;&gt;Point access methods&lt;/h4&gt;
&lt;p&gt;Divide the apce into disjoint partitions and group the points according to the regions they belong&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/point_access_methods.png&#34; alt=&#34;point_access_methods&#34;&gt;&lt;/p&gt;
&lt;p&gt;Not effective for extended objects (may need to be clipped into several parts which leads to data redundancy and affects performance negatively).&lt;/p&gt;
&lt;p&gt;Object clipping can be avoided if we allow the regions of object to overlap.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/object_clipping.png&#34; alt=&#34;object_clipping&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Optimization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group the objects below into 3 groups of 4 objects each such that the MBRs of the groups have the minimum overlap&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overlap_region.png&#34; alt=&#34;overlap_region&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard optimization problem&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-r-tree&#34;&gt;The R-tree&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Concept&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group object MBRs to disk blocks hierarchically&lt;/li&gt;
&lt;li&gt;Each group of object is a leaf of the tree&lt;/li&gt;
&lt;li&gt;The MBRs of the leaf nodes are grouped to form nodes at the next level&lt;/li&gt;
&lt;li&gt;Grouping is recursively applied at each level until a single group (the root) is formed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_Tree_example.png&#34; alt=&#34;R_Tree_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Elements&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leaf node entries: &amp;lt;MBR, object-id&amp;gt;, all leaves are in same level&lt;/li&gt;
&lt;li&gt;Non-leaf node entries: &amp;lt;MBR, ptr&amp;gt;, pointing to entries&lt;/li&gt;
&lt;li&gt;Root: have at least two children&lt;/li&gt;
&lt;li&gt;Non-root node parameters
&lt;ul&gt;
&lt;li&gt;M&lt;/li&gt;
&lt;li&gt;m&lt;/li&gt;
&lt;li&gt;m &amp;lt;= M/2&lt;/li&gt;
&lt;li&gt;Usually m = 0.4 M&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;range-searching-using-an-r-tree&#34;&gt;Range searching using an R-tree&lt;/h4&gt;
&lt;p&gt;Range_query (query W, R-tree node n)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If n is not a leaf node
&lt;ul&gt;
&lt;li&gt;For each index entry e in n such that e.MBR intersects W
&lt;ul&gt;
&lt;li&gt;Visit node n&#39; pointed  by e.ptr&lt;/li&gt;
&lt;li&gt;Range_query (W, n&#39;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If n is a leaf
&lt;ul&gt;
&lt;li&gt;For each index entry e in n such that e.MBR intersects W
&lt;ul&gt;
&lt;li&gt;Visit object o pointed by e.object-id&lt;/li&gt;
&lt;li&gt;Test range query against exact geometry of o; If o intersects W, report o&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;May follow multiple paths during search&lt;/li&gt;
&lt;li&gt;Different search predicates are used for different realtionships with W&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/range_search.png&#34; alt=&#34;range_search&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;construction-of-the-r-tree&#34;&gt;Construction of the R-tree&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Dynamically constructed/maintained&lt;/li&gt;
&lt;li&gt;Insertions/deletions interleave with search operations
&lt;ul&gt;
&lt;li&gt;Insertion similiar to B+ Tree, but with special optimization algorithms
&lt;ul&gt;
&lt;li&gt;Choose the path where a new MBR is inserted&lt;/li&gt;
&lt;li&gt;Split overflow nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Underflows in deletions
&lt;ul&gt;
&lt;li&gt;Deleting the underflow leaf node&lt;/li&gt;
&lt;li&gt;Re-insert the remaining entries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;r-tree&#34;&gt;R*-tree&lt;/h3&gt;
&lt;p&gt;Only different in the insertion algorithm (compared to R-tree), aiming at constructing a tree of high quality&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A good tree&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nodes with small MBRs&lt;/li&gt;
&lt;li&gt;nodes with small overlap&lt;/li&gt;
&lt;li&gt;nodes that look like squares&lt;/li&gt;
&lt;li&gt;nodes as full as possible&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;optimization&#34;&gt;Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Minimize the area covered by an index rectangle (small area means small dead space)&lt;/li&gt;
&lt;li&gt;Minimize overlap between node MBRs (Minimizes the number of traversed paths)&lt;/li&gt;
&lt;li&gt;Minimize the margins of node MBRs (Square-like nodes, smaller number of intersections for a random query, better structure)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/margin_minimization.png&#34; alt=&#34;margin_minimization&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimize the storage utilization
&lt;ul&gt;
&lt;li&gt;Nodes in tree should be filled as much as possible&lt;/li&gt;
&lt;li&gt;Minimizes tree height and potentially decreases dead space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Insertion heuristics (Select the path)
&lt;ul&gt;
&lt;li&gt;Least MBR enlargement after insertion
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/MBR_enlargement.png&#34; alt=&#34;MBR_enlargement&#34;&gt;&lt;/li&gt;
&lt;li&gt;Least MBR overlap after insertion
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/MBR_overlap.png&#34; alt=&#34;MBR_overlap&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node-spliting&#34;&gt;Node Spliting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Determine the split axis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each axis (i.e. x and y axis)
&lt;ul&gt;
&lt;li&gt;Sum=0;&lt;/li&gt;
&lt;li&gt;sort entries by the lower value, then by upper value&lt;/li&gt;
&lt;li&gt;for each sorting (e.g. lower value)
&lt;ul&gt;
&lt;li&gt;for k=m to M+1-m&lt;/li&gt;
&lt;li&gt;place first k entries in group A, and the remaining ones in group B&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Sum = Sum + margin(A) + margin(B)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Choose axis with the minimum Sum&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Distribute entries along axis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Along the split axis, choose the distribution with minimum overlap&lt;/li&gt;
&lt;li&gt;If there are multiple groupings with minimal overlap choose &amp;lt;A,B&amp;gt; such that area(A)+area(B) is minimized&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;insertion-heuristics-forced-reinsert&#34;&gt;Insertion heuristics: Forced Reinsert&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/forced_reinsert.png&#34; alt=&#34;forced_reinsert&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forced Reinsert
&lt;ul&gt;
&lt;li&gt;When R*-tree node n overflows, instead of splitting n immediately, try to see if some entries in n could possibly fit better in another node&lt;/li&gt;
&lt;li&gt;Find the 30% furthest entries from the center of the group&lt;/li&gt;
&lt;li&gt;Re-insert them to the tree (not to be repeated if another overflow occurs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slightly more expensive, but better tree structure:
&lt;ul&gt;
&lt;li&gt;less overlap&lt;/li&gt;
&lt;li&gt;more space is utilized (more full nodes)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bulk-loading-r-trees&#34;&gt;Bulk-loading R-trees&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/bulk_loading_R_tree.png&#34; alt=&#34;bulk_loading_R_tree&#34;&gt;&lt;/p&gt;
&lt;p&gt;Given a static set S of rectangles, build an R-tree that indexes S.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Method 1: iteratively insert rectangles into an initially empty tree
&lt;ul&gt;
&lt;li&gt;Feature
&lt;ul&gt;
&lt;li&gt;tree reorganization is slow&lt;/li&gt;
&lt;li&gt;tree nodes are not as full as possible: more space occupied for the tree&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 2 (x-sorting): bulk-load the rectangles into the tree using some fast (sort or hash-based) process
&lt;ul&gt;
&lt;li&gt;sort rectangles using the x-coordinate of their center&lt;/li&gt;
&lt;li&gt;pack M consecutive rectangles in leaf nodes&lt;/li&gt;
&lt;li&gt;build tree bottom-up&lt;/li&gt;
&lt;li&gt;Feature
&lt;ul&gt;
&lt;li&gt;R-tree is built fast&lt;/li&gt;
&lt;li&gt;good space utilization&lt;/li&gt;
&lt;li&gt;results in leaf nodes that are have long stripes as MBRs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 3 (Hilbert sorting): use a space-filling curve to order the rectangles
&lt;ul&gt;
&lt;li&gt;much better structure, but still the nodes have large overlap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 4 (sort-tile-recursive): Sort using one axis first and then groups of sqrt(n) rectangles using the other axis
&lt;ul&gt;
&lt;li&gt;Usually the best structure compared to other bulk-loading methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;k-nearest-neighbor-search&#34;&gt;K Nearest Neighbor Search&lt;/h3&gt;
&lt;p&gt;Given a spatial relation R, a query object q, and a number k &amp;lt;|R|, find the k-nearest neighbors of q in R.&lt;/p&gt;
&lt;p&gt;We can have more than one k-NN sets (with multiple possible equidistant furthest points in them).&lt;/p&gt;
&lt;h4 id=&#34;distance-measures-and-mbrs&#34;&gt;Distance measures and MBRs&lt;/h4&gt;
&lt;p&gt;Distances between MBRs lower-bound the distances between the corresponding objects&lt;/p&gt;
&lt;p&gt;dist(MBR(oi),MBR(oj)) ≤ dist(oi, oj)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/distance_mbr.png&#34; alt=&#34;distance_mbr&#34;&gt;&lt;/p&gt;
&lt;p&gt;Distances between R-tree node MBRs lower-bound the distances between the entries in them&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/min_distance_mbr.png&#34; alt=&#34;min_distance_mbr&#34;&gt;&lt;/p&gt;
&lt;p&gt;The distance between a query object q and an R-tree node MBR lower-bounds the distances between q and the objects indexed under this node&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/q_distance_mbr.png&#34; alt=&#34;q_distance_mbr&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;depth-first-nn-search-using-an-r-tree&#34;&gt;Depth-first NN search using an R-tree&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Start from the root and visit the node nearest to q&lt;/li&gt;
&lt;li&gt;Continue recursively, until a leaf node nl is visited.&lt;/li&gt;
&lt;li&gt;Find the NN of q in nl.&lt;/li&gt;
&lt;li&gt;Continue visiting other nodes after backtracking as long there are nodes closer to q than the current NN.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/DFNNS_code.png&#34; alt=&#34;DFNNS_code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large space can be pruned by avoiding visiting R-tree nodes and their sub-trees&lt;/li&gt;
&lt;li&gt;Should order the entries of a node in increasing distance from q to maximize potential for a good NN found fast&lt;/li&gt;
&lt;li&gt;Can be easily adapted for k-NN search&lt;/li&gt;
&lt;li&gt;Requires at most one tree path to be currently in memory – good for small memory buffers
&lt;ul&gt;
&lt;li&gt;Characteristic of all depth-first search algorithms&lt;/li&gt;
&lt;li&gt;Recall that the range search algorithm is also DF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;However, does not visit the least possible number of nodes&lt;/li&gt;
&lt;li&gt;Also, not incremental – more on this later…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/DFNNS_example.png&#34; alt=&#34;DFNNS_example&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. visit root
dist(q,M1)&amp;lt;dist(q,oNN)
must visit node M1

2. visit M1
dist(q,m1)&amp;lt;dist(q,oNN)
must visit node m1

3. visit m1
check a,b,c
found new NN:
oNN = a, dist(q,oNN) = sqrt(5)

4. backtrack to M1
check m2dist(q,m2) = 3 &amp;gt;= sqrt(5):
No need to visit node m2
check m3dist(q,m3) = sqrt(5) &amp;gt;= sqrt(5):
No need to visit node m3

5. backtrack to root
check M2dist(q,M2) = sqrt(2) &amp;lt; sqrt(5):
must visit node M2

6. visit M2
check m4dist(q,m4) = sqrt(2) &amp;lt; sqrt(5):
must visit node m4

7. visit m4
check i,j,k
found new NN:
oNN = k, dist(q,oNN) = sqrt(2)

8. backtrack to M2
check m5dist(q,m5) &amp;gt;= sqrt(2):
No need to visit node m5
check m6dist(q,m6) &amp;gt;= sqrt(2):
No need to visit node m6

9. backtrack to root
check M3dist(q,M3) &amp;gt;= sqrt(2):
No need to visit node M3

10. backtrack from root
Algorithm terminates
oNN =k with dist(q,oNN)= sqrt(2) found
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;best-first-nn-search&#34;&gt;Best-first NN search&lt;/h4&gt;
&lt;p&gt;Put all entries in a priority queue and always “open” the closest one, independently of the node that contains it.&lt;/p&gt;
&lt;p&gt;Thus the best (i.e., closest) entry is always visited first.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A more efficient algorithm (given large enough memory)&lt;/li&gt;
&lt;li&gt;Optimal in the number of R-tree nodes visited for a given query q&lt;/li&gt;
&lt;li&gt;Uses a priority queue to organize seen entries and prioritize the next node to be visited&lt;/li&gt;
&lt;li&gt;Adaptable for k-NN search and incremental NN search&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/BFNNS_code.png&#34; alt=&#34;BFNNS_code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the previous example, we have visited fewer nodes compared to DF-NN algorithm
&lt;ul&gt;
&lt;li&gt;Only nodes whose MBR intersect the disk centered at q with radius the real NN distance are visited (see if you can you prove this)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The algorithm can be adapted for incremental NN search
&lt;ul&gt;
&lt;li&gt;After having found the NN can we easily (incrementally) find the next NN without starting search from the beginning?
&lt;ul&gt;
&lt;li&gt;put objects on the heap&lt;/li&gt;
&lt;li&gt;never prune, but wait until an object comes out&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The algorithm can be used for k-NN search
&lt;ul&gt;
&lt;li&gt;use a second heap to organize the NN found so far (same can be done for DF-NN)&lt;/li&gt;
&lt;li&gt;no need if we just use the inc. version of the algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;… but: The heap can grow very large until the algorithm terminates&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/BFNNS_example.png&#34; alt=&#34;BFNNS_example&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Step 1: put all entries of root on heap Q
Q = M1(1), M2(sqrt(2)), M3(sqrt(8))

Step 2: get closest entry (top element of Q):
M1(1). Visit node M1. Put all entries of 
visited node on heap Q
Q = M2(sqrt(2)), m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3)

Step 3: get closest entry (top element of Q):
M2(sqrt(2)). Visit node M2. Put all entries of 
visited node on heap Q
Q =m4(sqrt(2)), m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3), 	m5(sqrt(13)), m5(sqrt(17))

Step 4: get closest entry (top element of Q):
m4(sqrt(2)). Visit node m4. m4 is a leaf node, so update NN if some object in m4 is closer than the current NN:
oNN = k, dist(q,oNN)= sqrt(2)
Q =m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3), 	m5(sqrt(13)), m5(sqrt(17))

Step 5: get closest entry (top element of Q):
m1(sqrt(5)). Since sqrt(5) &amp;gt;= dist(q,oNN)= sqrt(2), search stops and oNN is returned as the NN of q
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;incremental NN search&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example 1: find the nearest large city (&amp;gt;10,000 residents) to my current position
&lt;ul&gt;
&lt;li&gt;Solution 1:
&lt;ul&gt;
&lt;li&gt;find all large cities&lt;/li&gt;
&lt;li&gt;apply NN search on the result&lt;/li&gt;
&lt;li&gt;could be slow if many such cities&lt;/li&gt;
&lt;li&gt;also R-tree may not be available for large cities only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution 2:
&lt;ul&gt;
&lt;li&gt;incrementally find NN and check if the large city requirement is satisfied; if not get the next NN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example 2: find the nearest hotel; see if you like it; if not get the next one; see if you like it; …&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-joins&#34;&gt;Spatial Joins&lt;/h3&gt;
&lt;p&gt;Most algorithms focus on the efficient processing of the filter step.&lt;/p&gt;
&lt;p&gt;Most spatial predicates on actual objects reduce to intersection of MBRs in the filter step. Thus all algorithms consider mainly the intersect predicate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Types&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intersection joins&lt;/li&gt;
&lt;li&gt;Semi-join: Find the cities that intersect a river&lt;/li&gt;
&lt;li&gt;Similarity join: Find pairs of hotels, restaurants close to each other (with distance smaller than 100m)&lt;/li&gt;
&lt;li&gt;Closest pairs: Find the closest pair of hotels, restaurants&lt;/li&gt;
&lt;li&gt;All-NN: For each hotel find the nearest restaurant&lt;/li&gt;
&lt;li&gt;Iceberg distance join: Find hotels close to at least 10 restaurants&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Three categories of spatial join algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both inputs are indexed (e.g., synchronized tree traversal)&lt;/li&gt;
&lt;li&gt;One input is indexed (e.g., indexed nested loops)&lt;/li&gt;
&lt;li&gt;Neither input is indexed (e.g., spatial hash join)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;r-tree-intersection-join&#34;&gt;R-tree (Intersection) Join&lt;/h4&gt;
&lt;p&gt;Applies on two R-trees of spatial relations R and S&lt;/p&gt;
&lt;p&gt;Node MBRs at the high level of the trees can prune object combinations to be checked&lt;/p&gt;
&lt;p&gt;This pseudo-code version assumes that the trees have same height&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_code.png&#34; alt=&#34;R_tree_join_code&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run for root(RA), root(RB)&lt;/li&gt;
&lt;li&gt;for every intersecting pair there (e.g., A1, B1) run recursively for pointed nodes&lt;/li&gt;
&lt;li&gt;intersecting pairs of leaf nodes are qualifying object MBR pairs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_example.png&#34; alt=&#34;R_tree_join_example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;optimization-1&#34;&gt;Optimization&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;space restriction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If an entry in n1 does not intersect the MBR of n2 it may not intersect any entry in n2.&lt;/li&gt;
&lt;li&gt;Perform two scans in n1 and n2 to prune such entries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_optimization.png&#34; alt=&#34;R_tree_join_optimization&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;plane sweep&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sort entries in both nodes on their lower-x value (lower bound of x-projection)&lt;/li&gt;
&lt;li&gt;Sweep a line to find fast all entry pairs that qualify x-intersection
&lt;ul&gt;
&lt;li&gt;for each of them check y-intersection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_optimization2.png&#34; alt=&#34;R_tree_join_optimization2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worst-case sub-optimal. But very effective on the average&lt;/li&gt;
&lt;li&gt;Worst-case optimal algorithms require advanced data structures for y-intersection. Large hidden constants, thus high cost for this problem size&lt;/li&gt;
&lt;li&gt;Can be used with other spatial join algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;R-tree join&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The most efficient algorithm (assuming that the relations are indexed)&lt;/li&gt;
&lt;li&gt;Cannot be used for non-indexed inputs&lt;/li&gt;
&lt;li&gt;unless we build on-the-fly R-trees&lt;/li&gt;
&lt;li&gt;Comes with some I/O scheduling techniques for minimizing the page accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;joining-non-indexed-inputs&#34;&gt;Joining non-indexed inputs&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Spatial hash join&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/spatial_hash_join.png&#34; alt=&#34;spatial_hash_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Partition based spatial merge join&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/spatial_merge_join.png&#34; alt=&#34;spatial_merge_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Indexed Nested Loops&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexed_nest_loops.png&#34; alt=&#34;indexed_nest_loops&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Seeded tree join and Bulk-load and Match build an on-the-fly R-tree&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/seeded_tree_join.png&#34; alt=&#34;seeded_tree_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slot-index spatial join applies hash-join using the entries of a high R-tree level&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/slot_index_spatial_join.png&#34; alt=&#34;slot_index_spatial_join&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-refinement-step&#34;&gt;The refinement step&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_step.png&#34; alt=&#34;refinement_step&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: find MBR pairs that intersect&lt;/li&gt;
&lt;li&gt;Step 2: compare some more detailed approximations to make conclusions (a.k.a. geometric filter)
&lt;ul&gt;
&lt;li&gt;conservative approximations
&lt;ul&gt;
&lt;li&gt;e.g., convex hull&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;progressive approximation
&lt;ul&gt;
&lt;li&gt;e.g., maximum enclosed rectangle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_detailed_approximations.png&#34; alt=&#34;refinement_detailed_approximations&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: if still join predicate inconclusive, perform expensive refinement step
&lt;ul&gt;
&lt;li&gt;can be processed by computational geometry algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-step processing (R-tree join as example)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_multi_step.png&#34; alt=&#34;refinement_multi_step&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链隐私问题概述</title>
      <link>https://www.pseudoyu.com/en/2021/01/30/blockchain_note_privacy/</link>
      <pubDate>Sat, 30 Jan 2021 05:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/30/blockchain_note_privacy/</guid>
      
        <description>&lt;h2 id=&#34;区块链隐私问题概述&#34;&gt;区块链隐私问题概述&lt;/h2&gt;
&lt;h3 id=&#34;区块链透明性&#34;&gt;区块链透明性&lt;/h3&gt;
&lt;p&gt;所有人都能看到交易细节/历史记录&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用场景：供应链 （食品、药品、酒&amp;hellip;）&lt;/li&gt;
&lt;li&gt;隐私风险：个人信息（账户余额、交易信息&amp;hellip;）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;隐私分类&#34;&gt;隐私分类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;发送方匿名&lt;/li&gt;
&lt;li&gt;交易匿名/机密&lt;/li&gt;
&lt;li&gt;接收方匿名&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;比特币隐私建议&#34;&gt;比特币隐私建议&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;不要重复使用地址&lt;/li&gt;
&lt;li&gt;在同一比交易中不要将多个输出（UTXO）作为输入&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;隐私保护技术&#34;&gt;隐私保护技术&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;混币&lt;/li&gt;
&lt;li&gt;匿名签名
&lt;ul&gt;
&lt;li&gt;环签（小组中每一个人都可以签名，但不知道被谁签名）&lt;/li&gt;
&lt;li&gt;可链接环签名（依然不知道被谁签名，但是可以知道被同一个签名者签，可检测双花）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;零知识证明 （在不让其他人知道额外信息的前提下证明正确性）&lt;/li&gt;
&lt;li&gt;加密
&lt;ul&gt;
&lt;li&gt;同态加密（以太坊智能合约在区块链存储上提供了同态加密）&lt;/li&gt;
&lt;li&gt;基于属性的加密（Attribute-based encryption(ABE)）
&lt;ul&gt;
&lt;li&gt;每个用户有一些属性（角色）&lt;/li&gt;
&lt;li&gt;权限控制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可信执行环境（Trusted execution environment(TEE)）
&lt;ul&gt;
&lt;li&gt;安全硬件（如Intel SGX）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;基于隐私保护的交易平台&#34;&gt;基于隐私保护的交易平台&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_privacy_market_place.png&#34; alt=&#34;blockchain_privacy_market_place&#34;&gt;&lt;/p&gt;
&lt;p&gt;现有平台不支持对于加密数据的计算（区块链多方计算）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加密搜索&lt;/li&gt;
&lt;li&gt;统计计算/数据挖掘&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 1b Database Indexing</title>
      <link>https://www.pseudoyu.com/en/2021/01/30/comp7801_topic1b/</link>
      <pubDate>Sat, 30 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/30/comp7801_topic1b/</guid>
      
        <description>&lt;h2 id=&#34;database-indexing&#34;&gt;Database Indexing&lt;/h2&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Indexing mechanisms used to speed up access to desired data&lt;/li&gt;
&lt;li&gt;Search Key
&lt;ul&gt;
&lt;li&gt;An attribute or a set of attributes used to look up records in a file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An index file consists of records (called index entries) of the form &lt;code&gt;search key - pointer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Index files are typically much smaller than the original file&lt;/li&gt;
&lt;li&gt;Two basic kinds of indices
&lt;ul&gt;
&lt;li&gt;Ordered indices:  search keys are stored in sorted order&lt;/li&gt;
&lt;li&gt;Hash indices:  search keys are distributed across &amp;ldquo;buckets&amp;rdquo; using a &amp;ldquo;hash function&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexing_example.png&#34; alt=&#34;indexing_example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;good-index&#34;&gt;Good Index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Index quality is evaluated by several factors
&lt;ul&gt;
&lt;li&gt;Access types supported by the index efficiently
&lt;ul&gt;
&lt;li&gt;records with a specified value in the attribute (equality query)&lt;/li&gt;
&lt;li&gt;or records with an attribute value falling in a specified range of values (range query)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Access time – query response time&lt;/li&gt;
&lt;li&gt;Insertion time – data record insertion time&lt;/li&gt;
&lt;li&gt;Deletion time – data record deletion time&lt;/li&gt;
&lt;li&gt;Space overhead – size of the index file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;classification-of-indexes&#34;&gt;Classification of Indexes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Primary index
&lt;ul&gt;
&lt;li&gt;In a sequentially ordered file, the index whose search key specifies the sequential order of the file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary index
&lt;ul&gt;
&lt;li&gt;an index whose search key specifies an order different from the sequential order of the file&lt;/li&gt;
&lt;li&gt;Also called non-clustered index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/classification_of_indexing.png&#34; alt=&#34;classification_of_indexing&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dense index
&lt;ul&gt;
&lt;li&gt;Index record appears for every search-key value in the file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sparse Index
&lt;ul&gt;
&lt;li&gt;Contains index records for only some search-key values&lt;/li&gt;
&lt;li&gt;Applicable when records are sequentially ordered on search-key&lt;/li&gt;
&lt;li&gt;Less space and less maintenance overhead for insertions and deletions&lt;/li&gt;
&lt;li&gt;Generally slower than dense index for locating records&lt;/li&gt;
&lt;li&gt;Good tradeoff: sparse index with an index entry for every block in file, corresponding to least search-key value in the block&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/classification_of_indexing_2.png&#34; alt=&#34;classification_of_indexing_2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;primary-and-secondary-indices&#34;&gt;Primary and Secondary Indices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Secondary indices have to be dense&lt;/li&gt;
&lt;li&gt;Indices offer substantial benefits when searching for records
&lt;ul&gt;
&lt;li&gt;Index is much smaller than relation file (cheap scan)&lt;/li&gt;
&lt;li&gt;Index can be ordered (fast search)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;When a file is modified, every index on the file must be updated
&lt;ul&gt;
&lt;li&gt;Updating indices imposes overhead on database modification&lt;/li&gt;
&lt;li&gt;Indexes should be used with care&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential scan using primary index is efficient, but a sequential scan using a secondary index is expensive
&lt;ul&gt;
&lt;li&gt;Each record access may fetch a new block from disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multilevel-index&#34;&gt;Multilevel Index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If index does not fit in memory, access becomes expensive&lt;/li&gt;
&lt;li&gt;To reduce number of disk accesses to index records, treat 1st level of index kept on disk as a sequential file and construct a sparse index on it
&lt;ul&gt;
&lt;li&gt;outer index – a sparse index on 1st-level index file&lt;/li&gt;
&lt;li&gt;inner index – the 1st-level index file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If even outer index is too large to fit in main memory, yet another level of index can be created, and so on&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/multilevel_index_example.png&#34; alt=&#34;multilevel_index_example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;b-tree-index-files&#34;&gt;B+-Tree Index Files&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A dynamic, multi-level index&lt;/li&gt;
&lt;li&gt;Advantage
&lt;ul&gt;
&lt;li&gt;automatically reorganizes itself with small local changes, in the face of insertions and deletions&lt;/li&gt;
&lt;li&gt;Reorganization of entire file is not required to maintain performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disadvantage of B+-trees
&lt;ul&gt;
&lt;li&gt;Extra insertion and deletion overhead, space overhead&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Advantages of B+-trees outweigh disadvantages, and they are used extensively&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;basic-properties&#34;&gt;Basic Properties&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Disk-based tree structure
&lt;ul&gt;
&lt;li&gt;every node of the tree is a block and has an address (block-id) on the disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiway tree
&lt;ul&gt;
&lt;li&gt;each node has multiple children (between n/2 and n, where n/2 is the order or degree of the tree)&lt;/li&gt;
&lt;li&gt;Therefore, at least 50% of the space in a node is guaranteed to be occupied (this rule may not apply to tree root)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Balanced tree
&lt;ul&gt;
&lt;li&gt;all paths from the root to a leaf have the same length&lt;/li&gt;
&lt;li&gt;guarantees good search performance (to be seen later)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disjoint partition of attribute domain into ranges
&lt;ul&gt;
&lt;li&gt;each sub-tree indexes a range in the attribute domain&lt;/li&gt;
&lt;li&gt;the entries of a directory node define the separators between domain intervals&lt;/li&gt;
&lt;li&gt;leaf nodes store index entries and pointers to the relation file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Example.png&#34; alt=&#34;B_Plus_Tree_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;non-leaf-nodes-in-b-trees&#34;&gt;Non-Leaf Nodes in B+-Trees&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Each non-leaf node contains up to n-1 search key values and up to n pointers&lt;/li&gt;
&lt;li&gt;All non-leaf nodes (except root) contain at least n/2 pointers (n/2 is sometimes called the minimum fan-out or degree)&lt;/li&gt;
&lt;li&gt;Non leaf nodes form a multi-level sparse index on the leaf nodes.  For a non-leaf node with m pointers
&lt;ul&gt;
&lt;li&gt;All the search-keys in the subtree to which P1 points are less than K1&lt;/li&gt;
&lt;li&gt;For 2 &amp;lt;= i &amp;lt;= n – 1, all the search-keys in the subtree to which Pi points have values greater than or equal to Ki–1 and smaller than Km–1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Non_Leaf_Node.png&#34; alt=&#34;B_Plus_Tree_Non_Leaf_Node&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;leaf-node-in-a-b-tree&#34;&gt;Leaf Node in a B+-Tree&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Contains between (n-1)/2 and n-1 entries&lt;/li&gt;
&lt;li&gt;Each index entry is a search key value + a record-id&lt;/li&gt;
&lt;li&gt;If Li, Lj are leaf nodes and i &amp;lt; j, Li’s search-key values are all smaller than Lj’s search-key values&lt;/li&gt;
&lt;li&gt;Each leaf node is linked with a pointer to the next node&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;observations&#34;&gt;Observations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Since the inter-node connections are done by pointers, &amp;ldquo;logically&amp;rdquo; close blocks need not be “physically” close
&lt;ul&gt;
&lt;li&gt;Nodes of the tree are dynamically created/deleted, so we cannot guarantee physical closeness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The non-leaf levels of the B+-tree form a hierarchy of sparse indices&lt;/li&gt;
&lt;li&gt;The B+-tree contains a relatively small number of levels (logarithmic in the size of the main file), thus searches can be conducted efficiently&lt;/li&gt;
&lt;li&gt;Insertions and deletions to the main file can be handled efficiently (in logarithmic time)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;queries&#34;&gt;Queries&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Find all records with a search-key value of k&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start with the root node
&lt;ul&gt;
&lt;li&gt;Examine the node for the smallest search-key value &amp;gt; k&lt;/li&gt;
&lt;li&gt;If such a value exists, assume it is Ki.  Then follow Pi to the child node. (E.g. P2 is for keys in  K1 &amp;lt;= Keys &amp;lt; K2 )&lt;/li&gt;
&lt;li&gt;Otherwise k &amp;gt;= Kn–1, where there are n pointers in the node.  Then follow Pn to the child node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the node reached by following the pointer above is not a leaf node, repeat the above procedure on the node, and follow the corresponding pointer&lt;/li&gt;
&lt;li&gt;Eventually reach a leaf node.  If for some i, key Ki = k  follow pointer Pi  to the desired record.  Else no record with search-key value k exists&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In processing a query, a path is traversed in the tree from the root to some leaf node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If there are K search-key values in the file, the path is not longer than log(n/2)(K). (The degree of a node is no less than n/2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A node has generally the same size of a disk block, typically 4 kilobytes, and n is typically around 100 (40 bytes per index entry)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With 1 million search key values and n/2 = 50, at most log50(1,000,000) = 4 nodes are accessed in a lookup&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Contrast this with a balanced binary tree with 1 million search key values — around 20 nodes are accessed in a lookup&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(log2(1,000,000) ~= 20)&lt;/li&gt;
&lt;li&gt;above difference is significant since every node access may need a disk I/O, costing around 10 milliseconds!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similar result for a binary search of an ordered sequential file&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;range-queries&#34;&gt;Range Queries&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find all records with a search-key value between k and m (k&amp;lt;m)
&lt;ul&gt;
&lt;li&gt;Start with the root node
&lt;ul&gt;
&lt;li&gt;Examine the node for the smallest search-key value &amp;gt; k&lt;/li&gt;
&lt;li&gt;If such a value exists, assume it is Kj
&lt;ul&gt;
&lt;li&gt;Then follow Pi to the child node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Otherwise k &amp;gt;= Kn–1, where there are n pointers in the node
&lt;ul&gt;
&lt;li&gt;Then follow Pn to the child node.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the node reached by following the pointer above is not a leaf node, repeat the above procedure on the node, and follow the corresponding pointer&lt;/li&gt;
&lt;li&gt;Eventually reach a leaf node.  If for some i, k &amp;lt;= Ki &amp;lt;= m follow pointer Pi  to the desired record. Continue with next entry Ki+1, while Ki+1 &amp;lt;= m. If at end of leaf node follow pointer to next node, until Ki &amp;gt;m or end of index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Range_Query.png&#34; alt=&#34;B_Plus_Tree_Range_Query&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;insertion&#34;&gt;Insertion&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the leaf node in which the search-key value to be inserted  would appear&lt;/li&gt;
&lt;li&gt;If the search-key value is already there in the leaf node, record is added to file and if necessary one more pointer is associated with the search key value&lt;/li&gt;
&lt;li&gt;If the search-key value is not there, then add the record to the main file. Then
&lt;ul&gt;
&lt;li&gt;If there is room in the leaf node, insert (key-value, pointer) pair in the leaf node&lt;/li&gt;
&lt;li&gt;Otherwise, split the node (along with the new (key-value, pointer) entry) as discussed in the next slides&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Insertion.png&#34; alt=&#34;B_Plus_Tree_Insertion&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;splitting&#34;&gt;Splitting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Splitting a node
&lt;ul&gt;
&lt;li&gt;take the (search-key value, pointer) pairs (including the one being inserted) in sorted order.  Place the first n/2 in the original node, and the rest in a new node&lt;/li&gt;
&lt;li&gt;let the new node be p, and let k be the least key value in p.  Insert (k,p) in the parent of the node being split. If the parent is full, split it and propagate the split further up&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The splitting of nodes proceeds upwards till a node that is not full is found.  In the worst case the root node may be split increasing the height of the tree by 1&lt;/li&gt;
&lt;li&gt;Non-leaf node splitting
&lt;ul&gt;
&lt;li&gt;Overflown node has n+1 pointers and n values&lt;/li&gt;
&lt;li&gt;Leave first n/2 key values and n/2+1 pointers to original node&lt;/li&gt;
&lt;li&gt;Move last n/2 key values and n/2+1 pointers to new node&lt;/li&gt;
&lt;li&gt;insert (middle key value, pointer to new node) to parent node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_splitting.png&#34; alt=&#34;B_Plus_Tree_splitting&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;deletion&#34;&gt;Deletion&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the record to be deleted, and remove it from the relation file&lt;/li&gt;
&lt;li&gt;Remove (search-key value, record-id) of deleted record from the leaf node of the B+-tree&lt;/li&gt;
&lt;li&gt;If the node has too few entries due to the removal, and the entries in the node and a sibling fit into a single node, then
&lt;ul&gt;
&lt;li&gt;Insert all the search-key values in the two nodes into a single node (the one on the left), and delete the other node. (Deletion triggers a merge)&lt;/li&gt;
&lt;li&gt;Delete the pair (Ki–1, Pi), where Pi is the pointer to the deleted node, from its parent, recursively using the above procedure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Otherwise, if the node has too few entries due to the removal, and the entries in the node and a sibling does not fit into a single node, then
&lt;ul&gt;
&lt;li&gt;Redistribute the pointers between the node and a sibling such that both have more than the minimum number of entries. (Deletion and rebalancing)&lt;/li&gt;
&lt;li&gt;Update the corresponding search-key value in the parent of the node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The node deletions may cascade upwards until a node which has n/2 or more pointers is found.  If the root node has only one pointer after deletion, it is deleted and the sole child becomes the root&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_deletion.png&#34; alt=&#34;B_Plus_Tree_deletion&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;static-hashing&#34;&gt;Static Hashing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A bucket is a unit of storage containing one or more records (a bucket is typically a disk block)&lt;/li&gt;
&lt;li&gt;In a hash file organization we obtain the bucket of a record directly from its search-key value using a hash function&lt;/li&gt;
&lt;li&gt;Hash function h is a function from the set of all search-key values K to the set of all bucket addresses B&lt;/li&gt;
&lt;li&gt;Hash function is used to locate records for access, insertion as well as deletion&lt;/li&gt;
&lt;li&gt;Records with different search-key values may be mapped to the same bucket; thus entire bucket has to be searched sequentially to locate a record. (Collision)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexing_hashing.png&#34; alt=&#34;indexing_hashing&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;hash-function&#34;&gt;Hash Function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Worst case has function maps all search-key values to the same bucket; this makes access time proportional to the number of search-key values in the file&lt;/li&gt;
&lt;li&gt;An ideal hash function is uniform, i.e., each bucket is assigned the same number of search-key values from the set of all possible values&lt;/li&gt;
&lt;li&gt;Ideal hash function is random, so each bucket will have the same number of records assigned to it irrespective of the actual distribution of search-key values in the file&lt;/li&gt;
&lt;li&gt;Typical hash functions perform computation on the internal binary representation of the search-key
&lt;ul&gt;
&lt;li&gt;For example, for a string search-key, the binary representations of all the characters in the string could be added and the sum modulo the number of buckets could be returned&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;handling-of-bucket-overflows&#34;&gt;Handling of Bucket Overflows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Bucket overflow can occur because of
&lt;ul&gt;
&lt;li&gt;Insufficient buckets&lt;/li&gt;
&lt;li&gt;Skew in distribution of records.  This can occur due to two reasons
&lt;ul&gt;
&lt;li&gt;multiple records have same search-key value&lt;/li&gt;
&lt;li&gt;chosen hash function produces non-uniform distribution of key values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Although the probability of bucket overflow can be reduced, it cannot be eliminated; it is handled by using overflow buckets&lt;/li&gt;
&lt;li&gt;Overflow chaining / closed hashing – the overflow buckets of a given bucket are chained together in a linked list&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hash-indices&#34;&gt;Hash Indices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Hashing can be used not only for file organization, but also for index-structure creation&lt;/li&gt;
&lt;li&gt;A hash index organizes the search keys, with their associated record pointers, into a hash file structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hash_Index.png&#34; alt=&#34;Hash_Index&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;deficiencies-of-static-hashing&#34;&gt;Deficiencies of Static Hashing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In static hashing, function h maps search-key values to a fixed set of B of bucket addresses
&lt;ul&gt;
&lt;li&gt;Databases grow with time.  If initial number of buckets is too small, performance will degrade due to too much overflows&lt;/li&gt;
&lt;li&gt;If file size at some point in the future is anticipated and number of buckets allocated accordingly, significant amount of space will be wasted initially&lt;/li&gt;
&lt;li&gt;If database shrinks, again space will be wasted&lt;/li&gt;
&lt;li&gt;One option is periodic re-organization of the file with a new hash function, but it is very expensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;These problems can be avoided by using techniques that allow the number of buckets to be modified dynamically (dynamic hashing)&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 1 Introduction</title>
      <link>https://www.pseudoyu.com/en/2021/01/28/comp7103_topic1/</link>
      <pubDate>Thu, 28 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/28/comp7103_topic1/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-1-introduction&#34;&gt;Topic 1 Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Decision-Support System (DSS)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A decision-support system (DSS) is a system that assists decision makers to make important decisions for an organization or business&lt;/li&gt;
&lt;li&gt;KDD and data mining are important components in many DSS&amp;rsquo;s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data and Knowledge&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;A collecion of facts about certain group of objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pattern
&lt;ul&gt;
&lt;li&gt;Certain characteristics of data that are frequently observed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Knowledge
&lt;ul&gt;
&lt;li&gt;Some general rules about the objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Warehouse&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An integration of various departmental databases (organization-wide data)&lt;/li&gt;
&lt;li&gt;Avoids overloading local operational databases&lt;/li&gt;
&lt;li&gt;A convenient place where KDD and data mining applications are performed&lt;/li&gt;
&lt;li&gt;Provide data mining algorithms an easy access to the required data&lt;/li&gt;
&lt;li&gt;Wrappers
&lt;ul&gt;
&lt;li&gt;Extract&lt;/li&gt;
&lt;li&gt;Transform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can also be used to support other DSS tools, e.g. On-Line Analytical Processing (OLAP) - analyze large amount of data, Online Transaction Processing (OLTP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Mining and KDD&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KDD (Knowledge Discovery in Databases)
&lt;ul&gt;
&lt;li&gt;A process of discovering useful knowledge from big collection of data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Mining
&lt;ul&gt;
&lt;li&gt;A step within the KDD process in which interesting patterns are found. Some of these patterns are then interpreted and transformed into useful knowledge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Data Mining is a step in the whole KDD process&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;KDD is a process of identifying patterns in data and deriving knowledge from them&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;valid&lt;/li&gt;
&lt;li&gt;novel&lt;/li&gt;
&lt;li&gt;potentially useful&lt;/li&gt;
&lt;li&gt;understandable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Mining&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/data_mining_system.png&#34; alt=&#34;data_mining_system&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Databases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bottom layer of the architecture&lt;/li&gt;
&lt;li&gt;Contains data sources (raw data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Traditional Database usually only provides the functions of storing and retrieving facts&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The knowledge resulting from data mining should carry certain degree of predictive ability or descriptive (explanatory) ability (or both)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Mining Engine&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applies data mining algorithms on data&lt;/li&gt;
&lt;li&gt;Provides multiple functionality&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Evaluation Module&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow users to specify what is/isn&amp;rsquo;t interesting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Knowledge Base&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Capture domain specific knowledge&lt;/li&gt;
&lt;li&gt;Stores the rules generated by data mining&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Graphical User Interface&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Presents mined patterns and rules to users in an easy-to-visualize way&lt;/li&gt;
&lt;li&gt;Provides feedback mechanisms for the users to specify the criteria of interestingness&lt;/li&gt;
&lt;li&gt;Provides a query language or query interface for users to select and retrieve&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Challenges of Data Mining&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technical
&lt;ul&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Dimensionality&lt;/li&gt;
&lt;li&gt;Data stream&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Complex and heterogeneous data&lt;/li&gt;
&lt;li&gt;Data quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Privacy
&lt;ul&gt;
&lt;li&gt;Data ownership and distribution&lt;/li&gt;
&lt;li&gt;Privacy preservation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Results
&lt;ul&gt;
&lt;li&gt;Interpretation of patterns&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The KDD Process&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kdd_process.png&#34; alt=&#34;kdd_process&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: Goal Setting
&lt;ul&gt;
&lt;li&gt;Understand your application domain&lt;/li&gt;
&lt;li&gt;Obtain prior known knowledge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 2: Data Collection
&lt;ul&gt;
&lt;li&gt;Characteristics&lt;/li&gt;
&lt;li&gt;Where to find&lt;/li&gt;
&lt;li&gt;How to store&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 3: Data Cleaning and Preprocessing
&lt;ul&gt;
&lt;li&gt;Missing data&lt;/li&gt;
&lt;li&gt;Incorrect data (noise)&lt;/li&gt;
&lt;li&gt;Outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 4: Data Reduction and Transformation (or Preparation)
&lt;ul&gt;
&lt;li&gt;Compact data into a form&lt;/li&gt;
&lt;li&gt;Improve data mining algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 5: Data Mining
&lt;ul&gt;
&lt;li&gt;Pick a data mining model&lt;/li&gt;
&lt;li&gt;Pick a data mining algorithm&lt;/li&gt;
&lt;li&gt;Apply the algorithm to the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 6: Result Evaluation
&lt;ul&gt;
&lt;li&gt;Check the results and goals&lt;/li&gt;
&lt;li&gt;Refine and re-run (if not)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 7: Knowledge Consolidation
&lt;ul&gt;
&lt;li&gt;Document&lt;/li&gt;
&lt;li&gt;Report&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Iterative and Interactive&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some steps of the process need to be refined, and the whole process be repeated&lt;/li&gt;
&lt;li&gt;Certain amount of human involvement is needed to monitor and to fine tune the steps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uses database records that describe information about past behavior to automatically generate a model (or rule) that can predict future behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Derive patterns that summarize the underlying relationships in data and to describe the characteristics of data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;OLAP (On-Line Analytical Processing)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;View data in a multi-dimensional model (a data cube)&lt;/li&gt;
&lt;li&gt;Fast aggregation&lt;/li&gt;
&lt;li&gt;Summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selection -&amp;gt; Group-by -&amp;gt; Summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Supervised learning&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Unseen records should be assigned a class (accuracy)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approach
&lt;ul&gt;
&lt;li&gt;Given a training set&lt;/li&gt;
&lt;li&gt;Learn classifier&lt;/li&gt;
&lt;li&gt;Find a model&lt;/li&gt;
&lt;li&gt;Test the model using test set&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct Marketing
&lt;ul&gt;
&lt;li&gt;Reduce cost of mailing by targeting a set of consumers likely to buy a new cell-phone product&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Preduct a value of numerical variable based on the values of other variables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predicting sales amounts of new product based on advertising expenditure&lt;/li&gt;
&lt;li&gt;Predicting wind velocities as a function of temperature, humidity, air pressure, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Clustering&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of data objects with a set of attributes and similarity measure&lt;/li&gt;
&lt;li&gt;Find clusters (e.g. distance-based clustering)
&lt;ul&gt;
&lt;li&gt;Maximize the intra-cluster similarity&lt;/li&gt;
&lt;li&gt;Minimize the inter-cluster similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objects in one cluster are more similiar to one another&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/illustrating_cluster.png&#34; alt=&#34;illustrating_cluster&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Document Clustering
&lt;ul&gt;
&lt;li&gt;To find groups of documents that are similar to each other based on the important terms they contain&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Association Rule Discovery&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of records each of which contains some items from a given collection&lt;/li&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Produce dependency rules which predict occurrence of an item based on occurrences of other items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Marketing and Sales Promotion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sequence Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a sequence database contains sequences of events&lt;/li&gt;
&lt;li&gt;Find sequences
&lt;ul&gt;
&lt;li&gt;Interesting&lt;/li&gt;
&lt;li&gt;Frequently occurring&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Predict future behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Renting movies&lt;/li&gt;
&lt;li&gt;Buying habits&lt;/li&gt;
&lt;li&gt;Web serving behavior&lt;/li&gt;
&lt;li&gt;Web log analysis&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链安全问题概述</title>
      <link>https://www.pseudoyu.com/en/2021/01/25/blockchain_note_security/</link>
      <pubDate>Mon, 25 Jan 2021 05:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/25/blockchain_note_security/</guid>
      
        <description>&lt;h2 id=&#34;区块链安全问题概述&#34;&gt;区块链安全问题概述&lt;/h2&gt;
&lt;h3 id=&#34;风险来源&#34;&gt;风险来源&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;应用层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;与应用程序相关的攻击和安全问题，如数字货币交易所&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;智能合约层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;很多潜在风险，如DAO事件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;激励层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;矿工付出成本 &amp;gt; 奖励，则去中心化系统可能崩溃&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;共识层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bribe Attack&lt;/li&gt;
&lt;li&gt;Long-Range Attack&lt;/li&gt;
&lt;li&gt;Coin age Accumulation Attack&lt;/li&gt;
&lt;li&gt;Precomputing Attack&lt;/li&gt;
&lt;li&gt;Sybil Attack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;网络层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BGP hijacking: 大约60%的比特币流量是通过几个互联网服务提供商，这些互联网服务提供商可以轻松控制和查看流量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;数据层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;恶意信息攻击（区块链上数据不可变）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;区块链风险分类&#34;&gt;区块链风险分类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;51%攻击 - 共识机制&lt;/li&gt;
&lt;li&gt;私钥安全 - 加密方案&lt;/li&gt;
&lt;li&gt;违法行为 - 数字货币应用&lt;/li&gt;
&lt;li&gt;双重花费 - 验证机制&lt;/li&gt;
&lt;li&gt;信息传输隐私泄漏 - 交易方案设计缺陷&lt;/li&gt;
&lt;li&gt;恶意智能合约 - 智能合约应用&lt;/li&gt;
&lt;li&gt;智能合约漏洞 - 智能合约开发缺陷&lt;/li&gt;
&lt;li&gt;智能合约执行优化 - 程序执行缺陷&lt;/li&gt;
&lt;li&gt;低成本操作 - EVM设计缺陷&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;风险分析&#34;&gt;风险分析&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;协议&lt;/li&gt;
&lt;li&gt;加密方案&lt;/li&gt;
&lt;li&gt;应用&lt;/li&gt;
&lt;li&gt;程序开发&lt;/li&gt;
&lt;li&gt;系统&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以太坊智能合约漏洞&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solidity 编程语言&lt;/li&gt;
&lt;li&gt;EVM 以太坊虚拟机&lt;/li&gt;
&lt;li&gt;Blockchain 区块链&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;著名安全事件&#34;&gt;著名安全事件&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Youbit&lt;/li&gt;
&lt;li&gt;Bitfinex
&lt;ul&gt;
&lt;li&gt;DDoS攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ICO攻击
&lt;ul&gt;
&lt;li&gt;对ICO钱包地址进行攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mt. Gox事件
&lt;ul&gt;
&lt;li&gt;占据70%比特币交易&lt;/li&gt;
&lt;li&gt;US$450M比特币被盗&lt;/li&gt;
&lt;li&gt;利用了比特币transaction malleability&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DAO事件
&lt;ul&gt;
&lt;li&gt;一个众筹智能合约应用&lt;/li&gt;
&lt;li&gt;利用了Solidity语言的脆弱性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;transaction-malleability攻击概述&#34;&gt;Transaction Malleability攻击概述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;每一笔交易都被数字签名&lt;/li&gt;
&lt;li&gt;创建Hash作为交易ID&lt;/li&gt;
&lt;li&gt;在早期的实现中，对于padding数据没有严格标准，hash创建使用&amp;lt;$,form, to, padding string&amp;gt;&lt;/li&gt;
&lt;li&gt;攻击者可以改变padding字符串从而改变交易ID&lt;/li&gt;
&lt;li&gt;攻击者要求交易所转出1美元&lt;/li&gt;
&lt;li&gt;交易所会通知攻击者关于交易ID&lt;/li&gt;
&lt;li&gt;攻击者更改ID，存入金额，并声明交易丢失，欺骗交易所重新发送&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;智能合约安全&#34;&gt;智能合约安全&lt;/h3&gt;
&lt;p&gt;E.g. 低成本攻击&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础
&lt;ul&gt;
&lt;li&gt;智能合约&lt;/li&gt;
&lt;li&gt;以太坊Gas机制
&lt;ul&gt;
&lt;li&gt;收取用户执行合约费用，以避免智能合约占用大量计算资源&lt;/li&gt;
&lt;li&gt;每个操作都分配有特定的Gas单位&lt;/li&gt;
&lt;li&gt;用户可以指定每单位Gas的数量和限额&lt;/li&gt;
&lt;li&gt;执行智能合约代码的矿工获得Gas费用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;攻击思路
&lt;ul&gt;
&lt;li&gt;识别较低Gas费的操作&lt;/li&gt;
&lt;li&gt;重复执行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;实例
&lt;ul&gt;
&lt;li&gt;EXTCODESIZE&lt;/li&gt;
&lt;li&gt;SUICIDE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更通用的安全解决方案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建一个自动检查器来检查代码以识别恶意代码&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 1a Relational Database</title>
      <link>https://www.pseudoyu.com/en/2021/01/23/comp7801_topic1a/</link>
      <pubDate>Sat, 23 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/23/comp7801_topic1a/</guid>
      
        <description>&lt;h2 id=&#34;relational-databases&#34;&gt;Relational Databases&lt;/h2&gt;
&lt;h3 id=&#34;structure-of-relational-databases&#34;&gt;Structure of Relational Databases&lt;/h3&gt;
&lt;h4 id=&#34;basic-structure&#34;&gt;Basic structure&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Given sets D1, D2, …. Dn&lt;/li&gt;
&lt;li&gt;A relation r is a subset of D1 x  D2  x … x Dn&lt;/li&gt;
&lt;li&gt;A relation is a set of n-tuples (a1, a2, …, an) where each ai  &lt;!-- raw HTML omitted --&gt; Di&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;customer-name = {Jones, Smith, Curry, Lindsay}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;customer-street = {Main, North, Park}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;customer-city = {Harrison, Rye, Pittsfield}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Then
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;r = {(Jones, Main, Harrison), (Smith, North, Rye), (Curry, North, Rye), (Lindsay, Park, Pittsfield)}&lt;/code&gt; is a relation over customer-name x customer-street x customer-city&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;attribute-types&#34;&gt;Attribute Types&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Each attribute of a relation has a name&lt;/li&gt;
&lt;li&gt;The set of allowed values for each attribute is called the domain of the attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;relation-schema&#34;&gt;Relation Schema&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A1, A2, …, An are attributes&lt;/li&gt;
&lt;li&gt;R = (A1, A2, …, An ) is a relation schema
&lt;ul&gt;
&lt;li&gt;E.g. &lt;code&gt;Account-schema = (account-number, branch-name, balance)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;r(R) is a relation on the relation schema R
&lt;ul&gt;
&lt;li&gt;E.g. &lt;code&gt;customer(Customer-schema)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;relation-instance&#34;&gt;Relation Instance&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The current values (relation instance) of a relation are specified by a table&lt;/li&gt;
&lt;li&gt;An element t of r is a tuple, represented by a row in a table&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/relation_instance.png&#34; alt=&#34;relation_instance&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;database&#34;&gt;Database&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A database consists of multiple relations which are inter-related&lt;/li&gt;
&lt;li&gt;Information about an enterprise is broken up into parts, with each relation storing one part of the information&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/database_overview.png&#34; alt=&#34;database_overview&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;query-language&#34;&gt;Query language&lt;/h4&gt;
&lt;p&gt;Language in which user requests information from the database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Categories
&lt;ul&gt;
&lt;li&gt;procedural&lt;/li&gt;
&lt;li&gt;non-procedural&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pure languages
&lt;ul&gt;
&lt;li&gt;Relational Algebra
&lt;ul&gt;
&lt;li&gt;The operators take one or more relations as inputs and give a new relation as a result&lt;/li&gt;
&lt;li&gt;Operations
&lt;ul&gt;
&lt;li&gt;select&lt;/li&gt;
&lt;li&gt;project&lt;/li&gt;
&lt;li&gt;union&lt;/li&gt;
&lt;li&gt;set-Intersection&lt;/li&gt;
&lt;li&gt;set difference&lt;/li&gt;
&lt;li&gt;cartesian product&lt;/li&gt;
&lt;li&gt;rename&lt;/li&gt;
&lt;li&gt;Natural Join&lt;/li&gt;
&lt;li&gt;Aggregate Functions
&lt;ul&gt;
&lt;li&gt;avg:  average value&lt;/li&gt;
&lt;li&gt;min:  minimum value&lt;/li&gt;
&lt;li&gt;max:  maximum value&lt;/li&gt;
&lt;li&gt;sum:  sum of values&lt;/li&gt;
&lt;li&gt;count:  number of values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relational Calculus&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL is based on set and relational operations with certain modifications and enhancements&lt;/li&gt;
&lt;li&gt;A typical SQL query has the form
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select A1, A2, ..., Anfrom r1, r2, ..., rm where P&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The result of an SQL query is a multiset of tuples&lt;/li&gt;
&lt;li&gt;Clauses
&lt;ul&gt;
&lt;li&gt;select
&lt;ul&gt;
&lt;li&gt;To force the elimination of duplicates, insert the keyword &lt;code&gt;distinct&lt;/code&gt; after &lt;code&gt;select&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;where
&lt;ul&gt;
&lt;li&gt;The where clause specifies conditions that the result must satisfy
&lt;ul&gt;
&lt;li&gt;Comparison results can be combined using the logical connectives and, or, and not&lt;/li&gt;
&lt;li&gt;Comparisons can be applied to results of arithmetic expressions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;from
&lt;ul&gt;
&lt;li&gt;The from clause lists the relations involved in the query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aggregate Functions
&lt;ul&gt;
&lt;li&gt;Group By
&lt;ul&gt;
&lt;li&gt;Find the number of depositors for each branch
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select branch-name,count (distinct customer-name)from depositor,account where depositor.account-number = account.account-numbergroup by branch-name&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Having
&lt;ul&gt;
&lt;li&gt;formation of groups whereas predicates in the where clause are applied before forming groups&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Query Evaluation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basic operations
&lt;ul&gt;
&lt;li&gt;Selections&lt;/li&gt;
&lt;li&gt;Joins&lt;/li&gt;
&lt;li&gt;Other operations (projection, aggregation)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Transformation of queries into a tree of operations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Query Optimizationh&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many equivalent expressions to the original query can be derived&lt;/li&gt;
&lt;li&gt;The query optimizer uses statistical data and appropriate algorithms to compute an expression of low evaluation cost&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;storage-of-databases&#34;&gt;Storage of databases&lt;/h3&gt;
&lt;h4 id=&#34;physical-storage-media&#34;&gt;Physical Storage Media&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cache
&lt;ul&gt;
&lt;li&gt;fastest and most costly form of storage&lt;/li&gt;
&lt;li&gt;volatile&lt;/li&gt;
&lt;li&gt;managed by the computer system hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Main memory
&lt;ul&gt;
&lt;li&gt;fast access&lt;/li&gt;
&lt;li&gt;generally too small (or too expensive) to store the entire database&lt;/li&gt;
&lt;li&gt;Volatile
&lt;ul&gt;
&lt;li&gt;contents of main memory are usually lost if a power failure or system crash occurs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Magnetic-disk
&lt;ul&gt;
&lt;li&gt;Data is stored on spinning disk, and read/written magnetically&lt;/li&gt;
&lt;li&gt;Primary medium for the long-term storage of data&lt;/li&gt;
&lt;li&gt;typically stores entire database&lt;/li&gt;
&lt;li&gt;Data must be moved from disk to main memory for access, and written back for storage
&lt;ul&gt;
&lt;li&gt;Much slower access than main memory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;direct-access –  possible to read data on disk in any order, unlike magnetic tape&lt;/li&gt;
&lt;li&gt;Capacities range up to several TB currently&lt;/li&gt;
&lt;li&gt;Survives power failures and system crashes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;storage-hierarchy&#34;&gt;Storage Hierarchy&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Primary storage
&lt;ul&gt;
&lt;li&gt;Fastest media but volatile (cache, main memory).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary storage&lt;/li&gt;
&lt;li&gt;Next level in hierarchy, non-volatile, moderately fast access time
&lt;ul&gt;
&lt;li&gt;Also called on-line storage, E.g. flash memory, magnetic disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tertiary storage: lowest level in hierarchy, non-volatile, slow access time
&lt;ul&gt;
&lt;li&gt;Also called off-line storage, E.g. magnetic tape, optical storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/memory_hierarchy.png&#34; alt=&#34;memory_hierarchy&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;magnetic-disks&#34;&gt;Magnetic Disks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Read-write head
&lt;ul&gt;
&lt;li&gt;Positioned very close to the platter surface (almost touching it)&lt;/li&gt;
&lt;li&gt;Reads or writes magnetically encoded information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Surface of platter divided into circular tracks
&lt;ul&gt;
&lt;li&gt;Over 16,000 tracks per platter on typical hard disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each track is divided into sectors
&lt;ul&gt;
&lt;li&gt;A sector is the smallest unit of data that can be read or written&lt;/li&gt;
&lt;li&gt;Sector size typically 512 bytes&lt;/li&gt;
&lt;li&gt;Typical sectors per track: 200 (on inner tracks) to 400 (on outer tracks)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To read/write a sector
&lt;ul&gt;
&lt;li&gt;disk arm swings to position head on right track&lt;/li&gt;
&lt;li&gt;platter spins continually; data is read/written as sector passes under head&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Head-disk assemblies
&lt;ul&gt;
&lt;li&gt;multiple disk platters on a single spindle (typically 2 to 4)&lt;/li&gt;
&lt;li&gt;one head per platter, mounted on a common arm.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cylinder i consists of ith track of all the platters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/magnetic_hard_disk.png&#34; alt=&#34;magnetic_hard_disk&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;performance-measures-of-disks&#34;&gt;Performance Measures of Disks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Access time – the time it takes from when a read or write request is issued to when data transfer begins
&lt;ul&gt;
&lt;li&gt;Seek time – time it takes to reposition the arm over the correct track
&lt;ul&gt;
&lt;li&gt;Average seek time is 1/2 the worst case seek time
&lt;ul&gt;
&lt;li&gt;Would be 1/3 if all tracks had the same number of sectors, and we ignore the time to start and stop arm movement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;4 to 10 milliseconds on typical disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rotational latency – time it takes for the sector to be accessed to appear under the head
&lt;ul&gt;
&lt;li&gt;Average latency is 1/2 of the worst case latency&lt;/li&gt;
&lt;li&gt;4 to 11 milliseconds on typical disks (5400 to 15000 r.p.m.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data-transfer rate – the rate at which data can be retrieved from or stored to the disk
&lt;ul&gt;
&lt;li&gt;4 to 8 MB per second is typical&lt;/li&gt;
&lt;li&gt;Multiple disks may share a controller, so rate that controller can handle is also important&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;optimization-of-disk-block-access&#34;&gt;Optimization of Disk-Block Access&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Block – a contiguous sequence of sectors from a single track
&lt;ul&gt;
&lt;li&gt;data is transferred between disk and main memory in blocks&lt;/li&gt;
&lt;li&gt;sizes range from 512 bytes to several kilobytes
&lt;ul&gt;
&lt;li&gt;Smaller blocks: more transfers from disk&lt;/li&gt;
&lt;li&gt;Larger blocks:  more space wasted due to partially filled blocks&lt;/li&gt;
&lt;li&gt;Typical block sizes today range from 4 to 16 kilobytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disk-arm-scheduling algorithms order pending accesses to tracks so that disk arm movement is minimized&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;storage-access&#34;&gt;Storage Access&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A database file is partitioned into fixed-length storage units called blocks.  Blocks are units of both storage allocation and data transfer. Typical size of a block ranges between 4Kb-16Kb&lt;/li&gt;
&lt;li&gt;Database system seeks to minimize the number of block transfers between the disk and memory.  We can reduce the number of disk accesses by keeping as many blocks as possible in main memory&lt;/li&gt;
&lt;li&gt;Buffer
&lt;ul&gt;
&lt;li&gt;portion of main memory available to store copies of disk blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Buffer manager
&lt;ul&gt;
&lt;li&gt;subsystem responsible for allocating buffer space in main memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/storage_access.png&#34; alt=&#34;storage_access&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;buffer-manager&#34;&gt;Buffer manager&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Programs call on the buffer manager when they need a block from disk
&lt;ul&gt;
&lt;li&gt;If the block is already in the buffer, the requesting program is given the address of the block in main memory&lt;/li&gt;
&lt;li&gt;If the block is not in the buffer
&lt;ul&gt;
&lt;li&gt;the buffer manager allocates space in the buffer for the block, replacing (throwing out) some other block, if required, to make space for the new block&lt;/li&gt;
&lt;li&gt;The block that is thrown out is written back to disk only if it was modified since the most recent time that it was written to/fetched from the disk&lt;/li&gt;
&lt;li&gt;Once space is allocated in the buffer, the buffer manager reads the block from the disk to the buffer, and passes the address of the block in main memory to requester&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Buffer-Replacement Policies&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most operating systems replace the block least recently used (LRU strategy)&lt;/li&gt;
&lt;li&gt;Idea behind LRU – use past pattern of block references as a predictor of future references. If a block has not been recently used, then it is unlikely that it will be used in the near future&lt;/li&gt;
&lt;li&gt;This replacement policy is also used at different applications. A proxy server keeps in the most recently used web pages in a local cache. If a user requests again a page he has seen, it does not need to be downloaded again in the future&lt;/li&gt;
&lt;li&gt;LRU works well for unpredicted access patterns&lt;/li&gt;
&lt;li&gt;However, queries have well-defined access patterns (such as sequential scans), and a database system can use the information in a user’s query to predict future references&lt;/li&gt;
&lt;li&gt;LRU can be a bad strategy for certain access patterns involving repeated scans of data. Mixed strategy with hints on replacement strategy provided by the query optimizer is preferable&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;file-organization&#34;&gt;File Organization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The database is stored as a collection of files. Each file is a sequence of records. A record is a sequence of fields&lt;/li&gt;
&lt;li&gt;Each record has an address in the file, which is called record pointer or record id (simply rid)&lt;/li&gt;
&lt;li&gt;A simple approach
&lt;ul&gt;
&lt;li&gt;assume record size is fixed&lt;/li&gt;
&lt;li&gt;each file has records of one particular type only&lt;/li&gt;
&lt;li&gt;different files are used for different relations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Organization of Records in Files&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Heap
&lt;ul&gt;
&lt;li&gt;a record can be placed anywhere in the file where there is space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential
&lt;ul&gt;
&lt;li&gt;store records in sequential order, based on the value of the search key of each record&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hashing
&lt;ul&gt;
&lt;li&gt;a hash function computed on some attribute of each record; the result specifies in which block of the file the record should be placed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Records of each relation may be stored in a separate file. In a  clustered file organization  records of several different relations can be stored in the same file
&lt;ul&gt;
&lt;li&gt;Motivation: store related records on the same block to minimize I/O&lt;/li&gt;
&lt;li&gt;However, not good for queries accessing only a few relations&lt;/li&gt;
&lt;li&gt;In general, this representation is barely used&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>比特币数据模型概述</title>
      <link>https://www.pseudoyu.com/en/2021/01/22/blockchain_note_bitcoin_data/</link>
      <pubDate>Fri, 22 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/22/blockchain_note_bitcoin_data/</guid>
      
        <description>&lt;h2 id=&#34;比特币数据模型概述&#34;&gt;比特币数据模型概述&lt;/h2&gt;
&lt;h3 id=&#34;区块头&#34;&gt;区块头&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;前一个区块的哈希值&lt;/li&gt;
&lt;li&gt;时间戳&lt;/li&gt;
&lt;li&gt;Merkle Root&lt;/li&gt;
&lt;li&gt;Nonce&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;block-body&#34;&gt;Block Body&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction.png&#34; alt=&#34;blockchain_bitcoin_data_transaction&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交易
&lt;ul&gt;
&lt;li&gt;输入
&lt;ul&gt;
&lt;li&gt;UTXO: Unspent outputs from another Transaction
&lt;ul&gt;
&lt;li&gt;必须以整体被花费，不能划分，多余部分转回源账户&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有输入都可以追溯至输出&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;输出&lt;/li&gt;
&lt;li&gt;双重Hash形式
&lt;ul&gt;
&lt;li&gt;SHA256(SHA256(源交易)) = Transhaction Hash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;交易模型&#34;&gt;交易模型&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction_detail.png&#34; alt=&#34;blockchain_bitcoin_data_transaction_detail&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Version&lt;/li&gt;
&lt;li&gt;Input count&lt;/li&gt;
&lt;li&gt;Input info - Unlocking Script
&lt;ul&gt;
&lt;li&gt;Input来源&lt;/li&gt;
&lt;li&gt;核对Input是否可用&lt;/li&gt;
&lt;li&gt;Input info细节
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction_input_info.png&#34; alt=&#34;blockchain_bitcoin_data_transaction_input_info&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Previous output hash&lt;/strong&gt; - 所有输入都能追溯回一个输出(UTXO)，这指向包含将在该输入中花费的UTXO，该UTXO的哈希值在这里以相反的顺序保存&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Previous output index&lt;/strong&gt; - 一个交易可以有多个由它们的索引号引用的UTXO，第一个索引是0&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unlocking Script Size&lt;/strong&gt; - Unlocking Script的字节大小&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unlocking Script&lt;/strong&gt; - 满足UTXO Unlocking Script的哈希&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sequence Number&lt;/strong&gt; - 默认为ffffffff&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Output Count&lt;/li&gt;
&lt;li&gt;Output Info - Locking Script
&lt;ul&gt;
&lt;li&gt;输出了多少比特币&lt;/li&gt;
&lt;li&gt;未来支出的条件&lt;/li&gt;
&lt;li&gt;存储在输出信息中的数据
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction_output_info.png&#34; alt=&#34;blockchain_bitcoin_data_transaction_output_info&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Amount&lt;/strong&gt; - 以Satoshis(最小的比特币单位)表示的输出比特币数量，10^8 Satoshis = 1比特币&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locking Script Size&lt;/strong&gt; - 这是Locking Script的字节大小&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locking Script&lt;/strong&gt; - 这是Locking Script的哈希，它指定了使用此输出必须满足的条件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Locktime
&lt;ul&gt;
&lt;li&gt;一个交易可以被最早添加到区块链的时间/块&lt;/li&gt;
&lt;li&gt;如果 &amp;lt;500 million，读取块高度&lt;/li&gt;
&lt;li&gt;如果 &amp;gt;500 million，读取时间戳&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币脚本&#34;&gt;比特币脚本&lt;/h2&gt;
&lt;p&gt;记录在每个交易中的指令列表，当被执行时确定交易是否有效以及比特币是否可以使用&lt;/p&gt;
&lt;h3 id=&#34;脚本&#34;&gt;脚本&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_detail.png&#34; alt=&#34;blockchain_bitcoin_script_detail&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&amp;lt;sig&amp;gt; &amp;lt;pubKey&amp;gt; OP_DUP OP_HASH160 &amp;lt;pubKeyHash&amp;gt; OP_EQUALVERIFY OP_CHECKSIG
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;基于Stack&lt;/li&gt;
&lt;li&gt;存储常数&lt;/li&gt;
&lt;li&gt;使用Opcodes
&lt;ul&gt;
&lt;li&gt;Push (Add)&lt;/li&gt;
&lt;li&gt;Pop (Remove)&lt;/li&gt;
&lt;li&gt;Etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;从左至右执行&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;交易&#34;&gt;交易&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_locking_unlocking.png&#34; alt=&#34;blockchain_bitcoin_script_locking_unlocking&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_relationship.png&#34; alt=&#34;blockchain_bitcoin_script_relationship&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;标准脚本符号&#34;&gt;标准脚本符号&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lt;&amp;gt;包含的是要被推入stack的数据&lt;/li&gt;
&lt;li&gt;没有&amp;lt;&amp;gt;包含，以OP_为前缀的是操作符（OP可省略）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;脚本的特征&#34;&gt;脚本的特征&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;非图灵完备
&lt;ul&gt;
&lt;li&gt;没有循环或者复杂的流程控制&lt;/li&gt;
&lt;li&gt;执行是确定性的&lt;/li&gt;
&lt;li&gt;简单、安全&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;无状态验证
&lt;ul&gt;
&lt;li&gt;脚本执行之前或之后没有保存任何状态&lt;/li&gt;
&lt;li&gt;脚本之间是独立的&lt;/li&gt;
&lt;li&gt;无论脚本在哪里执行，都提供可预测性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;可以嵌入数据&#34;&gt;可以嵌入数据&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_embedding_data.png&#34; alt=&#34;blockchain_bitcoin_script_embedding_data&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Bitcoin Core客户端入门</title>
      <link>https://www.pseudoyu.com/en/2021/01/19/blockchain_note_bitcoin_core/</link>
      <pubDate>Tue, 19 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/19/blockchain_note_bitcoin_core/</guid>
      
        <description>&lt;h3 id=&#34;bitcoin-core客户端入门&#34;&gt;Bitcoin Core客户端入门&lt;/h3&gt;
&lt;p&gt;比特币的实现&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bitcoin-QT&lt;/li&gt;
&lt;li&gt;Satoshi-client&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连接至比特币网络&lt;/li&gt;
&lt;li&gt;可验证区块链&lt;/li&gt;
&lt;li&gt;可以发送与接收区块链&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;网络&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mainnet&lt;/li&gt;
&lt;li&gt;Testnet&lt;/li&gt;
&lt;li&gt;Regnet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_core_network.png&#34; alt=&#34;blockchain_bitcoin_core_network&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_core_mainnet_testnet.png&#34; alt=&#34;blockchain_bitcoin_core_mainnet_testnet&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_core_regnet_testnet.png&#34; alt=&#34;blockchain_bitcoin_core_regnet_testnet&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;debug-console&#34;&gt;Debug Console&lt;/h3&gt;
&lt;p&gt;与比特币区块链交互的工具&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blockchain&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getblockchaininfo: 返回有关区块链处理的各种状态信息&lt;/li&gt;
&lt;li&gt;getblockcount: 返回区块链中的块数&lt;/li&gt;
&lt;li&gt;verifychain: 验证区块链数据库&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Hash&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getblockhash: 返回所提供的区块哈希值&lt;/li&gt;
&lt;li&gt;getnetworkhashps: 基于指定数量的最近块，返回每秒网络哈希数&lt;/li&gt;
&lt;li&gt;getbestblockhash: 返回最佳块的哈希值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Blocks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getblock: 返回块信息的详细信息&lt;/li&gt;
&lt;li&gt;getblockheader: 返回有关区块头信息&lt;/li&gt;
&lt;li&gt;generate: 立即将指定数量的块挖矿到钱包中的一个地址&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Wallet&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getwalletinfo: 返回一个对象，该对象包含有关钱包状态的各种信息&lt;/li&gt;
&lt;li&gt;listwallets: 返回当前加载的钱包列表&lt;/li&gt;
&lt;li&gt;walletpassphrasechange: 更改钱包密码&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mempool&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getmempoolinfo: 返回内存池活动状态的详细信息&lt;/li&gt;
&lt;li&gt;getrawmempool: 返回内存池中的所有交易详细信息&lt;/li&gt;
&lt;li&gt;getmempoolentry: 返回给定交易的内存池数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Transaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getchaintxstats: 计算关于链中交易总数和速率的统计数据&lt;/li&gt;
&lt;li&gt;getrawtransaction: 返回原始交易数据&lt;/li&gt;
&lt;li&gt;listtransactions: 返回给定帐户的交易列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Signature&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;signrawtransaction: 签署原始交易的输入&lt;/li&gt;
&lt;li&gt;signmessage: 使用地址的私钥对信息进行签名&lt;/li&gt;
&lt;li&gt;dumpprivkey: 获取私钥&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Network&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getnetworkinfo: 返回P2P网络的状态信息&lt;/li&gt;
&lt;li&gt;getpeerinfo: 返回每个连接网络节点的数据&lt;/li&gt;
&lt;li&gt;getconnectioncount: 返回节点的连接数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mining&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getmininginfo: 返回包含挖掘相关信息的对象&lt;/li&gt;
&lt;li&gt;getblocktemplate: 返回构造块所需的数据&lt;/li&gt;
&lt;li&gt;prioritisetransaction: 以较高或较低的优先级接受交易进入挖掘的块&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>比特币基础原理</title>
      <link>https://www.pseudoyu.com/en/2021/01/15/blockchain_note_bitcoin/</link>
      <pubDate>Fri, 15 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/15/blockchain_note_bitcoin/</guid>
      
        <description>&lt;h2 id=&#34;比特币基础原理&#34;&gt;比特币基础原理&lt;/h2&gt;
&lt;h3 id=&#34;哈希指针-hash-pointers&#34;&gt;哈希指针 Hash Pointers&lt;/h3&gt;
&lt;p&gt;哈希指针指向一个结构体的哈希值（整个区块+其H()一起算出下一个值）&lt;/p&gt;
&lt;p&gt;特征&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tamper-evident log&lt;/li&gt;
&lt;li&gt;如果这个区块被篡改，则会影响后续所有区块，最终导致和本地存储的哈希指针对不上&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;默克尔树-merkle-tree&#34;&gt;默克尔树 Merkle Tree&lt;/h3&gt;
&lt;p&gt;比特币中，每个数据块其实是一种交易transaction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;区块
&lt;ul&gt;
&lt;li&gt;Block header 块头：有根哈希值，没有交易具体内容&lt;/li&gt;
&lt;li&gt;Block body 块身：有交易列表&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Merkle Tree&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点类型
&lt;ul&gt;
&lt;li&gt;Full Node 全节点：保存Block header和Block body&lt;/li&gt;
&lt;li&gt;Light Node 轻节点：只保存Block Header，如手机上的比特币钱包&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;只要存放root hash，就能检测出树中任意节点的修改&lt;/li&gt;
&lt;li&gt;Merkle proof：如何向轻节点证明某个交易写入区块链（复杂度为O(logN)，Proof of Membership）&lt;/li&gt;
&lt;li&gt;Proof of non-membership
&lt;ul&gt;
&lt;li&gt;遍历验证，复杂度为O(n)&lt;/li&gt;
&lt;li&gt;可以对叶节点按哈希值大小进行排序，用二分法对相邻的数据块分别向上取哈希值，直到root hash验证，复杂度为O(logN)，称为sorted merkle tree，比特币没有采用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;问题央行如何发行数字货币&#34;&gt;问题：央行如何发行数字货币&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;谁有权力发行&lt;/li&gt;
&lt;li&gt;怎么验证交易有效性，防止双花攻击
&lt;ul&gt;
&lt;li&gt;数字货币交易
&lt;ul&gt;
&lt;li&gt;Input：说明币的来源和支付人的公钥&lt;/li&gt;
&lt;li&gt;Output：说明接收者的公钥Hash（即地址）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;交易信息写进区块链
&lt;ul&gt;
&lt;li&gt;账本的内容需要取得分布式共识（Distributed consensus）&lt;/li&gt;
&lt;li&gt;分布式哈希表，即系统里许多节点共同维护&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FLP Impossibility：在一个异步系统里，网络传输延迟没有上限，哪怕系统中有一个进程失败，无法达成共识&lt;/p&gt;
&lt;p&gt;CAP Theorem，三个要素最多只能同时实现两点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一致性 Consistency&lt;/li&gt;
&lt;li&gt;可用性 Availability&lt;/li&gt;
&lt;li&gt;分区容错性 Partition tolerance&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;比特币共识协议&#34;&gt;比特币共识协议&lt;/h3&gt;
&lt;p&gt;解决系统中有部分节点是恶意的，解决思路为过半数同意，其中谁有投票权&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;风险：Sybil attack 女巫攻击，利用少数节点控制多个虚假身份&lt;/li&gt;
&lt;li&gt;比特币解决方案：工作量证明机制（算力投票机制）
&lt;ul&gt;
&lt;li&gt;全网广播新的数据记录&lt;/li&gt;
&lt;li&gt;全网执行共识算法，即暴力求解数学难题&lt;/li&gt;
&lt;li&gt;率先解出难题的矿工获得记账权，产生新区块&lt;/li&gt;
&lt;li&gt;对外广播新区块，其他节点验证通过后加至主链&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最长合法链
&lt;ul&gt;
&lt;li&gt;分叉攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;同时挖到矿，出现两个等长区块，则会维持一段时间，看哪个区块先被接上&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币系统的实现&#34;&gt;比特币系统的实现&lt;/h2&gt;
&lt;p&gt;基于交易的账本模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UTXO: Unspent Transaction Outputs，未花费交易输出&lt;/li&gt;
&lt;li&gt;比特币系统中，要确认一个地址的余额需要回顾以前所有的交易，并且找到所有给自己的比特币并相加&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;预防双花的机制&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设Alice收了了两笔交易，共计5 BTC（2+3）&lt;/li&gt;
&lt;li&gt;Alice拥有了两笔UTXO，可作为未来转钱给别人的input&lt;/li&gt;
&lt;li&gt;当Alice想要转账给别人，矿工需要验证的是有没有在其他交易在先前的区块中已经使用过这笔Unspent Output&lt;/li&gt;
&lt;li&gt;如果同一笔输出已经被发送过，就不是Unspent了&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;区块链是不可篡改的账本的特性只是概率上的保证，刚写入block的区块是容易篡改的，比特币采用6个confirmation来保障。&lt;/p&gt;
&lt;h2 id=&#34;比特币网络工作原理&#34;&gt;比特币网络工作原理&lt;/h2&gt;
&lt;h3 id=&#34;设计原则&#34;&gt;设计原则&lt;/h3&gt;
&lt;p&gt;simple, robust but not efficient&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用层 - 运行Bitcoin Blockchain&lt;/li&gt;
&lt;li&gt;网络层 - 运行P2P Overlay Network&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;节点工作流程&#34;&gt;节点工作流程&lt;/h3&gt;
&lt;p&gt;每个节点都要维护一个等待上链的交易的集合，一个区块大小为1M，需要几秒才能传到大多数节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;监听到A→B的交易，就将其写入集合&lt;/li&gt;
&lt;li&gt;如果同时有A→C的双花攻击，该节点不会再写入&lt;/li&gt;
&lt;li&gt;如果监听到有同样一笔A→B交易，会将该集合中的该笔交易删除&lt;/li&gt;
&lt;li&gt;如果监听到有一笔A→C的交易（同一个币来源），也会将该集合中A→这笔交易删除&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币挖矿&#34;&gt;比特币挖矿&lt;/h2&gt;
&lt;p&gt;为什么要挖矿&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Block reward 出块奖励：coinbase tx是唯一一个产生新币的途径&lt;/li&gt;
&lt;li&gt;矿工费&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;挖矿：不断尝试nonce值，是Block header里的hash值≤给定的目标阈值&lt;/p&gt;
&lt;p&gt;H(block header) ≤ target （target是难度为1的时候所对应的阈值，target越小，挖矿难度越大）&lt;/p&gt;
&lt;p&gt;difficulty = (difficulty - 1 - target) / target&lt;/p&gt;
&lt;p&gt;挖矿过程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一次挖矿过程都是随机测试&lt;/li&gt;
&lt;li&gt;每次试nonce构成了无记忆性&lt;/li&gt;
&lt;li&gt;次数很多，但是成功率很低&lt;/li&gt;
&lt;li&gt;出块时间服从指数分布&lt;/li&gt;
&lt;li&gt;从任何一点开始，成功概率不变，所以给予算力成比例优势&lt;/li&gt;
&lt;li&gt;挖矿并不是解数学题，挖矿难度是人为设定的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么要调整难度&#34;&gt;为什么要调整难度&lt;/h3&gt;
&lt;p&gt;出块时间太短容易出现分叉，分叉过多则会影响系统达成共识，危害系统安全性&lt;/p&gt;
&lt;p&gt;BTC的出块速度是10分钟，ETH出块速度是15秒（意味着ETH需要新的协议，ghost → orphan block不能简单丢弃，而是要给奖励，uncle reward）&lt;/p&gt;
&lt;h3 id=&#34;如何调整挖矿难度&#34;&gt;如何调整挖矿难度&lt;/h3&gt;
&lt;p&gt;每2016个区块（约两周）调整一次目标阈值，存在Block header中，有个nbits，是编码的版本&lt;/p&gt;
&lt;p&gt;target = target * (actual time / expected time)&lt;/p&gt;
&lt;p&gt;actual time → 系统中产生2016个区块花费的时间&lt;/p&gt;
&lt;p&gt;expected time → 产生2016个区块预计花费的时间（约14天）&lt;/p&gt;
&lt;p&gt;恶意节点不调整代码中的target的话，诚实的矿工则不会认可&lt;/p&gt;
&lt;p&gt;全节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一直在线&lt;/li&gt;
&lt;li&gt;在本地硬盘上维护完整的区块链信息&lt;/li&gt;
&lt;li&gt;在内存里维护UTXO集合，以便于快速检验交易的正确性&lt;/li&gt;
&lt;li&gt;监听比特币网络上的交易信息，验证每个交易的合法性&lt;/li&gt;
&lt;li&gt;决定哪些交易会被打包到区块里&lt;/li&gt;
&lt;li&gt;监听别的矿工挖出来的区块，验证其合法性&lt;/li&gt;
&lt;li&gt;挖矿
&lt;ul&gt;
&lt;li&gt;决定沿着哪条链挖下去&lt;/li&gt;
&lt;li&gt;当出现等长的分叉时，选择哪一个分叉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;轻节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不是一直在线&lt;/li&gt;
&lt;li&gt;不用保存整个区块链，只需要保存每个区块的块头&lt;/li&gt;
&lt;li&gt;不用保存全部交易，只需要保存与自己有关的交易&lt;/li&gt;
&lt;li&gt;无法检验大多交易的合法性，只能检验与自己相关的那些交易的合法性&lt;/li&gt;
&lt;li&gt;无法检测网上发布区块的正确性&lt;/li&gt;
&lt;li&gt;可以验证挖矿的难度&lt;/li&gt;
&lt;li&gt;只能检测哪个是最长链，不知道哪个是最长合法链&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;挖矿设备&#34;&gt;挖矿设备&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CPU&lt;/li&gt;
&lt;li&gt;GPU → 主要用于通用并行计算&lt;/li&gt;
&lt;li&gt;ASIC → Application Specific Integrated circuit&lt;/li&gt;
&lt;li&gt;大型矿池
&lt;ul&gt;
&lt;li&gt;Pool Manager：负责全节点要做的事&lt;/li&gt;
&lt;li&gt;Miner：计算hash值，通过POW分配收益&lt;/li&gt;
&lt;li&gt;如矿池达到51%以上算力
&lt;ul&gt;
&lt;li&gt;Forking attack，回滚交易&lt;/li&gt;
&lt;li&gt;Boycott，全网抵制与B有关的任何交易&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币分叉&#34;&gt;比特币分叉&lt;/h2&gt;
&lt;h3 id=&#34;分叉类型&#34;&gt;分叉类型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;state fork
&lt;ul&gt;
&lt;li&gt;forking attack (deliberate fork)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;protocol fork（因为对BTC协议产生分歧而造成的分叉）
&lt;ul&gt;
&lt;li&gt;hard fork
&lt;ul&gt;
&lt;li&gt;例如对block size limit的变化 1M  → 4M&lt;/li&gt;
&lt;li&gt;产生了永久性分叉&lt;/li&gt;
&lt;li&gt;两条链平行发展，各挖各的，互不认可，形成两种币&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;soft fork
&lt;ul&gt;
&lt;li&gt;例如对block size limit的变化 1M  → 0.5M&lt;/li&gt;
&lt;li&gt;新节点挖小区块，即使旧节点挖出了大区块，也会被放弃，再次出现分叉&lt;/li&gt;
&lt;li&gt;旧节点挖大区块&lt;/li&gt;
&lt;li&gt;出现软分叉的情况
&lt;ul&gt;
&lt;li&gt;coinbase内容修改&lt;/li&gt;
&lt;li&gt;P2SH: Pay to Script Hash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币的匿名性&#34;&gt;比特币的匿名性&lt;/h2&gt;
&lt;h3 id=&#34;破坏匿名性的方法&#34;&gt;破坏匿名性的方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;即使一笔交易生成多个inputs和outputs，这些inputs和outputs的地址也可能被人关联&lt;/li&gt;
&lt;li&gt;地址账户和现实世界中的真实身份也可能产生关联
&lt;ul&gt;
&lt;li&gt;防范比特币洗钱：盯住资金转入转出链&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;提高匿名性的方法&#34;&gt;提高匿名性的方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Application Layer: coin mixing 把各种人混在一起&lt;/li&gt;
&lt;li&gt;Network Layer: 多路径转发以避免从节点的ip地址推算出真实身份&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;零知识证明&#34;&gt;零知识证明&lt;/h3&gt;
&lt;p&gt;一方（证明者）向另一方（验证者）证明一个陈述是正确的，而无需透露除该陈述是正确的以外的人和信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同态隐藏
&lt;ul&gt;
&lt;li&gt;给定E(x)和E(y)，可以很容易计算出某些关于x,y的加密函数值（同态运算）
&lt;ul&gt;
&lt;li&gt;Alice把E(x)和E(y)发给Bob&lt;/li&gt;
&lt;li&gt;Bob通过收到的E(x)和E(y)计算出E(x+y)的值&lt;/li&gt;
&lt;li&gt;Bob同时计算E(7)的值，如果E(x+y)和E(7)相等，验证通过&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;盲签
&lt;ul&gt;
&lt;li&gt;用户提供SerialNum（暗文），银行在不知道SerialNum的情况下返回签名Token，减少A的存款&lt;/li&gt;
&lt;li&gt;用户A把SerialNum和Token交给B完成交易&lt;/li&gt;
&lt;li&gt;用户B拿SerialNum和Token给银行验证，银行验证通过，增加B的存款&lt;/li&gt;
&lt;li&gt;银行无法把A和B联系起来&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例如：证明某个比特币账户是我的（不泄露私钥） - 由私钥产生一个签名来证明所有权&lt;/li&gt;
&lt;li&gt;BTC的每一笔转账交易都要说明币的来源&lt;/li&gt;
&lt;li&gt;Zerocoin可以证明花的币是合法存在的，但不知道具体是哪一个&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结思考&#34;&gt;总结思考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;转账交易不需要接收者在线&lt;/li&gt;
&lt;li&gt;私钥丢失则失去对币的所有权，除非存在交易所中，但交易所有风险&lt;/li&gt;
&lt;li&gt;私钥泄漏需要立即将账户中的钱转到另外的账户&lt;/li&gt;
&lt;li&gt;转账时写错地址无法取消交易，也没办法追回&lt;/li&gt;
&lt;li&gt;既然所有要写入区块链的交易都需要被验证正确性，为什么proof of burn中OP_RETURN会被区块接受：
&lt;ul&gt;
&lt;li&gt;对于某个交易，我们需要验证输入脚本和输出脚本，而OP_RETURN是写在当前交易的输出脚本的，因此在本次验证中不会被检查到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在coinbase transaction中有收款人的地址，矿工如果想要偷答案则需要修改地址，会导致merkle tree发生改变，从而改变root hash，block header会发生改变，nonce也作废了&lt;/li&gt;
&lt;li&gt;比特币系统里并没有取得严格意义上的共识，如分叉&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链基本框架</title>
      <link>https://www.pseudoyu.com/en/2021/01/11/blockchain_note_framework/</link>
      <pubDate>Mon, 11 Jan 2021 08:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/11/blockchain_note_framework/</guid>
      
        <description>&lt;h2 id=&#34;区块链框架&#34;&gt;区块链框架&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;交易&lt;/li&gt;
&lt;li&gt;钱包&lt;/li&gt;
&lt;li&gt;签名&lt;/li&gt;
&lt;li&gt;内存池&lt;/li&gt;
&lt;li&gt;网络&lt;/li&gt;
&lt;li&gt;共识机制&lt;/li&gt;
&lt;li&gt;哈希&lt;/li&gt;
&lt;li&gt;区块&lt;/li&gt;
&lt;li&gt;区块链&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;哈希&#34;&gt;哈希&lt;/h3&gt;
&lt;p&gt;区块链使用的是SHA256(Secure Hashing Algorithm 256 bits)
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_sha256.png&#34; alt=&#34;blockchain_sha256&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;crypto-js/sha256&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;data1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Blockchain Rock!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;dataObject&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;With Object Works too&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;Date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;getTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;toString&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;slice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;function&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;JSON&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;stringify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`SHA256 Hash: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;data1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;************************************&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`SHA256 Hash: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;dataObject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;区块&#34;&gt;区块&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;区块头&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前一个区块的Hash&lt;/li&gt;
&lt;li&gt;时间戳&lt;/li&gt;
&lt;li&gt;Merkle Root&lt;/li&gt;
&lt;li&gt;Nonce
&lt;ul&gt;
&lt;li&gt;Block Data + Nonce = Hash value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;挖矿难度&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;000000HASHVALUE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;区块大小&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1MB (Bitcoin)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;哈希&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;即使数据产生很微小的变化，哈希值也会截然不同，如以下Demo所示&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;crypto-js/sha256&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;kr&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;constructor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;nonce&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;144444&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;body&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hash&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;self&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;promise&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;Promise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;resolve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;reject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
          &lt;span class=&#34;nx&#34;&gt;setTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
          &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hash&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
            &lt;span class=&#34;nx&#34;&gt;resolve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

          &lt;span class=&#34;nx&#34;&gt;setTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nx&#34;&gt;reject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SOMETHING WRONG!!!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;});&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;promise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;exports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;BlockClass&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;./block.js&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;block&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;BlockClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Test Block&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;block&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;then&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`Block Hash: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hash&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`Block: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;JSON&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;stringify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}).&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;catch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;区块链&#34;&gt;区块链&lt;/h3&gt;
&lt;p&gt;存储网络中所有交易历史记录的账本
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_overview.png&#34; alt=&#34;blockchain_overview&#34;&gt;
&lt;a href=&#34;https://andersbrownworth.com/blockchain/blockchain&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;network&#34;&gt;Network&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;P2P网络：不同用户之间共享信息和资源的一种分布式网络&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分布式网络：分布在不同地域的网络互相连接
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_network.png&#34; alt=&#34;blockchain_network&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;中心化网络：所有人都连接至一个（或一组）中心化网络&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;去中心化网络：没有一个单点网络可以拥有所有的信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分布式网络：每个人都得到一份信息备份，且都拥有访问权限&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;内存池&#34;&gt;内存池&lt;/h3&gt;
&lt;p&gt;交易脱离内存池的原因&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交易过期（14天）&lt;/li&gt;
&lt;li&gt;在以交易费排序的结构中交易处于内存池底部&lt;/li&gt;
&lt;li&gt;交易已经被一个区块包含&lt;/li&gt;
&lt;li&gt;交易有未确认的祖先区块被区块包含&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;共识机制&#34;&gt;共识机制&lt;/h3&gt;
&lt;p&gt;网络如何对交易达成信任/一致&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PoW(Proof of Work)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算消耗大（算力），但是很容易检验正确性&lt;/li&gt;
&lt;li&gt;比特币网络
&lt;ul&gt;
&lt;li&gt;10分钟左右（6个确认）&lt;/li&gt;
&lt;li&gt;动态调整难度&lt;/li&gt;
&lt;li&gt;消耗大量能源&lt;/li&gt;
&lt;li&gt;如果矿工（矿池）拥有大量资源则有中心化风险&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;PoS (Proof of Stake)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过与系统相关的用户（权益持有者）投票来达成共识&lt;/li&gt;
&lt;li&gt;Nothing at Stake问题：在所有区块都投注
&lt;ul&gt;
&lt;li&gt;同时在多个链上创建区块的用户会遭到惩罚&lt;/li&gt;
&lt;li&gt;在错误链上创建区块的用户会遭到惩罚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以太坊正在向PoS转变&lt;/li&gt;
&lt;li&gt;DASH&lt;/li&gt;
&lt;li&gt;LISK
&lt;ul&gt;
&lt;li&gt;DPoS (Delegated Proof of Stake)委任权益证明&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DBFT (Delegated Byzantine Fault Tolerance)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过对节点分配不同的角色来达成共识&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;降低开销&lt;/li&gt;
&lt;li&gt;避免分叉&lt;/li&gt;
&lt;li&gt;问题
&lt;ul&gt;
&lt;li&gt;不诚实的发言者&lt;/li&gt;
&lt;li&gt;不诚实的委任者&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;钱包&#34;&gt;钱包&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;私钥&lt;/li&gt;
&lt;li&gt;公钥&lt;/li&gt;
&lt;li&gt;钱包地址&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ECDSA (One-way Elliptic Curve Digital Signature Algorithm)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过私钥生成公钥&lt;/li&gt;
&lt;li&gt;单向，不能逆推&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;生成钱包地址&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过SHA256和RIPEMD160来生成钱包地址&lt;/li&gt;
&lt;li&gt;通过Base58Check来保障其可读性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;流程&lt;/strong&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_generate1.png&#34; alt=&#34;blockchain_wallet_generate1&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_generate2.png&#34; alt=&#34;blockchain_wallet_generate2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;钱包类型&lt;/strong&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_type.png&#34; alt=&#34;blockchain_wallet_type&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non-Deterministic Wallet&lt;/li&gt;
&lt;li&gt;Deterministic Wallet
&lt;ul&gt;
&lt;li&gt;Sequential Deterministic Wallet&lt;/li&gt;
&lt;li&gt;Hierarchical Deterministic (HD) Wallet
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_hd.png&#34; alt=&#34;blockchain_wallet_hd&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;私钥&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个256位随机数，介于1和2^256之间&lt;/li&gt;
&lt;li&gt;格式
&lt;ul&gt;
&lt;li&gt;Hex&lt;/li&gt;
&lt;li&gt;WIF(Base58Check)&lt;/li&gt;
&lt;li&gt;WIF-Compressed(Base58Check added suffix 0x01 before encoding)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Entropy 熵&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;混乱与不可预测状态&lt;/li&gt;
&lt;li&gt;应用
&lt;ul&gt;
&lt;li&gt;Python: Random&lt;/li&gt;
&lt;li&gt;Java: SecureRandom&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;签名&#34;&gt;签名&lt;/h3&gt;
&lt;p&gt;为区块链上每笔交易提供证明&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;私钥签名&lt;/li&gt;
&lt;li&gt;公钥验证&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;交易周期&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Inputs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Outputs
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_transaction_lifecycle.png&#34; alt=&#34;blockchain_transaction_lifecycle&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;UTXO (Unspent transaction output in bitcoin)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;广播到区块链&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链基础原理</title>
      <link>https://www.pseudoyu.com/en/2021/01/07/blockchain_note_concept/</link>
      <pubDate>Thu, 07 Jan 2021 05:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/07/blockchain_note_concept/</guid>
      
        <description>&lt;h2 id=&#34;区块链基础原理&#34;&gt;区块链基础原理&lt;/h2&gt;
&lt;p&gt;区块链是一种分布式账本技术，由于是一群人来记账，所以修改这个账本的难度比较高。&lt;/p&gt;
&lt;p&gt;单式记账 → 复式记账 → 数字化记账 → 分布式记账&lt;/p&gt;
&lt;p&gt;传统中心化数字记账依赖于某个组织的可信度，而区块链是通过共识机制来共同记账，由区块链技术来保障信任机制，具有去中心化、难以篡改、可追溯等特点。&lt;/p&gt;
&lt;p&gt;难以篡改是区块链主要特征，相比传统数据库（传统数据库包含了增删改查），区块链只有增加和查询，是一种“历史记录不可篡改的数据库”。&lt;/p&gt;
&lt;h3 id=&#34;传统数据库-vs-区块链数据库&#34;&gt;传统数据库 vs. 区块链数据库&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;传统数据库&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网络
&lt;ul&gt;
&lt;li&gt;中心化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;功能
&lt;ul&gt;
&lt;li&gt;Create 创建&lt;/li&gt;
&lt;li&gt;Read 读取&lt;/li&gt;
&lt;li&gt;Update 更新&lt;/li&gt;
&lt;li&gt;Delete 删除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可变性
&lt;ul&gt;
&lt;li&gt;可变&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;权限
&lt;ul&gt;
&lt;li&gt;中心化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透明度
&lt;ul&gt;
&lt;li&gt;低&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;区块链数据库&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网络
&lt;ul&gt;
&lt;li&gt;去中心化
&lt;ul&gt;
&lt;li&gt;给予节点控制权&lt;/li&gt;
&lt;li&gt;必须达成共识&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;功能
&lt;ul&gt;
&lt;li&gt;Read，Append，Validate
&lt;ul&gt;
&lt;li&gt;具有准确的历史记录&lt;/li&gt;
&lt;li&gt;读取和写入更快&lt;/li&gt;
&lt;li&gt;必须达成共识&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可变性
&lt;ul&gt;
&lt;li&gt;不可变
&lt;ul&gt;
&lt;li&gt;永久保存历史记录&lt;/li&gt;
&lt;li&gt;占据较大存储空间&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;权限
&lt;ul&gt;
&lt;li&gt;分布式
&lt;ul&gt;
&lt;li&gt;安全性高&lt;/li&gt;
&lt;li&gt;不能撤回交易&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透明度
&lt;ul&gt;
&lt;li&gt;高
&lt;ul&gt;
&lt;li&gt;每个人都能看到&lt;/li&gt;
&lt;li&gt;没有权限控制机制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;是否需要区块链&#34;&gt;是否需要区块链&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;是否需要数据库？&lt;/li&gt;
&lt;li&gt;是否需要共享写入权限？&lt;/li&gt;
&lt;li&gt;是否需要多方达成信任？&lt;/li&gt;
&lt;li&gt;能否脱离第三方机构运作？&lt;/li&gt;
&lt;li&gt;能否脱离权限控制机制运作？&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;适合区块链的应用场景&#34;&gt;适合区块链的应用场景&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;需要建立一个共享数据库，且有多方参与&lt;/li&gt;
&lt;li&gt;参与业务的各方没有建立起信任&lt;/li&gt;
&lt;li&gt;现有业务中信任一个或多个信任机构&lt;/li&gt;
&lt;li&gt;现有业务中有加密认证的业务需求&lt;/li&gt;
&lt;li&gt;数据需要集成到不同数据库且业务数字化和一致性的需求迫切&lt;/li&gt;
&lt;li&gt;对于系统参与者有统一的规则&lt;/li&gt;
&lt;li&gt;多方决策是透明的&lt;/li&gt;
&lt;li&gt;需要客观、不可改变的记录&lt;/li&gt;
&lt;li&gt;非实时性处理业务&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果以下条件则不适合采用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据无法公开&lt;/li&gt;
&lt;li&gt;数据很大&lt;/li&gt;
&lt;li&gt;业务规则经常变化&lt;/li&gt;
&lt;li&gt;需要外部服务来收集、存储数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;区块链类型&#34;&gt;区块链类型&lt;/h3&gt;
&lt;p&gt;区块链分为&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公链：交易是否要公开&lt;/li&gt;
&lt;li&gt;私链：是否需要其他公司（机构）访问数据&lt;/li&gt;
&lt;li&gt;联盟链：权限控制&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;越靠近公有链则对节点的认证和权限管理要求越少、去中心化程度越高&lt;/p&gt;
&lt;p&gt;公有链主流共识机制有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;工作量证明 PoW&lt;/li&gt;
&lt;li&gt;权益证明 PoS&lt;/li&gt;
&lt;li&gt;委任权益证明 DPoS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;共识机制核心是记账权的争夺，公链的设计思路是让恶意节点的攻击成本远远大于诚实节点的受益。一般采取拜占庭容错机制，解决了节点故障和节点作恶的情况下还是能达成共识。&lt;/p&gt;
&lt;h4 id=&#34;公链&#34;&gt;公链&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;比特币：第一个成功的去中心化数字货币系统&lt;/li&gt;
&lt;li&gt;以太坊：可编程、可运算的智能合约&lt;/li&gt;
&lt;li&gt;EOS：超越货币、经济的去中心话应用操作系统&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;联盟链&#34;&gt;联盟链&lt;/h4&gt;
&lt;p&gt;联盟链节点需要经过认证才能参与到区块链网络，交易速度更快、拓展性更高、并能很好地保护交易隐私。联盟链因为节点数有限且需要认证，为了提升效率，弱化了节点作恶，重点考虑1/3节点故障下系统共识机制的达成，且一般不需要代币作为激励机制，而是每个部门作为记账节点，实现跨部门之间的业务协同给大家带来经济效益。&lt;/p&gt;
&lt;p&gt;联盟链的代表是Hyperledger，这是首个面向企业应用场景的开源分布式账本平台，而Hyperledger Fabric是其中发展的最好的子项目。&lt;/p&gt;
&lt;p&gt;Hyperledger Fabric定位是面向企业的分布式账本平台，引入了权限管理机制，设计上支持可插拔、可拓展，具备良好的设计架构、完善的文档、清晰的代码。&lt;/p&gt;
&lt;h4 id=&#34;私有链&#34;&gt;私有链&lt;/h4&gt;
&lt;p&gt;而私有链是在某一领域、某一企业运行的区块链，一般用于解决部门间的信任问题。&lt;/p&gt;
&lt;h4 id=&#34;应用场景&#34;&gt;应用场景&lt;/h4&gt;
&lt;p&gt;长期来看，公有链和联盟链在技术上会趋于融合，界限也会越来越模糊，一般将需要信任的数据放在公有链上，而一些行业数据、私有数据放在联盟链上。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链中的密码学原理</title>
      <link>https://www.pseudoyu.com/en/2021/01/03/blockchain_note_cryptography/</link>
      <pubDate>Sun, 03 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/en/2021/01/03/blockchain_note_cryptography/</guid>
      
        <description>&lt;h2 id=&#34;密码学原理&#34;&gt;密码学原理&lt;/h2&gt;
&lt;h3 id=&#34;哈希&#34;&gt;哈希&lt;/h3&gt;
&lt;p&gt;特征&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;collision resistance 抗碰撞性
&lt;ul&gt;
&lt;li&gt;哈希碰撞是指当x≠y时，存在H(x)=H(y)，不同的输入映射到哈希表的同一个位置&lt;/li&gt;
&lt;li&gt;很难人工创造哈希碰撞&lt;/li&gt;
&lt;li&gt;常用于文件校验&lt;/li&gt;
&lt;li&gt;MD5是一个流行的哈希函数，但目前已经知道如何制造哈希碰撞&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;hiding 单向不可逆性
&lt;ul&gt;
&lt;li&gt;x → H(x), H(x)很难逆推出x&lt;/li&gt;
&lt;li&gt;条件
&lt;ul&gt;
&lt;li&gt;输入空间足够大&lt;/li&gt;
&lt;li&gt;分布尽可能均匀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;puzzle friendly 哈希值计算不可预测
&lt;ul&gt;
&lt;li&gt;很难解决哈希值推导&lt;/li&gt;
&lt;li&gt;易于验证结果正确性&lt;/li&gt;
&lt;li&gt;如POW工作量证明，挖矿试随机数nonce，使得H(block header) ≤ target&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;哈希函数用法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为文件D创建哈希函数H(D)，对H(D)进行数字签名
&lt;ol&gt;
&lt;li&gt;H(D) 可以保证D未被篡改&lt;/li&gt;
&lt;li&gt;给H(D)进行数字签名可以确认D的归属权&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;加密&#34;&gt;加密&lt;/h3&gt;
&lt;p&gt;公私钥对应用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;加密（公钥加密、私钥解密）&lt;/li&gt;
&lt;li&gt;数字签名&lt;/li&gt;
&lt;li&gt;哈希加密 (cryptographic hash)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;E.g. MD5, SHA1&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;对称加密&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A使用私钥加密，B使用同一个私钥解密&lt;/li&gt;
&lt;li&gt;私钥的分发存在风险&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;非对称加密&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A使用B的公钥进行加密，B使用自己的私钥进行解密&lt;/li&gt;
&lt;li&gt;C也可以使用B的公钥进行加密&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;数字签名&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A使用自己的私钥给信息加密&lt;/li&gt;
&lt;li&gt;大家都可以用A的公钥进行验证，防止其他人假冒A&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对比：数字签名和哈希加密&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数字签名针对某个特定对象&lt;/li&gt;
&lt;li&gt;所有人运算哈希函数可以得到相同结果&lt;/li&gt;
&lt;li&gt;哈希函数运算结果是固定长度的&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;应用（比特币区块链）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;私钥代表了对比特币的控制权&lt;/li&gt;
&lt;li&gt;交易发起方用私钥对交易（包括转账金额和转账地址）签名，并将签名后的交易和公钥广播&lt;/li&gt;
&lt;li&gt;各节点接收到交易后可以用公钥验证交易是否合法&lt;/li&gt;
&lt;li&gt;整个过程中无需暴露私钥，实现保密&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
