<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:webfeeds="http://webfeeds.org/rss/1.0">
  <channel>
    <title>Pseudoyu</title>
    <link>https://www.pseudoyu.com/zh/</link>
    <description>Recent content on Pseudoyu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sat, 27 Mar 2021 18:46:17 +0800</lastBuildDate>
    
    <atom:link href="https://www.pseudoyu.com/zh/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于</title>
      <link>https://www.pseudoyu.com/zh/about/</link>
      <pubDate>Thu, 04 Mar 2021 16:03:46 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/about/</guid>
      
        <description>&lt;h2 id=&#34;hi我是-yu-zhanghttpswwwpseudoyucom&#34;&gt;Hi，我是 &lt;a href=&#34;https://www.pseudoyu.com&#34;&gt;Yu Zhang&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;在香港大学计算机系读研，正在学习区块链，空闲也折腾Notion等效率工具，欢迎交流。&lt;/p&gt;
&lt;p&gt;希望不断学习，不断成长。现阶段的目标是能够在忙碌的闲隙里不断思考，多阅读写作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/dino.gif&#34; alt=&#34;picture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;个人希望&#34;&gt;个人希望&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;生活方面&lt;/strong&gt;&lt;/em&gt;，希望能够和现在的挚友一直相互支持走下去，和家人保持现在这样亦亲亦友的关系，和在意的人一起面对人生的挑战，同时也能认识更多有趣的人。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;专业方面&lt;/strong&gt;&lt;/em&gt;，希望一直有所进步，能够在开源世界留下一些痕迹。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;经济方面&lt;/strong&gt;&lt;/em&gt;，希望能自主无虞，足够支撑做自己想做的事，探索更多元的未来生活。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;社会方面&lt;/strong&gt;&lt;/em&gt;，希望有机会做参与一些公益活动或其他形式的善举，为世界带来一些微小的改变。&lt;/p&gt;
&lt;h2 id=&#34;关于网站&#34;&gt;关于网站&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; 是我的第一个网站，主要用来记录生活、学习与零碎的一些想法。最早基于WordPress并放在自己的个人服务器上，后又迁移至同名微信公众号，最后出于稳定性和自由度考虑还是决定用Hugo生成自己的静态网页，托管于GitHub并绑定 &lt;a href=&#34;https://www.pseudoyu.com/zh/&#34;&gt;pseudoyu.com&lt;/a&gt; 域名。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; 的命名很巧合，在HKU入学注册时因为自己名字过于常见而很难抉择使用什么uid，后取用了一个前缀「&lt;a href=&#34;https://www.oxfordlearnersdictionaries.com/definition/english/pseudo&#34;&gt;pseudo&lt;/a&gt;」，&lt;a href=&#34;https://www.oxfordlearnersdictionaries.com/definition/english/pseudonym&#34;&gt;pseudonym&lt;/a&gt; 有「笔名、假名」的含义，编程里常用到的 &lt;a href=&#34;https://www.lexico.com/definition/pseudocode&#34;&gt;pseudocode&lt;/a&gt; 是「伪码」的含义，而很喜欢的日漫 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%81%BD%E7%89%A9%E8%AA%9E&#34;&gt;&lt;em&gt;物语系列 - 伪物语&lt;/em&gt;&lt;/a&gt; 中也不乏对「真物」与「伪物」的探究，那为什么不能有一个 pseudo 的 yu（我）呢？&lt;/p&gt;
&lt;p&gt;我常辗转于自我怀疑之中，在与挚友聊天时谈及「初心」或是「意义」时总是选择逃避，即使取得一些世俗的小成就也很难从心底感受到喜悦或满足，总觉得一切都如同「伪物」一样毫无意义。而随着年岁与经历的增长，我在另一篇文章 &lt;a href=&#34;https://www.pseudoyu.com/zh/2020/06/06/23%E5%B2%81%E7%9A%84%E8%87%AA%E7%99%BD%E5%8E%BB%E8%BF%BD%E5%AF%BB%E6%84%8F%E4%B9%89/&#34;&gt;&lt;em&gt;23岁的自白：去追寻意义&lt;/em&gt;&lt;/a&gt; 中写道，「&lt;em&gt;也许思考本身就是建构意义的过程，让我不再期待某个瞬间能够顿悟，只是希望继续向前，体验和追寻着自己的人生.&lt;/em&gt;」&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; 这个名字也是寓意自己不应该再时常纠结意义，而是要不断去学习、体验与挑战新的事物，即使被评价「变了」、「不像自己」也能欣然接受。&lt;/p&gt;
&lt;p&gt;希望自己能多输入一些新的知识和想法，多写一些小文章。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS本地节点搭建（命令行）</title>
      <link>https://www.pseudoyu.com/zh/2021/03/27/blockchain_note_ipfs_practice/</link>
      <pubDate>Sat, 27 Mar 2021 18:46:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/27/blockchain_note_ipfs_practice/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;上一篇《&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/25/blockchain_note_ipfs_structure/&#34;&gt;IPFS分布式文件存储原理&lt;/a&gt;》对于IPFS系统的设计理念、功能、工作原理及IPNS做了详细的介绍，那么，如何在本地搭建一个IPFS节点呢？&lt;/p&gt;
&lt;p&gt;本文在&lt;code&gt;macOS 11.2.3&lt;/code&gt;系统上搭建了一个IPFS节点（命令行版本），并对文件上传、下载、网络同步、&lt;code&gt;pin&lt;/code&gt;、&lt;code&gt;GC&lt;/code&gt;、&lt;code&gt;IPNS&lt;/code&gt;等进行了实际操作，以加深对IPFS工作原理的理解。&lt;/p&gt;
&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;wget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_darwin-amd64.tar.gz
tar -xvzf go-ipfs_v0.8.0_darwin-amd64.tar.gz
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; go-ipfs
./install.sh
ipfs --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动&#34;&gt;启动&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动节点&lt;/span&gt;
ipfs init

&lt;span class=&#34;c1&#34;&gt;# 上传文件&lt;/span&gt;
ipfs add ipfs_init_readme.png

&lt;span class=&#34;c1&#34;&gt;# 上传文件并且只输出哈希值&lt;/span&gt;
ipfs add -q ipfs_init_readme.png

&lt;span class=&#34;c1&#34;&gt;# 上传目录&lt;/span&gt;
ipfs add -r &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查看文件&lt;/span&gt;
ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme
ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/quick-start

&lt;span class=&#34;c1&#34;&gt;# 查看自己上传的文件&lt;/span&gt;
ipfs cat QmaP3QS6ZfBoEaUJZ3ZfRKoBm3GGuhQSnUWtkVCNc8ZLTj

&lt;span class=&#34;c1&#34;&gt;# 查看图片并输出到文件&lt;/span&gt;
ipfs cat QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH &amp;gt; ipfsTest.png

&lt;span class=&#34;c1&#34;&gt;# 下载文件&lt;/span&gt;
ipfs get QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH -o ipfsTest.png

&lt;span class=&#34;c1&#34;&gt;# 压缩并下载文件&lt;/span&gt;
ipfs get QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH -Cao ipfsTest.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_init_readme.png&#34; alt=&#34;ipfs_init_readme&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;开启加入服务&#34;&gt;开启/加入服务&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看当前节点信息 &lt;/span&gt;
ipfs id

&lt;span class=&#34;c1&#34;&gt;# 查看IPFS配置信息&lt;/span&gt;
ipfs config show

&lt;span class=&#34;c1&#34;&gt;# 开启节点服务器&lt;/span&gt;
ipfs daemon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;API服务，默认在5001端口，可以通过 http://localhost:5001/webui 进行访问&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_webui.png&#34; alt=&#34;ipfs_webui&#34;&gt;&lt;/p&gt;
&lt;p&gt;网关服务，默认在8080端口，在浏览器里访问文件需要借助于IPFS提供的网关服务，由浏览器先访问到网关，网关去获取IPFS网络杀过了的文件。通过 http://localhost:8080/ipfs/[File Hash] 来访问上传到ipfs的文件&lt;/p&gt;
&lt;h3 id=&#34;文件操作&#34;&gt;文件操作&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 列出文件&lt;/span&gt;
ipfs files ls

&lt;span class=&#34;c1&#34;&gt;# 创建目录&lt;/span&gt;
ipfs files mkdir

&lt;span class=&#34;c1&#34;&gt;# 删除文件&lt;/span&gt;
ipfs files rm

&lt;span class=&#34;c1&#34;&gt;# 拷贝文件&lt;/span&gt;
ipfs files cp &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; /&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dest Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 移动文件&lt;/span&gt;
ipfs files mv &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; /&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dest Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 状态&lt;/span&gt;
ipfs files stat

&lt;span class=&#34;c1&#34;&gt;# 读取&lt;/span&gt;
ipfs files &lt;span class=&#34;nb&#34;&gt;read&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;使用ipns来解决文件更新问题&#34;&gt;使用IPNS来解决文件更新问题&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 使用IPNS发布内容以自动更新&lt;/span&gt;
ipfs name publish &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查询节点id指向的Hash&lt;/span&gt;
ipfs name resolve

&lt;span class=&#34;c1&#34;&gt;# 有多个站点需要更新，可以新产生一个秘钥对，使用新的key发布&lt;/span&gt;
ipfs key gen --type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;rsa --size&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2048&lt;/span&gt; mykey
ipfs name publish --key&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mykey  &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pinning&#34;&gt;Pinning&lt;/h3&gt;
&lt;p&gt;当我们向IPFS网络请求文件时，IPFS会把内容先同步的本地提供服务，使用Cache机制处理文件以防止存储空间不断增长，如果文件一段时间未被使用则会被“回收”，Pining的作用就是确保文件在本地不被“回收”。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# pin一个文件&lt;/span&gt;
ipfs pin add &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查询某一个Hash是否被pin&lt;/span&gt;
ipfs pin ls &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 删除pin的状态&lt;/span&gt;
ipfs pin rm -r &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# GC操作&lt;/span&gt;
ipfs repo gc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文主要在本地部署了IPFS文件系统并对基本操作进行了尝试，基于&lt;code&gt;macOS 11.2.3&lt;/code&gt;和&lt;code&gt;go-ipfs_v0.8.0_darwin-amd64&lt;/code&gt;版本，不同系统操作可能会因版本或依赖问题不一样，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://ipfs.io&#34;&gt;IPFS官网&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS分布式文件存储原理</title>
      <link>https://www.pseudoyu.com/zh/2021/03/25/blockchain_note_ipfs_structure/</link>
      <pubDate>Thu, 25 Mar 2021 16:30:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/25/blockchain_note_ipfs_structure/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在做学校的Case Study项目，是一个基于Ethereum平台的音乐版权管理项目，其中对于音乐作品、版权证明文件等上传用到了IPFS分布式文件存储技术，主要是利用其去重的特性来检测侵权行为。对IPFS这个系统产生了兴趣，阅读了&lt;a href=&#34;https://tech.hyperchain.cn&#34;&gt;QTech平台&lt;/a&gt;上的&lt;a href=&#34;https://tech.hyperchain.cn/tag/ipfs/&#34;&gt;IPFS系列文章&lt;/a&gt;，也查询了一些相关资料，通过本文梳理一下，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;
&lt;p&gt;我们日常使用网盘或其他服务时大多都是访问文件所在的特定的服务器（IP地址），请求文件并下载到本地，通过的是HTTP协议，本质上是基于位置寻址的，访问URL来得到一层层找到具体的文件，这种方式固然便捷，但是存在一些问题。文件依托于特定的服务器，因此一旦中心化的服务器宕机或者文件被删除了，内容将永久丢失，并且如果离服务器很远/同时访问文件的人很多的话访问速度也会比较慢；而且同样一份文件可能重复存储在不同的服务器中，造成资源的浪费；此外就是存在严重的安全隐患，DDoS、XSS、CSRF等攻击都可能对文件安全性造成威胁。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那有没有更好的解决方案呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;试想我们把文件存储在一个分布式网络里，每个节点都可以存储文件，用户可以通过访问一个类似目录索引的方式来向最近的节点互相请求文件。这就是IPFS星际文件系统的解决思路，它是一个点对点的超媒体文件存储、索引、交换协议，由Juan Benet在2014年5月发起。&lt;/p&gt;
&lt;h4 id=&#34;特点&#34;&gt;特点&lt;/h4&gt;
&lt;p&gt;IPFS想把全世界所有部署了相同文件系统的计算设备链接在一起，构建一个分布式网络来替代传统中心化的服务器模式，每个节点都可以存储文件，用户通过&lt;code&gt;DHT(Distributed Hash Table)&lt;/code&gt;分布式哈希表来获取文件，速度更快、更安全，网络安全性更强。&lt;/p&gt;
&lt;p&gt;因为通过IPFS存储的文件内容是通过分块求Hash值存储为地址的，本质上是通过多重哈希来确定文件的地址，这是一种去中心化但是基于内容寻址的方式，通过对数据本身进行加密，生成独一无二的Hash以供查找，这种方式下，即使是微小的改变，也会造成Hash结果截然不同，因此很容易能够从Hash检测内容是否被篡改，甚至不用访问文件本身。&lt;/p&gt;
&lt;p&gt;不同于传统的服务器模式，IPFS是一个统一的网络，因此已经上传的相同内容的文件不会重复存储（可以通过Hash值检验），极大地节约了整体网络资源，也更加高效。而且理论上只要节点达到一定规模，文件将永久保存，且同一个文件可以从多个（也更近）的节点下载，通讯效率也会更高。&lt;/p&gt;
&lt;p&gt;除此之外，因为是分布式网络进行存储，也可以天然地避免传统DDoS等攻击。&lt;/p&gt;
&lt;h4 id=&#34;功能&#34;&gt;功能&lt;/h4&gt;
&lt;p&gt;除了文件存储外，IPFS还有DHT组网、Bitswap文件交换等功能，之后也会单独写博文进行讲解。&lt;/p&gt;
&lt;h3 id=&#34;工作原理&#34;&gt;工作原理&lt;/h3&gt;
&lt;p&gt;作为一个文件存储系统，上传文件和下载文件是两个最基本的操作，我们分别讲一下原理。&lt;/p&gt;
&lt;h4 id=&#34;ipfs-add命令&#34;&gt;IPFS add命令&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;在IPFS系统中执行add操作就完成了上传操作，那是怎么上传的呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在IPFS文件存储系统中，每当上传一个新文件，系统会将单个文件拆分成若干个256KB的block，每个block会有一个专属的CID进行标识，这个后面会详细讲；然后计算每一个block的Hash值，并存储再一个数组中，最后对这个数组求Hash得到文件的最终Hash值；接着将文件的Hash和所有的blocks Hash的数组组成成一个对象，也就形成了一种索引结构；最后把文件block和这个索引结构全部上传到IPFS节点，同步到IPFS网络。&lt;/p&gt;
&lt;p&gt;文件上传时有两个值得注意的情况：1.文件特别小，如果文件小于1KB的话就不浪费一个block了，会直接和Hash一起上传到IPFS。2.文件特别大，比如之前上传了一个1G的视频，之后又加了几KB的字幕文件，这种情况下未变化的1G部分是不会重新分配新的空间的，而只会为追加的字母文件部分分配新的block，再重新上传Hash。&lt;/p&gt;
&lt;p&gt;因此，很好理解的是，即使是不同文件的相同部分也只会存储一份，很多文件的索引会指向同一个block，所形成的结构就是MerkleDAG数据结构。&lt;/p&gt;
&lt;p&gt;值得注意的是，当节点执行add操作时，会保留到本地blockstore中，但不会立刻主动上传到IPFS网络中，也就是说，与其连接的节点并不会存储这个文件，除非有某个节点请求过该block数据！因此，它并不是一个自动备份数据的分布式数据库。IPFS这种设计是出于网络带宽、可靠性等方面的考虑。&lt;/p&gt;
&lt;p&gt;还有一个细节就是，当节点在执行&lt;code&gt;add&lt;/code&gt;命令时，还会广播自己的块信息，并维护一个所有发给这个节点的block请求列表，一旦add命令添加到数据满足这个列表，就会主动向对应的节点发送数据并且更新列表。&lt;/p&gt;
&lt;h4 id=&#34;ipfs-get命令&#34;&gt;IPFS get命令&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;那文件上传后，要怎么查找访问呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这就关系到上文所提到的IPFS索引结构是&lt;code&gt;DHT&lt;/code&gt;（分布式哈希表），通过对&lt;code&gt;DHT&lt;/code&gt;进行访问可以很快访问得到数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_dht.png&#34; alt=&#34;ipfs_dht&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那如果想要查找一个本地没有的数据呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_get.gif&#34; alt=&#34;ipfs_get&#34;&gt;&lt;/p&gt;
&lt;p&gt;在IPFS系统中，所有和当前节点连接的节点会构成一个swarm网络，当节点发送一个文件请求(即&lt;code&gt;get&lt;/code&gt;)时，首先会在本地的blockstore里查找请求的数据，如果没找到的话，就会向swarm网络发出一个请求，通过网络中的&lt;code&gt;DHT Routing&lt;/code&gt;找到拥有该数据的节点。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;怎么知道网络中哪个（哪些）节点拥有这个请求文件呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如上文&lt;code&gt;add&lt;/code&gt;命令所讲的那样，当一个节点加入到IPFS网络中后，会告诉其它节点自己存储了什么内容（通过广播&lt;code&gt;DHT&lt;/code&gt;），这样每当有用户希望检索的内容正好在这个节点上时，其它节点就会告诉用户要从这个节点索取他想要的内容。&lt;/p&gt;
&lt;p&gt;一旦找到拥有这个数据的节点，就会把请求数据反馈回来，这样本地节点会把收到的block数据缓存一份到本地的blockstore中，这样整个网络中相当于多了一份原数据的拷贝，更多节点请求数据的话，查找就变得更容易，因此数据的不可丢失性也是基于这个原理，只要有一个节点保存着这个数据，就可以被全网获取。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在项目中，上传的文件可以通过&lt;code&gt;ipfs.io&lt;/code&gt;网关直接获取到文件，类似于&lt;code&gt;https://ipfs.io/ipfs/Qm.....&lt;/code&gt;这样的网站地址，这个是什么原理呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_io_get.gif&#34; alt=&#34;ipfs_io_get&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ipfs.io&lt;/code&gt;网关实际上就是一个IPFS节点，当我们打开上述这个网络链接的时候，实际上就是向这个节点发送了一次请求，因此&lt;code&gt;ipfs.io&lt;/code&gt;网关会帮我们去向拥有这个数据的节点请求这个block（如果这个文件是自己刚在本地节点通过&lt;code&gt;add&lt;/code&gt;命令添加的话就会通过这种方式被上传到IPFS网络上），在&lt;code&gt;swarm&lt;/code&gt;网络中通过&lt;code&gt;DHT Routing&lt;/code&gt;获取到数据后，网关会自己先缓存一份，然后将数据通过HTTP协议发给我们，因此，就可以在浏览器直接看到这个文件啦！&lt;/p&gt;
&lt;p&gt;而任何其他机器通过浏览器访问这个链接时，因为&lt;code&gt;ipfs.io&lt;/code&gt;网关已经缓存了这个文件，再次请求的时候，就不需要向原节点来请求数据了，可以直接从缓存中返回数据给浏览器。&lt;/p&gt;
&lt;h3 id=&#34;内容标识符cidcontent-id&#34;&gt;内容标识符CID(Content-ID)&lt;/h3&gt;
&lt;p&gt;现在考虑另一个问题，我们常见的图像为&lt;code&gt;.jpg&lt;/code&gt;、&lt;code&gt;.png&lt;/code&gt;，而常见的视频则是&lt;code&gt;.mp4&lt;/code&gt;一样，可以直接从后缀名判断文件类型。通过IPFS上传的文件也可以是多种类型，也包含了很多信息，怎么进行分辨呢？&lt;/p&gt;
&lt;p&gt;IPFS早期主要使用&lt;code&gt;base58btc&lt;/code&gt;对&lt;code&gt;multihash&lt;/code&gt;进行编码，但是在开发IPLD（主要用来定义数据，给数据建模）的过程中会遇到很多与格式相关的问题，因此使用了一种叫&lt;code&gt;CID&lt;/code&gt;的文件寻址格式来对不同格式的数据进行管理，官方的定义为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;CID&lt;/code&gt;是一种自描述式的内容寻址的识别符，必须使用加密散列函数来得到内容的地址&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说，&lt;code&gt;CID&lt;/code&gt;通过一些机制来对文件所包含的内容进行自描述，包含了版本信息、格式等。&lt;/p&gt;
&lt;h4 id=&#34;cid结构&#34;&gt;CID结构&lt;/h4&gt;
&lt;p&gt;目前&lt;code&gt;CID&lt;/code&gt;有&lt;code&gt;v0&lt;/code&gt;和&lt;code&gt;v1&lt;/code&gt;两种版本，&lt;code&gt;v1&lt;/code&gt;版本的&lt;code&gt;CID&lt;/code&gt;由&lt;code&gt;V1Builder&lt;/code&gt;生成&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;cidv1&amp;gt; ::= &amp;lt;mb&amp;gt;&amp;lt;version&amp;gt;&amp;lt;mcp&amp;gt;&amp;lt;mh&amp;gt;
# or, expanded:
&amp;lt;cidv1&amp;gt; ::= &amp;lt;multibase-prefix&amp;gt;&amp;lt;cid-version&amp;gt;&amp;lt;multicodec-packed-content-type&amp;gt;&amp;lt;multihash-content-address&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如上面列举的代码所示，采用的机制叫&lt;code&gt;multipleformats&lt;/code&gt;，主要包括：&lt;code&gt;multibase-prefix&lt;/code&gt;表示&lt;code&gt;CID&lt;/code&gt;编码成字符串，&lt;code&gt;cid-version&lt;/code&gt;表示版本变量，&lt;code&gt;multicodec-packed-content-type&lt;/code&gt;表示内容的类型和格式（类似于后缀，但是作为标识符的一部分，支持的格式有限，且用户是不能随意修改的），&lt;code&gt;multihash-content-address&lt;/code&gt;表示哈希值（让&lt;code&gt;CID&lt;/code&gt;可以使用不同的Hash函数）。&lt;/p&gt;
&lt;p&gt;目前&lt;code&gt;CID&lt;/code&gt;支持的&lt;code&gt;multicodec-packed&lt;/code&gt;编码有原生的&lt;code&gt;protobuf&lt;/code&gt;格式、&lt;code&gt;IPLD CBOR&lt;/code&gt;格式、&lt;code&gt;git&lt;/code&gt;、比特币和以太坊对象等格式，也在逐步开发支持更多格式。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CID&lt;/code&gt;代码详解：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Cid&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;str&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;V0Builder&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;V1Builder&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;Codec&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;MhType&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;MhLength&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Default: -1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Codec&lt;/code&gt;表示内容的编码类型，如&lt;code&gt;DagProtobuf&lt;/code&gt;, &lt;code&gt;DagCBOR&lt;/code&gt;等，&lt;code&gt;MhType&lt;/code&gt;表示哈希算法，如&lt;code&gt;SHA2_256&lt;/code&gt;, &lt;code&gt;SHA2_512&lt;/code&gt;, &lt;code&gt;SHA3_256&lt;/code&gt;, &lt;code&gt;SHA3_512&lt;/code&gt;等，而&lt;code&gt;MhLength&lt;/code&gt;则表示生成哈希的长度。&lt;/p&gt;
&lt;p&gt;而&lt;code&gt;v0&lt;/code&gt;版本的&lt;code&gt;CID&lt;/code&gt;由&lt;code&gt;V0Builder&lt;/code&gt;生成，以&lt;code&gt;Qm&lt;/code&gt;字符串开头，向后兼容，&lt;code&gt;multibase&lt;/code&gt;一直为&lt;code&gt;base58btc&lt;/code&gt;，&lt;code&gt;multicodec&lt;/code&gt;一直为&lt;code&gt;protobuf-mdag&lt;/code&gt;，&lt;code&gt;cid-version&lt;/code&gt;一直为&lt;code&gt;cidv0&lt;/code&gt;，&lt;code&gt;multihash&lt;/code&gt;表示为&lt;code&gt;cidv0 ::= &amp;lt;multihash-content-address&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;设计理念&#34;&gt;设计理念&lt;/h4&gt;
&lt;p&gt;通过&lt;code&gt;CID&lt;/code&gt;这种二进制的特性，大大提高了对于文件Hash的压缩效率，因此可以直接作为URL的一部分进行访问；通过&lt;code&gt;multibase&lt;/code&gt;的编码形式（如&lt;code&gt;base58btc&lt;/code&gt;）缩短了&lt;code&gt;CID&lt;/code&gt;的长度，这样更容易传输；可以表示任意格式、任何哈希函数的结果，十分灵活；可以通过结构中&lt;code&gt;cid-version&lt;/code&gt;参数进行编码版本的升级；不受限于历史内容。&lt;/p&gt;
&lt;h3 id=&#34;ipns&#34;&gt;IPNS&lt;/h3&gt;
&lt;p&gt;如上文所述，IPFS中文件内容的改变会造成其哈希值的变化，在实际应用中，如果通过IPFS托管网站等需要版本更新迭代的应用，每一次都通过更新后的Hash访问很不方便，因此，需要一个映射方案以保证用户体验，这样用户在访问时仅需要访问一个固定地址。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IPNS(Inter-Planetary Naming System)&lt;/code&gt;就提供了这样的服务，它提供了一个被私钥限定的哈希ID（通常是PeerID）来指向具体的IPFS文件，文件更新后会自动更新哈希ID的指向。&lt;/p&gt;
&lt;p&gt;即使哈希值可以固定不变了，但是依然不便于记忆和输入，因此，有了更进一步的解决方案。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IPNS&lt;/code&gt;同样兼容&lt;code&gt;DNS&lt;/code&gt;，可以使用&lt;code&gt;DNS TXT&lt;/code&gt;记录域名对应的&lt;code&gt;IPNS&lt;/code&gt;哈希ID，就可以域名来替换IPNS哈希ID来进行访问，从而实现更容易读写和记忆。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对&lt;code&gt;IPFS&lt;/code&gt;分布式存储原理的梳理，它的组件、存储流程细节、GC机制、数据交换模块Bitswap、网络以及实际应用场景都有很多值得深入挖掘的部分。&lt;/p&gt;
&lt;p&gt;推荐阅读：趣链科技QTech平台《&lt;a href=&#34;https://tech.hyperchain.cn/tag/ipfs/&#34;&gt;IPFS系列文章&lt;/a&gt;》&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://ipfs.io&#34;&gt;IPFS官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.hyperchain.cn/ipfs/&#34;&gt;原来IPFS是这样存储文件的&lt;/a&gt;，&lt;em&gt;QTech，趣链科技&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/news/277198&#34;&gt;IPFS到底怎么工作的？&lt;/a&gt;，&lt;em&gt;知辉&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://learnblockchain.cn/2018/12/12/what-is-ipfs&#34;&gt;站在Web3.0理解IPFS是什么&lt;/a&gt;，&lt;em&gt;Tiny熊，登链社区&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@kidinamoto/ipfs-cid-%E7%A0%94%E7%A9%B6-717c4ceb14a0&#34;&gt;IPFS CID研究&lt;/a&gt;，&lt;em&gt;Sophie Huang&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>Hyperledger Fabric架构详解</title>
      <link>https://www.pseudoyu.com/zh/2021/03/20/blockchain_note_hyperledger_fabric_structure/</link>
      <pubDate>Sat, 20 Mar 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/20/blockchain_note_hyperledger_fabric_structure/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;因为毕业Case Study的项目主要是基于&lt;code&gt;Ethereum&lt;/code&gt;公链，也没有面向企业的应用场景，所以之前对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;的了解大多只是停留在它的权限管理机制、通道、灵活的智能合约编写等几个特色的概念，对它的架构、各个节点的角色、运行机制等都是一知半解。最近在上HKU的&lt;code&gt;&amp;lt;FITE3011 Distributed Ledger and Blockchain&amp;gt;&lt;/code&gt;课程，教授对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;的工作原理、网络搭建及链码相关的知识做了很详细的讲解，受益匪浅，通过本文来梳理一下，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;hyperledger概述&#34;&gt;Hyperledger概述&lt;/h2&gt;
&lt;p&gt;要学习&lt;code&gt;Hyperledger Fabric&lt;/code&gt;，先来看看它的母项目&lt;code&gt;Hyperledger&lt;/code&gt;是什么。&lt;/p&gt;
&lt;p&gt;企业级应用有较复杂的业务逻辑和参与者角色划分，对于业务执行效率、安全性要求很高，并且针对常见的如支付、数据/信息交易等场景，隐私保护也是重中之重，因此，常见的比特币、以太坊等公链并不符合大部分企业应用需求。但是区块链的分布式、不可篡改的历史账本等特性在溯源、跨境电商等场景中又能够避免因各个国家/地区法律法规、货币等造成的复杂操作流程，大大提高效率。因此，针对企业的联盟链也在不断发展。&lt;/p&gt;
&lt;p&gt;联盟链严格意义上并不是真正的“去中心化”，它通过引入了权限管理机制（结合企业在现实业务中的角色）来弱化对节点作恶的预防机制，从而能提高效率、应对复杂的业务逻辑。&lt;/p&gt;
&lt;p&gt;其中，&lt;code&gt;Hyperledger&lt;/code&gt;是由Linux基金会维护的一组专注于跨行业分布式技术的开源项目，旨在创建企业级、开源、分布式的分类框架和代码库来支持业务用例，提供中立、开放和社区驱动的基础设施；建立技术社区并推广，开发区块链和共享账本概念验证、使用案例、试验和部署；建立行业标准，鼓励更多企业参与到分布式账本技术的建设和应用中来，形成一个开放的生态体系；教育公众关于区块链科技的市场机会。&lt;/p&gt;
&lt;h3 id=&#34;设计理念&#34;&gt;设计理念&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_design_philosophy.png&#34; alt=&#34;hyperledger_design_philosophy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Hyperledger&lt;/code&gt;有如下几个核心设计理念：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;它针对企业具体的业务场景提升效率，并且对溯源等场景有着独特优势，每个企业都可以针对自己的场景维护独立的&lt;code&gt;Hyperledger&lt;/code&gt;项目，因此，它不需要像公链一样通过数字货币来激励用户参与区块链系统。&lt;/li&gt;
&lt;li&gt;企业的应用场景较为复杂，往往Hyperledger只是在其中参与了某个或某些环节，因此与其他现有系统的交互必不可少，因此Hyperledger在设计上注重配备完整的API以供其他系统调用与交互。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hyperledger&lt;/code&gt;的框架结构是模块化、可拓展，企业可以根据具体的业务需求选择不同的模块，避免复杂的业务逻辑和臃肿的系统。&lt;/li&gt;
&lt;li&gt;企业应用的安全性是重中之重，尤其是许多应用场景牵扯到高价值交易或敏感数据，因此提供了很多机制来保障安全性（如&lt;code&gt;Fabric&lt;/code&gt;的通道机制等）&lt;/li&gt;
&lt;li&gt;除了与现有的系统交互外，企业未来的区块链应用中还可能会和很多不同的区块链网络进行交互，因此大部分智能合约/应用应该具备跨区块链网络的可移植性，以形成更复杂和强大的网络。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_family.png&#34; alt=&#34;hyperledger_family&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;框架&#34;&gt;框架&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Hyperledger&lt;/code&gt;下有如下几个项目，其中&lt;code&gt;Fabric&lt;/code&gt;目前应用最为广泛，本文也将主要介绍&lt;code&gt;Fabric&lt;/code&gt;区块链网络&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Burrow&lt;/li&gt;
&lt;li&gt;Fabric&lt;/li&gt;
&lt;li&gt;Grid&lt;/li&gt;
&lt;li&gt;Indy&lt;/li&gt;
&lt;li&gt;Iroha&lt;/li&gt;
&lt;li&gt;Sawtooth&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;工具&#34;&gt;工具&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Hyperledger Cello&lt;/code&gt;。主要用于更方便地搭建和管理区块链服务，降低项目框架部署、维护的复杂度；可以用来搭建区块链BaaS平台；可以通过Dashboard来创建和管理区块链，技术人员可以更方便地进行开发和部署；可以将SaaS部署模型引入区块链系统，帮助企业进一步开发框架。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hyperledger Explorer&lt;/code&gt;。是一个可视化区块链的操作工具，可以用于创建对用户友好的Web应用程序；是首个&lt;code&gt;Hyperledger&lt;/code&gt;的区块链浏览器，用户可以查看/调用/部署/查询交易、网络、智能合约、存储等信息。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hyperledger-fabric&#34;&gt;Hyperledger Fabric&lt;/h2&gt;
&lt;p&gt;我们着重来讲讲其中应用最广泛的&lt;code&gt;Fabric&lt;/code&gt;项目，它是由Linux基金会维护的一个模块化、可拓展的区块链联盟链项目，不依赖任何加密货币，它对有着共同目标（业务需求）但彼此不完全信息的实体之间的业务提供了保护，例如跨境电商、资金交易、溯源等。&lt;/p&gt;
&lt;h3 id=&#34;架构&#34;&gt;架构&lt;/h3&gt;
&lt;p&gt;在大部分公链中，架构为&lt;code&gt;Order - Execute - Validate - Update State&lt;/code&gt;。如比特币区块链中，如果有一个新交易，会先采用PoW机制对Block进行排序，然后比特币网络中的每个节点逐个进行验证，最后更新状态。因为需要依序进行验证，这种方式决定了其执行效率相对较低。&lt;/p&gt;
&lt;p&gt;而&lt;code&gt;Fabric&lt;/code&gt;采用了&lt;code&gt;Execute - Order - Validate - Update State&lt;/code&gt;架构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_architecture.png&#34; alt=&#34;hyperledger_fabric_architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;收到一笔新的交易后，首先提交至背书节点本地模拟交易执行（并背书），再将已背书交易排序并广播，各个节点对交易进行验证后更新状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_architecture_complete.png&#34; alt=&#34;hyperledger_fabric_architecture_complete&#34;&gt;&lt;/p&gt;
&lt;p&gt;正如上述联盟链特性中所述，&lt;code&gt;Fabric&lt;/code&gt;网络的加入需要得到许可（身份验证），&lt;code&gt;Fabric&lt;/code&gt;网路中的每个节点都有自己的身份。&lt;/p&gt;
&lt;p&gt;总的来说，&lt;code&gt;Fabric&lt;/code&gt;通过模块化、可插拔的架构来支持企业的复杂业务场景，通过身份验证（绑定现实身份）来弱化节点作恶，使用通道机制大大提升了系统的安全性和隐私保护。&lt;/p&gt;
&lt;h4 id=&#34;msp成员服务提供商&#34;&gt;MSP成员服务提供商&lt;/h4&gt;
&lt;p&gt;那么，参与&lt;code&gt;Fabric&lt;/code&gt;网络的身份是怎样管理的呢？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;有一个MSP(Membership Service Provider)成员管理提供商，它主要用来管理CA证书来验证哪些成员是可信任的。&lt;code&gt;Fabric CA&lt;/code&gt;模块是独立的，可以管理证书服务，也可以允许第三方CA的接入，大大拓展的系统的应用范围。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_ca_structure.png&#34; alt=&#34;hyperledger_fabric_ca_structure&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，&lt;code&gt;Fabric CA&lt;/code&gt;提供了客户端和SDK两种方式来和CA进行交互，每个&lt;code&gt;Fabric CA&lt;/code&gt;都有一个根CA或中间CA，为了进一步提高CA的安全性，可以采用集群来搭建中间CA。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_ca_hierarchy.png&#34; alt=&#34;hyperledger_fabric_ca_hierarchy&#34;&gt;&lt;/p&gt;
&lt;p&gt;更具体一点看CA的层级体系，一般是采用根CA、业务CA和用户CA三层树结构，所有的下层CA会继承上层CA的信任体系。根CA用来签发业务CA，业务CA用来签发具体的用户CA（身份认证CA、交易签名、安全通讯CA等）&lt;/p&gt;
&lt;h4 id=&#34;通道&#34;&gt;通道&lt;/h4&gt;
&lt;p&gt;上文提到&lt;code&gt;Fabric&lt;/code&gt;用Channel通道机制来保障交易的安全和隐私性，本质上每一个通道就是一个独立的账本，也是一个独立的区块链，有着不同的世界状态，网络中的一个节点可以同时加入多个通道。这种机制可以很好地划分不同的业务场景，也不用担心交易信息泄漏问题。&lt;/p&gt;
&lt;h4 id=&#34;链码&#34;&gt;链码&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;也有类似以太坊的智能合约，称为Chaincode链码，智能合约使外部的应用程序可以和&lt;code&gt;Fabric&lt;/code&gt;网络中的账本进行交互。不同于&lt;code&gt;Ethereum&lt;/code&gt;，&lt;code&gt;Fabric&lt;/code&gt;使用Docker而不是特定的虚拟机来存放链码，提供了一个安全、轻便的语言执行环境。&lt;/p&gt;
&lt;p&gt;链码主要分成系统链码和用户链码两种，系统链码嵌入在系统内，提供对系统进行配置、管理的支持；而用户链码则是运行在单独的Docker容器中，提供对上层应用的支持，用户通过链码相关的API编写用户链码，即可对账本中状态进行更新操作。&lt;/p&gt;
&lt;p&gt;链码经过安装和实例化操作后即可被调用，在安装的时候需要指定具体安装到哪个Peer节点（有的节点可以没有链码），实例化时还需要指定通道及背书策略。&lt;/p&gt;
&lt;p&gt;链码之间也可以相互调用，从而创建更灵活的应用逻辑。&lt;/p&gt;
&lt;h4 id=&#34;共识机制&#34;&gt;共识机制&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;中广义的共识机制包括背书、排序和验证三个环节，狭义的共识是指排序，&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;区块链网络中，不同参与者之间交易必须按照发生的顺序写到分布式账本中，依赖共识机制，主要有三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOLO（只限于开发）&lt;/li&gt;
&lt;li&gt;Kafka（一种消息平台）&lt;/li&gt;
&lt;li&gt;Raft（相比Kafka更中心化）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;网络协议&#34;&gt;网络协议&lt;/h4&gt;
&lt;p&gt;那&lt;code&gt;Fabric&lt;/code&gt;网络中各个节点的状态分发又是怎么进行的呢？&lt;/p&gt;
&lt;p&gt;外界的客户端是通过&lt;code&gt;gRPC&lt;/code&gt;来对&lt;code&gt;Fabric&lt;/code&gt;网络中的各个节点进行远程调用，而&lt;code&gt;P2P&lt;/code&gt;网络中各个节点之间的同步是通过&lt;code&gt;Gossip&lt;/code&gt;协议来进行的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gossip&lt;/code&gt;协议主要是用于网络中多个节点之间的数据交换，比较容易实现且容错率很高，原理就是数据发送一方从网络中随机选取若干个节点发送过去，等几个节点接收到这些数据后再随机发送给除了发送方外的若干节点，不断重复，最终所有节点达成一致（复杂度为LogN）。&lt;/p&gt;
&lt;h4 id=&#34;分布式账本&#34;&gt;分布式账本&lt;/h4&gt;
&lt;p&gt;最终所有的交易都会记录到分布式账本中，这也是区块链诸多特性的核心。&lt;code&gt;Fabric&lt;/code&gt;中交易可以存储相关业务信息，区块是一组排列后的交易集合，将区块通过密码算法链接起来就是区块链。分布式账本主要记录世界状态（最新的分布式账本状态，一般使用&lt;code&gt;CouchDB&lt;/code&gt;以方便查询）和事务日志（世界状态的更新历史，记录区块链结构，使用&lt;code&gt;LevelDB&lt;/code&gt;），对账本的每个操作都会记录在日志中，不可篡改。&lt;/p&gt;
&lt;h4 id=&#34;应用编程接口&#34;&gt;应用编程接口&lt;/h4&gt;
&lt;p&gt;对于基于&lt;code&gt;Fabric&lt;/code&gt;的应用，则主要提供了SDK开发工具包和CLI命令行两种方式进行交互。&lt;/p&gt;
&lt;h3 id=&#34;fabric区块链核心角色&#34;&gt;Fabric区块链核心角色&lt;/h3&gt;
&lt;p&gt;首先要提的是&lt;code&gt;Fabric&lt;/code&gt;网络中的角色都是逻辑角色，比如Peer节点A可能既是排序节点，也可能在某些业务中是背书节点，而一个角色也不仅仅由单一节点担任。&lt;/p&gt;
&lt;p&gt;接下来介绍一下各个角色的作用和职能。&lt;/p&gt;
&lt;p&gt;Clients客户端主要给交易签名，提交交易Proposal给背书节点，接收已经背书后的交易广播给排序节点；背书节点则是本地模拟执行交易Proposal验证交易（策略由Chaincode制定），签名并返回已背书交易；排序节点则将交易打包为block然后广播至各个节点，不参与交易的执行和验证，多个排序节点可以组成OSN；所有的节点都维护区块链账本。&lt;/p&gt;
&lt;h3 id=&#34;优势总结&#34;&gt;优势总结&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;通过将企业应用的各个复杂环节分配到各个逻辑角色节点（背书、排序等），不需要所有节点都承担如排序这样资源消耗较大的操作，消除了网络瓶颈；分配了角色后某些交易只在特定的节点部署和执行，且可以并发执行，大大提升效率和安全性，也隐藏了一些商业逻辑；因此，可以根据不同的业务需要来形成多种灵活的分配方案，极大增强了系统的拓展性。&lt;/p&gt;
&lt;p&gt;将共识机制、权限管理、加密机制、账本等模块都设置为可插拔，且不同的链码可以设置不同的背书策略，信任机制更加灵活，这样可以根据业务需要设置自己的高效系统。&lt;/p&gt;
&lt;p&gt;成员身份管理的&lt;code&gt;Fabric CA&lt;/code&gt;作为单独的项目，能够提供更多功能，也能够与很多第三方CA直接进行接入和交互，功能更强大，适合企业复杂的场景。&lt;/p&gt;
&lt;p&gt;多通道的特性是不同通道之间的数据彼此隔离，提高了安全性和隐私保护。&lt;/p&gt;
&lt;p&gt;链码支持如&lt;code&gt;Java&lt;/code&gt;、&lt;code&gt;Go&lt;/code&gt;、&lt;code&gt;Node&lt;/code&gt;等不同的编程语言，更加灵活，也支持更多第三方拓展应用，降低了业务迁移和维护成本。&lt;/p&gt;
&lt;h3 id=&#34;fabric应用开发及交互&#34;&gt;Fabric应用开发及交互&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_application_interact.png&#34; alt=&#34;hyperledger_fabric_application_interact&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图就是作为一个区块链开发者在应用&lt;code&gt;Fabric&lt;/code&gt;区块链中的开发和交互流程。&lt;/p&gt;
&lt;p&gt;开发者主要负责开发应用和智能合约（链码），应用通过SDK与智能合约进行交互，而智能合约的逻辑可以对账本进行&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;put&lt;/code&gt;、&lt;code&gt;delete&lt;/code&gt;等操作。&lt;/p&gt;
&lt;h3 id=&#34;fabric工作流程&#34;&gt;Fabric工作流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_transaction_flow.png&#34; alt=&#34;hyperledger_fabric_transaction_flow&#34;&gt;&lt;/p&gt;
&lt;p&gt;接下来通过一个完整的交易流来梳理一下&lt;code&gt;Fabric&lt;/code&gt;网络的工作原理
0. 在所有操作之前，需要向CA获取合法身份并且指定通道&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，Client提交交易Proposal（含自己的签名）至背书节点&lt;/li&gt;
&lt;li&gt;背书节点接收到交易Proposal后用本地状态模拟执行，对交易进行背书、签名并返回（其中包含Read-Write Set、签名等）&lt;/li&gt;
&lt;li&gt;Client收集到足够的背书后（策略由Chaincode制定，如图中示例为得到2个背书）提交已背书交易至排序节点（OSN）&lt;/li&gt;
&lt;li&gt;排序节点将交易打包成blocks，排序（不执行或验证交易正确性）并广播至所有节点&lt;/li&gt;
&lt;li&gt;所有节点对新blocks进行验证并提交至账本&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_processes.png&#34; alt=&#34;hyperledger_fabric_processes&#34;&gt;&lt;/p&gt;
&lt;p&gt;接下来对每个环节进行一些详细的拆解&lt;/p&gt;
&lt;h4 id=&#34;执行背书环节&#34;&gt;执行/背书环节&lt;/h4&gt;
&lt;p&gt;Client提交交易proposal后，背书节点会首先核对Client的签名，用本地状态模拟执行，对交易进行签名和Read-Write Set回Clients，R-W Sets主要包含&lt;code&gt;key&lt;/code&gt;, &lt;code&gt;version&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt;三个属性，Read-Set包含交易执行中读取的所有变量和其&lt;code&gt;version&lt;/code&gt;，对账本进行write操作的话&lt;code&gt;version&lt;/code&gt;会产生变化，Write-Set包含所有被编辑的变量及其新值。&lt;/p&gt;
&lt;p&gt;背书节点在执行交易时值根据本地区块链的状态检查链码是否正确，执行并返回。&lt;/p&gt;
&lt;p&gt;Fabric支持多种背书策略，Client在提交至排序节点前会验证是否满足背书要求，值得注意的是如果只做了查询账本操作，Client不会提交至OSN。&lt;/p&gt;
&lt;p&gt;上文所提到的交易proposal主要含括链码、链码的输入值、Client的签名，而背书节点返回至Client的的信息则包括返回值、模拟执行结果的R-W Set以及背书节点的签名，组合起来则是已背书节点。&lt;/p&gt;
&lt;p&gt;背书是相关组织对交易的认可，即相关节点对交易进行签名。对于一个链码交易来说，背书策略是在链码实例化的时候指定的，一笔有效交易必须是背书策略相关组织签名才能生效，本质上&lt;code&gt;Fabric&lt;/code&gt;区块链中的交易验证是基于对背书节点的信任，这也是称&lt;code&gt;Fabric&lt;/code&gt;并不是严格意义上的去中心化的原因之一。&lt;/p&gt;
&lt;p&gt;以下是一个简单的链码执行示例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;SimpleChaincode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;InitLedger&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;contractapi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;TransactionContextInterface&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Test Product&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Just a test product to make sure chaincode is running&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CreatedBy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;admin&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ProductId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

	&lt;span class=&#34;nx&#34;&gt;productAsBytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Marshal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

	&lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;GetStub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;PutState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;productAsBytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在这个简单示例中，链码的主要操作就是更新了&lt;code&gt;key-value&lt;/code&gt;值，经过了这个操作后，&lt;code&gt;version&lt;/code&gt;会变化。&lt;/p&gt;
&lt;p&gt;执行后返回的R-W Set为&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Test Product&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Just a test product to make sure chaincode is running&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CreatedBy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;admin&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ProductId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;的Json形式&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;排序环节&#34;&gt;排序环节&lt;/h4&gt;
&lt;p&gt;Client提交已背书的交易至排序节点（排序节点可通过一些共识策略组成OSN），排序节点接收到交易后，会打包成blocks并按照配置中的规则进行排序，在此过程中，只执行排序操作，而不进行任何执行或验证，排序完成后发送至所有节点。&lt;/p&gt;
&lt;p&gt;排序服务用来对全网交易达成一致，只负责对交易顺序达成一致，避免了整个网络瓶颈，更容易横向拓展以提升网络效率，目前支持&lt;code&gt;Kafka&lt;/code&gt;和&lt;code&gt;Raft&lt;/code&gt;两种，&lt;code&gt;Fabric&lt;/code&gt;区块链网络的统一/完整性依赖于排序节点的一致性。&lt;/p&gt;
&lt;p&gt;Raft共识机制属于非拜占庭共识机制，使用了领导者和跟随者（Leader和Follower）模型，当一个Leader被选出，日志信息会从Leader向Follower单向复制，更容易管理，在设计上允许所有节点都可以称为Orderer节点，相比Kafka更中心化，其实也允许采用PBFT共识机制，但是性能往往很差。&lt;/p&gt;
&lt;h4 id=&#34;验证环节&#34;&gt;验证环节&lt;/h4&gt;
&lt;p&gt;当节点接收到由排序节点发送来的区块时，会对区块中的所有交易进行验证并标记是否可信，主要验证两个方面：1.是否满足背书策略。2.交易结构的合法性，是否有状态冲突，如Read-Set中的&lt;code&gt;version&lt;/code&gt;是否一致等。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;架构的梳理了，虽然取舍了部分去中心化的理念，但是作为一个面向企业应用的开源联盟链，它鼓励了更多企业参与到分布式账本技术的建设和应用中来，现在国内也有很多联盟链的自研平台，如蚂蚁链、趣链等，相信未来会有更多企业参与到这个开放的生态体系！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&amp;ldquo;FITE3011 Distributed Ledger and Blockchain&amp;rdquo; Lecture Slides, &lt;em&gt;Allen Au，HKU&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yingpingzhang/enterprise_blockchain_tutorial&#34;&gt;企业级区块链实战教程&lt;/a&gt;，&lt;em&gt;张应平&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 3 Clustering</title>
      <link>https://www.pseudoyu.com/zh/2021/03/18/comp7103_topic3/</link>
      <pubDate>Thu, 18 Mar 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/18/comp7103_topic3/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-3-clustering&#34;&gt;Topic 3 Clustering&lt;/h2&gt;
&lt;h3 id=&#34;cluster-analysis&#34;&gt;Cluster Analysis&lt;/h3&gt;
&lt;p&gt;Finding groups of objects such that the objects in a group will be similar (or related) to one another and different from (or unrelated to) the objects in other groups&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/cluster_analysis.png&#34; alt=&#34;cluster_analysis&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;application&#34;&gt;Application&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Understanding
&lt;ul&gt;
&lt;li&gt;Group related documents for browsing, group genes and proteins that have similar functionality, or group stocks with similar price fluctuations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Summarization
&lt;ul&gt;
&lt;li&gt;Reduce size of large data sets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;types-of-clusterings&#34;&gt;Types of Clusterings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partitional Clustering
&lt;ul&gt;
&lt;li&gt;A division data objects into non-overlapping subsets (clusters) such that each data object is in exactly one subset
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/partitional_clustering.png&#34; alt=&#34;partitional_clustering&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hierarchical clustering
&lt;ul&gt;
&lt;li&gt;A set of nested clusters organized as a hierarchical tree
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hierarchical_clustering.png&#34; alt=&#34;hierarchical_clustering&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other Distinctions Between Sets of Clusters
&lt;ul&gt;
&lt;li&gt;Exclusive versus non-exclusive
&lt;ul&gt;
&lt;li&gt;In non-exclusive clusterings, points may belong to multiple clusters&lt;/li&gt;
&lt;li&gt;Can represent multiple classes or &amp;lsquo;border&amp;rsquo; points&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fuzzy versus non-fuzzy
&lt;ul&gt;
&lt;li&gt;In fuzzy clustering, a point belongs to every cluster with some weight between 0 and 1&lt;/li&gt;
&lt;li&gt;Weights must sum to 1&lt;/li&gt;
&lt;li&gt;Probabilistic clustering has similar characteristics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Partial versus complete
&lt;ul&gt;
&lt;li&gt;In some cases, we only want to cluster some of the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Heterogeneous versus homogeneous
&lt;ul&gt;
&lt;li&gt;Cluster of widely different sizes, shapes, and densities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;well-separated-clusters&#34;&gt;Well-separated clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of points such that any point in a cluster is closer (or more similar) to every other point in the cluster than to any point not in the cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/wellseparated_clusters.png&#34; alt=&#34;wellseparated_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;center-based-clusters&#34;&gt;Center-based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of objects such that an object in a cluster is closer (more similar) to the “center” of a cluster, than to the center of any other cluster&lt;/p&gt;
&lt;p&gt;The center of a cluster is often a centroid, the average of all the points in the cluster, or a medoid, the most “representative” point of a cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/center_based_clusters.png&#34; alt=&#34;center_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;contiguity-based-clusters&#34;&gt;Contiguity-Based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of points such that a point in a cluster is closer (or more similar) to one or more other points in the cluster than to any point not in the cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/contiguity_based_clusters.png&#34; alt=&#34;contiguity_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;density-based-clusters&#34;&gt;Density-based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a dense region of points, which is separated by low-density regions, from other regions of high density&lt;/p&gt;
&lt;p&gt;Used when the clusters are irregular or intertwined, and when noise and outliers are present&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/density_based_clusters.png&#34; alt=&#34;density_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;conceptual-clusters&#34;&gt;Conceptual Clusters&lt;/h4&gt;
&lt;p&gt;Finds clusters that share some common property or represent a particular concept&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/conceptual_clusters.png&#34; alt=&#34;conceptual_clusters&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-means&#34;&gt;K-means&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Input
&lt;ul&gt;
&lt;li&gt;integer k&amp;gt;0, set S of points in the euclidean space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Output
&lt;ul&gt;
&lt;li&gt;A (partitional) clustering of S&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Step&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select k points in S as the initial centroids&lt;/li&gt;
&lt;li&gt;Repeat until the centroids do not change
&lt;ul&gt;
&lt;li&gt;Form k clusters by assigning points to the closest centroids&lt;/li&gt;
&lt;li&gt;For each cluster recompute its centroid&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Feature&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial centroids are often chosen randomly&lt;/li&gt;
&lt;li&gt;Centroids are often the mean of the points in the cluster&lt;/li&gt;
&lt;li&gt;&amp;lsquo;Closeness&amp;rsquo; is measured by Euclidean distance, cosine similarity, correlation, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;importance-of-choosing-initial-centroids&#34;&gt;Importance of Choosing Initial Centroids&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids.png&#34; alt=&#34;choosing_Initial_centroids&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids_2.png&#34; alt=&#34;choosing_Initial_centroids_2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids_3.png&#34; alt=&#34;choosing_Initial_centroids_3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;evaluating-k-means-clusterings&#34;&gt;Evaluating K-means Clusterings&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Most common measure is Sum of Squared Error (SSE)
&lt;ul&gt;
&lt;li&gt;Given two clusterings, we can choose the one with smallest error&lt;/li&gt;
&lt;li&gt;Decreasing K might decrease SSE&lt;/li&gt;
&lt;li&gt;However, good clusterings with small K might have a lower SSE than poor clusterings with higher K&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;k-means-always-terminates&#34;&gt;K-Means Always Terminates&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Theorem
&lt;ul&gt;
&lt;li&gt;K-means with Euclidean distance as distance always terminates&lt;/li&gt;
&lt;li&gt;Proof follows from the following lemmas&lt;/li&gt;
&lt;li&gt;We cannot obtain the same clustering more than once, otherwise we get the same SSE value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 1
&lt;ul&gt;
&lt;li&gt;The point y that minimizes the SSE in a cluster C is the mean of all points in C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 2
&lt;ul&gt;
&lt;li&gt;SSE strictly decreases.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 3&lt;/li&gt;
&lt;li&gt;The total number of possible clusterings is finite (&amp;lt; n^k).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;solutions-to-initial-centroids-problem&#34;&gt;Solutions to Initial Centroids Problem&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Multiple runs (helps but low success probability)&lt;/li&gt;
&lt;li&gt;Sample and use hierarchical clustering to determine initial centroids&lt;/li&gt;
&lt;li&gt;Select more than k initial centroids and then select among these initial centroids&lt;/li&gt;
&lt;li&gt;Postprocessing&lt;/li&gt;
&lt;li&gt;K-Means++&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;handling-empty-clusters&#34;&gt;Handling Empty Clusters&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Basic K-means algorithm can yield less than k clusters (so called empty clusters)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pick the points that contributes most to SSE and move them to empty cluster&lt;/li&gt;
&lt;li&gt;Pick the points from the cluster with the highest SSE&lt;/li&gt;
&lt;li&gt;If there are several empty clusters, the above can be repeated several times&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;updating-centers-incrementally&#34;&gt;Updating Centers Incrementally&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In the basic K-means algorithm, centroids are updated after all points are assigned to a centroid&lt;/li&gt;
&lt;li&gt;An alternative is to update the centroids after each assignment (incremental approach)&lt;/li&gt;
&lt;li&gt;More precisely, let C1 ,C2 ,&amp;hellip;,C k be the current clusters. Reassign all points one by one to the best cluster. Let p in C i be the current point and suppose we re-assign it to Cj . Then, after that, recompute the centroid of C i and Cj
&lt;ul&gt;
&lt;li&gt;Never get an empty cluster&lt;/li&gt;
&lt;li&gt;Introduces an order dependency&lt;/li&gt;
&lt;li&gt;More expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pre-processing-and-post-processing&#34;&gt;Pre-processing and Post-processing&lt;/h4&gt;
&lt;p&gt;Pre-processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalize the data&lt;/li&gt;
&lt;li&gt;Eliminate outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Post-processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eliminate small clusters that may represent outliers&lt;/li&gt;
&lt;li&gt;Split &amp;lsquo;loose&amp;rsquo; clusters, i.e., clusters with relatively high SSE&lt;/li&gt;
&lt;li&gt;Merge clusters that are ‘close’ and that have relatively low SSE&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;limitations-of-k-means&#34;&gt;Limitations of K-means&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means has problems when clusters are of differing
&lt;ul&gt;
&lt;li&gt;Sizes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations.png&#34; alt=&#34;kmeans_limitations&#34;&gt;&lt;/li&gt;
&lt;li&gt;Densities
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations_density.png&#34; alt=&#34;kmeans_limitations_density&#34;&gt;&lt;/li&gt;
&lt;li&gt;Non-globular shapes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations_globular.png&#34; alt=&#34;kmeans_limitations_globular&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;K-means has problems when the data contains outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;overcoming-k-means-limitations&#34;&gt;Overcoming K-means Limitations&lt;/h4&gt;
&lt;p&gt;Use many clusters, find parts of clusters, but need to put together&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overcome_kmeans_limitations_1.png&#34; alt=&#34;overcome_kmeans_limitations_1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overcome_kmeans_limitations_2.png&#34; alt=&#34;overcome_kmeans_limitations_2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hierarchical-clustering&#34;&gt;Hierarchical clustering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Produces a set of nested clusters organized as a hierarchical tree&lt;/li&gt;
&lt;li&gt;Can be visualized as a dendrogram
&lt;ul&gt;
&lt;li&gt;A tree like diagram that records the sequences of merges or splits
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hierarchical_clustering_dendrogram.png&#34; alt=&#34;hierarchical_clustering_dendrogram&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;strengths-of-hierarchical-clustering&#34;&gt;Strengths of Hierarchical Clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Do not have to assume any particular number of clusters
&lt;ul&gt;
&lt;li&gt;Any desired number of clusters can be obtained by ‘cutting’ the dendogram at the proper level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;They may correspond to meaningful taxonomies
&lt;ul&gt;
&lt;li&gt;Example in biological sciences (e.g., animal kingdom, phylogeny reconstruction, …)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;two-main-types-of-hierarchical-clustering&#34;&gt;Two main types of hierarchical clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Agglomerative
&lt;ul&gt;
&lt;li&gt;Start with the points as individual clusters&lt;/li&gt;
&lt;li&gt;At each step, merge the closest pair of clusters until only one cluster (or k clusters) left&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Divisive
&lt;ul&gt;
&lt;li&gt;Start with one, all-inclusive cluster&lt;/li&gt;
&lt;li&gt;At each step, split a cluster until each cluster contains a point (or there are k clusters)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Traditional hierarchical algorithms use a similarity or distance matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Merge or split one cluster at a time&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;agglomerative-clustering-algorithm&#34;&gt;Agglomerative Clustering Algorithm&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Most popular hierarchical clustering technique&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let each data point be a cluster&lt;/li&gt;
&lt;li&gt;Compute the distance matrix n x n&lt;/li&gt;
&lt;li&gt;Repeat
&lt;ul&gt;
&lt;li&gt;Merge the two closest clusters&lt;/li&gt;
&lt;li&gt;Update distance matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Until only a single cluster remains&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Procedure&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Start with clusters of individual points and a distance matrix n x n
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_1.png&#34; alt=&#34;agglomerative_clustering_algorithm_1&#34;&gt;&lt;/li&gt;
&lt;li&gt;After some merging steps, we have some clusters
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_2.png&#34; alt=&#34;agglomerative_clustering_algorithm_2&#34;&gt;&lt;/li&gt;
&lt;li&gt;We want to merge the two closest clusters (C2 and C5) and update the distance matrix
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_3.png&#34; alt=&#34;agglomerative_clustering_algorithm_3&#34;&gt;&lt;/li&gt;
&lt;li&gt;The question is “How do we update the distance matrix
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_4.png&#34; alt=&#34;agglomerative_clustering_algorithm_4&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;how-to-define-inter-cluster-similarity&#34;&gt;How to Define Inter-Cluster Similarity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;MIN
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_1.png&#34; alt=&#34;inter_cluster_similarity_1&#34;&gt;&lt;/li&gt;
&lt;li&gt;MAX
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_2.png&#34; alt=&#34;inter_cluster_similarity_2&#34;&gt;&lt;/li&gt;
&lt;li&gt;Group Average
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_3.png&#34; alt=&#34;inter_cluster_similarity_3&#34;&gt;&lt;/li&gt;
&lt;li&gt;Distance Between Centroids
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_4.png&#34; alt=&#34;inter_cluster_similarity_4&#34;&gt;&lt;/li&gt;
&lt;li&gt;Other methods driven by an objective function
&lt;ul&gt;
&lt;li&gt;Ward’s Method uses squared error&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;problems-and-limitations&#34;&gt;Problems and Limitations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Once a decision is made to combine two clusters, it cannot be undone&lt;/li&gt;
&lt;li&gt;No objective function is directly minimized&lt;/li&gt;
&lt;li&gt;Different schemes have problems with one or more of the following
&lt;ul&gt;
&lt;li&gt;Sensitivity to noise and outliers&lt;/li&gt;
&lt;li&gt;Difficulty handling different sized clusters and convex shapes&lt;/li&gt;
&lt;li&gt;Breaking large clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cluster-validity&#34;&gt;Cluster Validity&lt;/h3&gt;
&lt;p&gt;Numerical measures that are applied to judge various aspects of cluster validity, are classified into the following three types&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;External Index
&lt;ul&gt;
&lt;li&gt;Used to measure the extent to which cluster labels match externally supplied class labels
&lt;ul&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Internal Index
&lt;ul&gt;
&lt;li&gt;Used to measure the goodness of a clustering structure without respect to external information
&lt;ul&gt;
&lt;li&gt;Sum of Squared Error (SSE)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relative Index
&lt;ul&gt;
&lt;li&gt;To compare two different clusterings or clusters
&lt;ul&gt;
&lt;li&gt;An external or internal index is used for this function, e.g., SSE or entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;internal-measures-sse&#34;&gt;Internal Measures: SSE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Clusters in more complicated figures aren’t well separated&lt;/li&gt;
&lt;li&gt;SSE is good for comparing two clusterings or two clusters (average SSE)&lt;/li&gt;
&lt;li&gt;Can also be used to estimate the number of clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/internal_measures_SSE.png&#34; alt=&#34;internal_measures_SSE&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;external-measures-of-cluster-validity-entropy&#34;&gt;External Measures of Cluster Validity: Entropy&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Definition: Entropy
&lt;ul&gt;
&lt;li&gt;Entropy measure how uncertain is an event, the larger the entropy the more uncertain is the event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/external_measures_of_cluster_validity_Entropy.png&#34; alt=&#34;external_measures_of_cluster_validity_Entropy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;The validation of clustering structures is the most difficult and frustrating part of cluster analysis. Without a strong effort in this direction, cluster analysis will remain a black art accessible only to those true believers who have experience and great courage.&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-means-1&#34;&gt;K-means++&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the centroids as in Algorithm 1&lt;/li&gt;
&lt;li&gt;Run K-means algorithm to improve the clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_plus_plus_algorithm1.png&#34; alt=&#34;kmeans_plus_plus_algorithm1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-comparison&#34;&gt;Algorithm Comparison&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means
&lt;ul&gt;
&lt;li&gt;No guarantees on the quality of the solution&lt;/li&gt;
&lt;li&gt;It always terminates&lt;/li&gt;
&lt;li&gt;Running time could be exponential but it is OK in practice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;K-means++
&lt;ul&gt;
&lt;li&gt;It always terminates&lt;/li&gt;
&lt;li&gt;O(log k)-approximation on the quality of the solution&lt;/li&gt;
&lt;li&gt;In practice the advantage is noticeable for large k&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 4 Top-k</title>
      <link>https://www.pseudoyu.com/zh/2021/03/06/comp7801_topic4/</link>
      <pubDate>Sat, 06 Mar 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/06/comp7801_topic4/</guid>
      
        <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;multidimensional-data&#34;&gt;Multidimensional Data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Flat relational tables&lt;/li&gt;
&lt;li&gt;Multimedia feature vectors&lt;/li&gt;
&lt;li&gt;Data warehouse data&lt;/li&gt;
&lt;li&gt;Spatial data&lt;/li&gt;
&lt;li&gt;Text documents&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;attribute-types&#34;&gt;Attribute Types&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Attributes of multidimensional tuples may have variable types
&lt;ul&gt;
&lt;li&gt;Ordinal (e.g., age, salary)&lt;/li&gt;
&lt;li&gt;Nominal categorical values (e.g., color, religion)&lt;/li&gt;
&lt;li&gt;Binary (e.g., gender, owns_property)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Basic queries: range, NN, similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-queries&#34;&gt;Basic Queries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;(Range) selection query
&lt;ul&gt;
&lt;li&gt;Returns the records that qualify a (multidimensional) range predicate&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Return the employees of age between 45 and 50 and salary above $100,000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distance (similarity) query
&lt;ul&gt;
&lt;li&gt;Returns the records that are within a distance from a reference record.&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Find images with feature vectors of Euclidean distance at most ε with the feature vector of a given image&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nearest neighbor (similarity) query
&lt;ul&gt;
&lt;li&gt;Replaces distance bound by ranking predicate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;top-k-search-methods&#34;&gt;Top-k Search Methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Rank aggregation&lt;/li&gt;
&lt;li&gt;Index-based methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query&#34;&gt;Top-k Query&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of objects (e.g., relational tuples),&lt;/li&gt;
&lt;li&gt;Returns the k objects with the highest combined score, based on an aggregate function f.&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Relational table containing information about restaurants, with attributes(e.g. price, quality, location)&lt;/li&gt;
&lt;li&gt;f: sum(-price, quality, -dist(location,my_hotel))‏&lt;/li&gt;
&lt;li&gt;attribute value ranges are usually normalized
&lt;ul&gt;
&lt;li&gt;E.g., all values in a (0,1) range&lt;/li&gt;
&lt;li&gt;otherwise some attribute may be favored in f&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query-variants&#34;&gt;Top-k Query Variants&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Apply on single table, or ranked lists of tuples ordered by individual attributes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_1.jpg&#34; alt=&#34;Top_k_Query_Variants_1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ranked inputs in the same or different servers (centralized or distributed data)
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_2.jpg&#34; alt=&#34;Top_k_Query_Variants_1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Standalone query or operator in a more complex query plan
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_3.jpg&#34; alt=&#34;Top_k_Query_Variants_3&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Incremental retrieval of objects with highest scores (k is not predefined)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Top-k joins&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;House&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;School&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;location&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;location&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;∗&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tuition&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;LIMIT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Probabilistic/approximate top-k retrieval&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random and/or sorted accesses at ranked inputs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query-evaluation&#34;&gt;Top-k Query Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Most solutions assume distributive, monotone aggregate functions (e.g. f=sum)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;distributive: f(x,y,z,w)= f(f(x,y),f(z,w))
&lt;ul&gt;
&lt;li&gt;e.g., A+B+C+D = (A+B) + (C+D)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;monotone: if x&amp;lt;y and z&amp;lt;w, then f(x,z)&amp;lt;f(y,w)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions based on 1-D ordering and merging sorted lists (rank aggregation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions based on multidimensional indexing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rank-aggregation&#34;&gt;Rank Aggregation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Solutions based on 1-D ordering and merging sorted lists (rank aggregation)&lt;/li&gt;
&lt;li&gt;Assume that there is a total ranking of theobjects for each attributethat can be used in top-kqueries&lt;/li&gt;
&lt;li&gt;These sorted inputs canbe accessed sequentiallyand/or by random accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Rank_Aggregation.jpg&#34; alt=&#34;Rank_Aggregation&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;advantages-and-drawbacks&#34;&gt;Advantages and Drawbacks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Advantages：
&lt;ul&gt;
&lt;li&gt;can be applied on any subset of inputs (arbitrary subspace)&lt;/li&gt;
&lt;li&gt;appropriate for distributed data&lt;/li&gt;
&lt;li&gt;appropriate for top-k joins&lt;/li&gt;
&lt;li&gt;easy to understand and implement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Drawbacks:
&lt;ul&gt;
&lt;li&gt;slower than index-based methods&lt;/li&gt;
&lt;li&gt;require inputs to be sorted&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ta-threshold-algorithm&#34;&gt;TA: Threshold Algorithm&lt;/h3&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Iteratively retrieves objects and their atomic scores from the ranked inputs in a round-robin fashion.&lt;/li&gt;
&lt;li&gt;For each encountered object x, perform random accesses to the inputs where x has not been seen.&lt;/li&gt;
&lt;li&gt;Maintain top-k objects seen so far.&lt;/li&gt;
&lt;li&gt;T = f($l_1$, . . . , $l_m$) is the score derived when applying the aggregation function to the last atomic scores seen at each input. If the score of the k-th object is no smaller than T, terminate.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-of-tak1fsum&#34;&gt;Example of TA(k=1,f=sum)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 1&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is c, with score 2.0&lt;/li&gt;
&lt;li&gt;T=sum(0.9,0.9,0.9)=2.7&lt;/li&gt;
&lt;li&gt;T&amp;gt;top-1, we proceed to another round of accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_1.jpg&#34; alt=&#34;TA_Step_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 2&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is b, with score 2.2&lt;/li&gt;
&lt;li&gt;T=sum(0.8,0.8,0.9)=2.5&lt;/li&gt;
&lt;li&gt;T&amp;gt;top-1, we proceed to another round of accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_2.jpg&#34; alt=&#34;TA_Step_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 3&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is b, with score 2.2&lt;/li&gt;
&lt;li&gt;T=sum(0.6,0.6,0.8)=2.0&lt;/li&gt;
&lt;li&gt;T≤top-1, terminate and output (b,2.2)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_3.jpg&#34; alt=&#34;TA_Step_3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;properties-of-ta&#34;&gt;Properties of TA&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Used as a standard module for merging ranked lists in many applications&lt;/li&gt;
&lt;li&gt;Usually finds the result quickly&lt;/li&gt;
&lt;li&gt;Depends on random accesses, which can be expensive&lt;/li&gt;
&lt;li&gt;random accesses are impossible in some cases
&lt;ul&gt;
&lt;li&gt;e.g., an API allows to access objects incrementally by ranking score, but does not provide the score of a given object&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nra-no-random-accesses&#34;&gt;NRA: No Random Accesses&lt;/h3&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Iteratively retrieves objects and their atomic scores from the ranked inputs in a round-robin fashion.&lt;/li&gt;
&lt;li&gt;For each object x seen so far at any input maintain:
&lt;ul&gt;
&lt;li&gt;f_x_ub: upper bound for x’s aggregate score (f_x)&lt;/li&gt;
&lt;li&gt;f_x_lb: lower bound for x’s aggregate score (f_x)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;W_k = k objects with the largest f^lb.&lt;/li&gt;
&lt;li&gt;If the smallest f^lb in W_k is at least the largest f_x_ub of any object x not in W_k, then terminate and report W_k as top-k result.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-of-nrak1fsum&#34;&gt;Example of NRA(k=1,f=sum)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 1&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_1.jpg&#34; alt=&#34;NRA_Step_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_2.jpg&#34; alt=&#34;NRA_Step_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 3&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_3.jpg&#34; alt=&#34;NRA_Step_3&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 4&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_4.jpg&#34; alt=&#34;NRA_Step_4&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;nra-properties&#34;&gt;NRA Properties&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;More generic than TA, since it does not depend on random accesses&lt;/li&gt;
&lt;li&gt;Can be cheaper than TA, if random accesses are very expensive&lt;/li&gt;
&lt;li&gt;NRA accesses objects sequentially from all inputs and updates the upper bounds for all objects seen so far unconditionally.
&lt;ul&gt;
&lt;li&gt;Cost: O(n) per access (the expected distinct number of objects accessed so far is O(n))&lt;/li&gt;
&lt;li&gt;No input list is pruned until the algorithm terminates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lara-lattice-based-rank-aggregation&#34;&gt;LARA: LAttice-based Rank Aggregation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LARA: An efficient NRA implementation&lt;/li&gt;
&lt;li&gt;Based on 3 observations about the top-k candidates&lt;/li&gt;
&lt;li&gt;Operates differently in the two (growing, shrinking) phases&lt;/li&gt;
&lt;li&gt;Takes its name from the lattice used in the shrinking phase&lt;/li&gt;
&lt;li&gt;Extendable to various top-k query variants&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 3 Spatial Networks</title>
      <link>https://www.pseudoyu.com/zh/2021/02/27/comp7801_topic3/</link>
      <pubDate>Sat, 27 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/27/comp7801_topic3/</guid>
      
        <description>&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;h4 id=&#34;network-distance&#34;&gt;Network Distance&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In many real applications accessibility of objects is restricted by a spatial network
&lt;ul&gt;
&lt;li&gt;Examples
&lt;ul&gt;
&lt;li&gt;Driver looking for nearest gas station&lt;/li&gt;
&lt;li&gt;Mobile user looking for nearest restaurant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shortest path distance&lt;/strong&gt; used instead of Euclidean distance&lt;/li&gt;
&lt;li&gt;SP(a,b) = path between a and b with the minimum accumulated length&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;challenges&#34;&gt;Challenges&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Euclidean distance is no longer relevant
&lt;ul&gt;
&lt;li&gt;R-tree may not be useful, when search is based on shortest path distance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph cannot be flattened to a one-dimensional space
&lt;ul&gt;
&lt;li&gt;Special storage and indexing techniques for graphs are required&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph properties may vary
&lt;ul&gt;
&lt;li&gt;directed vs. undirected&lt;/li&gt;
&lt;li&gt;length, time, etc. as edge weights&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;modeling-and-storing-spatial-networks&#34;&gt;Modeling and Storing Spatial Networks&lt;/h3&gt;
&lt;h4 id=&#34;modeling-spatial-networks&#34;&gt;Modeling Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Adjacency matrix only appropriate for dense graphs&lt;/li&gt;
&lt;li&gt;Spatial networks are sparse: use adjacency lists instead&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Modeling_Spatial_Networks.png&#34; alt=&#34;Modeling_Spatial_Networks&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;storing-large-spatial-networks&#34;&gt;Storing Large Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Problem: adjacency lists representation may not fit in memory if graph is large&lt;/li&gt;
&lt;li&gt;Solution:
&lt;ul&gt;
&lt;li&gt;partition adjacency lists to disk blocks (based on proximity)&lt;/li&gt;
&lt;li&gt;create B+-tree index on top of partitions (based on node-id)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Storing_Large_Spatial_Network.png&#34; alt=&#34;Storing_Large_Spatial_Network&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;shortest-path-search&#34;&gt;Shortest Path Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given a graph G(V,E), and two nodes s,t in V, find the shortest path from s to t&lt;/li&gt;
&lt;li&gt;A classic algorithmic problem&lt;/li&gt;
&lt;li&gt;Studied extensively since the 1950’s&lt;/li&gt;
&lt;li&gt;Several methods:
&lt;ul&gt;
&lt;li&gt;Dijkstra’s algorithm&lt;/li&gt;
&lt;li&gt;A*-search&lt;/li&gt;
&lt;li&gt;Bi-directional search&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dijkstras-shortest-path-search&#34;&gt;Dijkstra’s Shortest Path Search&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;idea: incrementally explore the graph around s, visitingnodes in distance order to suntil t is found (like NN)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_1.png&#34; alt=&#34;Dijkstra_1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_2.png&#34; alt=&#34;Dijkstra_2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_Algorithm.png&#34; alt=&#34;Dijkstra_Algorithm&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;example&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_Example.png&#34; alt=&#34;Dijkstra_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the shortest path between a and b.&lt;/li&gt;
&lt;li&gt;Worst-case performance O(|E| + |V|log|V| )&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-search&#34;&gt;A*-search&lt;/h3&gt;
&lt;h4 id=&#34;description&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dijkstra’s search explores nodes around s without a specific search direction until t is found&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Idea: improve Dijkstra’s algorithm by directing search towards t&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Due to triangular inequality, Euclidean distance is a lower bound of network distance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Euclidean distance to lower bound network distance based on known information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nodes are visited in increasing SPD(s,v)+dist(v,t) order
&lt;ul&gt;
&lt;li&gt;SPD(s,v): shortest path distance from s to v (computed by Dijkstra)&lt;/li&gt;
&lt;li&gt;dist(v,t): Euclidean distance between v and t&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Original Dijkstra visits nodes in increasing SPD(s,v) order&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/A_Star_1.png&#34; alt=&#34;A_Star_1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;example-1&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/A_Star_Example.png&#34; alt=&#34;A_Star_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating-1&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the shortest path between s and t.
&lt;ul&gt;
&lt;li&gt;f(p) = Dijkstra_dist(s, p) + Euclidean_dist(p, t)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bi-directional-search&#34;&gt;Bi-directional search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra’s search explores nodes around s without a specific search direction until t is found&lt;/li&gt;
&lt;li&gt;Idea: search can be performed concurrently from s and from t (backwards)&lt;/li&gt;
&lt;li&gt;The shortest path tree of s and the (backward) shortest path tree of t are computed in concurrently
&lt;ul&gt;
&lt;li&gt;One queue Q_s for forward and one queue Q_t for backward search&lt;/li&gt;
&lt;li&gt;Node visits are prioritized based on min(SPD(s,v), SPD(v,t))&lt;/li&gt;
&lt;li&gt;If v already visited from s and v is in Qt, then candidate shortest path: p(s,v)+p(v,t)  (if v already visited from t and v in Q_s symmetric)&lt;/li&gt;
&lt;li&gt;If v is visited by both s and t terminate search; report best candidate shortest path&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-2&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Bi_Directional_Example.png&#34; alt=&#34;Bi_Directional_Example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;discussions&#34;&gt;Discussions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A* and bi-directional search can be combined to powerful search techniques&lt;/li&gt;
&lt;li&gt;A* can only be applied if lower distance bounds are available&lt;/li&gt;
&lt;li&gt;All versions of Dijkstra’s search require non-negative edge weights
&lt;ul&gt;
&lt;li&gt;Bellman-Ford is an algorithm for arbitrary negative edges&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spatial-queries-over-spatial-networks&#34;&gt;Spatial queries over spatial networks&lt;/h2&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;h4 id=&#34;sourcedestination-on-edges&#34;&gt;Source/Destination on Edges&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;We have assumed that points s and t are nodes of the network&lt;/li&gt;
&lt;li&gt;In practice s and t could be arbitrary points on edges
&lt;ul&gt;
&lt;li&gt;Mobile user locations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solve problem by introducing 2 more nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Source_Destination_on_Edges.png&#34; alt=&#34;Source_Destination_on_Edges&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;spatial-queries-over-spatial-networks-1&#34;&gt;Spatial Queries over Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data:
&lt;ul&gt;
&lt;li&gt;A (static) spatial network (e.g., city map)&lt;/li&gt;
&lt;li&gt;A (dynamic) set of spatial objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial queries based on network distance:
&lt;ul&gt;
&lt;li&gt;Selections. Ex: find gas stations within 10km driving distance from here&lt;/li&gt;
&lt;li&gt;Nearest neighbor search. Ex: find k nearest restaurants from present position&lt;/li&gt;
&lt;li&gt;Joins. Ex: find pairs of restaurants and hotels at most 100m from each other&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Spatial_Queries_over_Spatial_Networks.png&#34; alt=&#34;Spatial_Queries_over_Spatial_Networks&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;methodology&#34;&gt;Methodology&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Store (and index) the spatial network
&lt;ul&gt;
&lt;li&gt;Graph component (indexes connectivity information)&lt;/li&gt;
&lt;li&gt;Spatial component (indexes coordinates of nodes, edges, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Store (and index) the sets of spatial objects
&lt;ul&gt;
&lt;li&gt;Ex., one spatial relation for restaurants, one spatial relation for hotels, one relation for mobile users, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Given a spatial location p, use spatial component of network to find the network edge containing p&lt;/li&gt;
&lt;li&gt;Given a network edge, use network component to traverse neighboring edges&lt;/li&gt;
&lt;li&gt;Given a neighboring edge, use spatial indexes to find objects on them&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-of-spatial-selections-1&#34;&gt;Evaluation of Spatial Selections (1)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find all objects in spatial relation R, within network distance ε from location q&lt;/li&gt;
&lt;li&gt;Method:
&lt;ul&gt;
&lt;li&gt;Use spatial index of network (R-tree indexing network edges) to find edge n_1n_2, which includes q&lt;/li&gt;
&lt;li&gt;Use adjacency index of network (graph component) and apply Dijkstra’s algorithm to progressively retrieve edges that are within network distance ε from location q&lt;/li&gt;
&lt;li&gt;For all these edges apply a spatial selection on the R-tree that indexes R to find the results&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-3&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example: Find restaurants at most distance 10 from q&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 1: find network edge which contains q&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_1.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: traverse network to find all edges (or parts of them within distance 10 from q)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_2.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: find restaurants that intersect the subnetwork computed at step 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_3.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_3&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluation-of-spatial-selections-2&#34;&gt;Evaluation of Spatial Selections (2)&lt;/h3&gt;
&lt;h4 id=&#34;description-1&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Query: find all objects in spatial relation R, within network distance ε from location q&lt;/li&gt;
&lt;li&gt;Alternative method based on Euclidean bounds:
&lt;ul&gt;
&lt;li&gt;Assumption: Euclidean distance is a lower-bound of network distance:
&lt;ul&gt;
&lt;li&gt;dist(v,u) ≤ SPD(v,u), for any v,u&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use R-tree on R to find set S of objects such that for each o in S: dist(q,o) ≤ ε&lt;/li&gt;
&lt;li&gt;For each o in S:
&lt;ul&gt;
&lt;li&gt;find where o is located in the network (use Network R-tree)&lt;/li&gt;
&lt;li&gt;compute SPD(q,o) (e.g. use A*)&lt;/li&gt;
&lt;li&gt;If SPD(q,o) ≤ ε then output o&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-4&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example: Find restaurants at most distance 10 from q&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 1: find restaurants for which the Euclidean distance to q is at most 10: S={r1,r2,r3}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_Example_1.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_Example_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: for each restaurant in S, compute SPD to q and verify if it is indeed a correct result&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_Example_2.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_Example_2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluation-of-nn-search-1&#34;&gt;Evaluation of NN search (1)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find in spatial relation R the nearest object to a given location q&lt;/li&gt;
&lt;li&gt;Method:
&lt;ul&gt;
&lt;li&gt;Use spatial index of network (R-tree indexing network edges) to find edge n_1n_2, which includes q&lt;/li&gt;
&lt;li&gt;Use adjacency index of network (graph component) and apply Dijkstra’s algorithm to progressively retrieve edges in order of their distance to q&lt;/li&gt;
&lt;li&gt;For each edge apply a spatial selection on the R-tree that indexes R to find any objects&lt;/li&gt;
&lt;li&gt;Keep track of nearest object found so far; use its shortest path distance to terminate network browsing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-5&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Example: Find nearest restaurant to q&lt;/li&gt;
&lt;li&gt;Step: in ppt 31&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-of-nn-search-2&#34;&gt;Evaluation of NN search (2)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find in spatial relation R the nearest object to a given location q&lt;/li&gt;
&lt;li&gt;Alternative method based on Euclidean bounds:
&lt;ul&gt;
&lt;li&gt;Assumption: Euclidean distance lower-bounds network distance:
&lt;ul&gt;
&lt;li&gt;dist(v,u) ≤ SPD(v,u), for any v,u&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_NN_search.png&#34; alt=&#34;Evaluation_of_NN_search&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;spatial-join-queries&#34;&gt;Spatial Join Queries&lt;/h3&gt;
&lt;h4 id=&#34;description-2&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Query: find pairs (r,s), such that r in relation R, s in relation S, and SPD(r,s)≤ε&lt;/li&gt;
&lt;li&gt;Methods:
&lt;ul&gt;
&lt;li&gt;For each r in R, do an ε-distance selection queries for objects in S (Index Nested Loops)&lt;/li&gt;
&lt;li&gt;For each pair (r,s), such that Euclidean dist(r,s)≤ε compute SPD(r,s) and verify SPD(r,s)≤ε&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;notes-on-query-evaluation-based-on-network-distance&#34;&gt;Notes on Query Evaluation based on Network Distance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;For each query type, there are methods based on network browsing and methods based on Euclidean bounds&lt;/li&gt;
&lt;li&gt;Network browsing methods are fast if network edges are densely populated with points of interest
&lt;ul&gt;
&lt;li&gt;A limited network traversal can find the result fast&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Methods based on Euclidean bounds are good if the searched POIs are sparsely distributed in the network
&lt;ul&gt;
&lt;li&gt;Few verifications with exact SP searches are required&lt;/li&gt;
&lt;li&gt;Directed SP search (e.g. using A*) avoids visiting empty parts of the network&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;advanced-indexing-techniques-for-spatial-networks&#34;&gt;Advanced indexing techniques for spatial networks&lt;/h2&gt;
&lt;h3 id=&#34;shortest-path-materialization-and-indexing-in-large-graphs&#34;&gt;Shortest Path Materialization and Indexing in Large Graphs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra’s algorithm and related methods could be very expensive on very large graphs&lt;/li&gt;
&lt;li&gt;(Partial) materialization of shortest paths in static graphs can accelerate search&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Shortest_Path_Materialization_and_Indexing_in_Large_Graphs.png&#34; alt=&#34;Shortest_Path_Materialization_and_Indexing_in_Large_Graphs.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hierarchical-path-materialization&#34;&gt;Hierarchical Path Materialization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Idea: Partition graph G into G_1,G_2,G_3,… based on connectivity and proximity of nodes&lt;/li&gt;
&lt;li&gt;Every edge of G goes to exactly one G_i&lt;/li&gt;
&lt;li&gt;Border nodes belong to more than one G_i’s&lt;/li&gt;
&lt;li&gt;For each G_i compute and materialize SPs between every pair of nodes in G_i (matrix M_i)
&lt;ul&gt;
&lt;li&gt;Partitions are small enough for materialization space overhead to be low&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute and materialize SPs between every pair of border nodes (matrix B)
&lt;ul&gt;
&lt;li&gt;If border nodes too many, hierarchically partition them into 2nd-level partitions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization.png&#34; alt=&#34;Hierarchical_Path_Materialization&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-1&#34;&gt;algorithm&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization_algorithm.png&#34; alt=&#34;Hierarchical_Path_Materialization_algorithm&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating-2&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Good partitioning if:
&lt;ul&gt;
&lt;li&gt;small partitions&lt;/li&gt;
&lt;li&gt;few combinations examined for SP search&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Real road networks:
&lt;ul&gt;
&lt;li&gt;Non-highway nodes in local partitions&lt;/li&gt;
&lt;li&gt;Highway nodes become border nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization_Illustration.png&#34; alt=&#34;Hierarchical_Path_Materialization_Illustration&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;compressing-materialized-paths&#34;&gt;Compressing Materialized Paths&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Distance matrix with successors has O(n_2) space cost&lt;/li&gt;
&lt;li&gt;Motivation: reduce space by grouping targets based on common successors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Compressing_Materialized_Paths.png&#34; alt=&#34;Compressing_Materialized_Paths&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-2&#34;&gt;algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Create and encode one space partitioning defined by targets of the same successor&lt;/li&gt;
&lt;li&gt;For each node s, index Is a set of &amp;lt;succ,R&amp;gt; pairs:
&lt;ul&gt;
&lt;li&gt;succ: a successor of s&lt;/li&gt;
&lt;li&gt;R: a continuous region, such that for each t in R, the successor of s in SP(s,t) is succ&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Compressing_Materialized_Paths_Algorithm.png&#34; alt=&#34;Compressing_Materialized_Paths_Algorithm&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To compute SP(s,t) for a given s, t:
&lt;ol&gt;
&lt;li&gt;SP=s&lt;/li&gt;
&lt;li&gt;Use spatial index Is to find &amp;lt;succ,R&amp;gt;, such that t in R&lt;/li&gt;
&lt;li&gt;SP = SP + (s,succ)&lt;/li&gt;
&lt;li&gt;If succ = t, report SP and terminate&lt;/li&gt;
&lt;li&gt;Otherwise s=succ; Goto step 2&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Indexing and search of spatial networks is different than spatial indexing
&lt;ul&gt;
&lt;li&gt;Shortest path distance is used instead of Euclidean distance, to define range queries, nearest neighbor search, and spatial joins&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial networks could be too large to fit in memory
&lt;ul&gt;
&lt;li&gt;Disk-based index for adjacency lists is used&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Several shortest path algorithms&lt;/li&gt;
&lt;li&gt;Spatial queries can be evaluated using Euclidean bounds&lt;/li&gt;
&lt;li&gt;Advanced indexing methods for shortest path search on large graphs&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 2 Association Rules</title>
      <link>https://www.pseudoyu.com/zh/2021/02/25/comp7103_topic2/</link>
      <pubDate>Thu, 25 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/25/comp7103_topic2/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-2-association-rules&#34;&gt;Topic 2 Association Rules&lt;/h2&gt;
&lt;h3 id=&#34;market-basket-model&#34;&gt;Market-Basket Model&lt;/h3&gt;
&lt;p&gt;A general many-many mapping (association) between two kinds of things&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A large set of items, e.g., things sold in a supermarket&lt;/li&gt;
&lt;li&gt;A large set of baskets, each of which is a small set of the items, e.g., the things one customer buys on one day&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;frequent-itemsets&#34;&gt;Frequent Itemsets&lt;/h3&gt;
&lt;h4 id=&#34;support&#34;&gt;Support&lt;/h4&gt;
&lt;p&gt;Support for itemset I (s(I)) = the number of baskets containing all items in I&lt;/p&gt;
&lt;p&gt;Given a support threshold s, sets of items that appear in at least s baskets are called frequent itemsets&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/frequent_itemsets.png&#34; alt=&#34;frequent_itemsets&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;monotonicity&#34;&gt;Monotonicity&lt;/h4&gt;
&lt;p&gt;For any sets of items I and any set of items J, it holds that&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_monotonicity.png&#34; alt=&#34;association_rules_monotonicity&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;applications&#34;&gt;Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;given that many people buy beer and diapers together
&lt;ul&gt;
&lt;li&gt;Run a sale on diapers; raise price of beer&lt;/li&gt;
&lt;li&gt;Only useful if many buy diapers &amp;amp; beer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Items that appear together too often could represent plagiarism&lt;/li&gt;
&lt;li&gt;Unusual words appearing together in a large number of documents&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;association-rules&#34;&gt;Association Rules&lt;/h3&gt;
&lt;p&gt;If-then rules I → j about the contents of baskets, I is a set of items and j is an item&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i → j means
&lt;ul&gt;
&lt;li&gt;if a basket contains all the items in I then it is likely to contain j&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;confidence&#34;&gt;Confidence&lt;/h4&gt;
&lt;p&gt;The probability of j given I&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_confidence.png&#34; alt=&#34;association_rules_confidence&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_confidence_example.png&#34; alt=&#34;association_rules_confidence_example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;finding-association-rules&#34;&gt;Finding Association Rules&lt;/h4&gt;
&lt;p&gt;find all association rules with support ≥ s and confidence ≥ c&lt;/p&gt;
&lt;h4 id=&#34;computation-model&#34;&gt;Computation Model&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data is kept in raw files rather than in a database system
&lt;ul&gt;
&lt;li&gt;Stored on disk&lt;/li&gt;
&lt;li&gt;Stored basket-by-basket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The true cost of mining disk-resident data is usually the number of disk I/O’s&lt;/li&gt;
&lt;li&gt;In practice, association-rule algorithms read data in passes – all baskets read in turn&lt;/li&gt;
&lt;li&gt;we measure the cost by the number of passes an algorithm takes&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;association-rules-algorithms&#34;&gt;Association Rules Algorithms&lt;/h3&gt;
&lt;h4 id=&#34;naïve-algorithm&#34;&gt;Naïve Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Read file once, counting in main memory the occurrences of each pair
&lt;ul&gt;
&lt;li&gt;From each basket of n items, generate its n (n -1)/2 pairs by two nested loops&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fails if (#items)^2 exceeds main memory&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-priori-algorithm&#34;&gt;A-Priori Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A two-pass approach called a-priori limits the need for main memory&lt;/li&gt;
&lt;li&gt;Key idea: monotonicity
&lt;ul&gt;
&lt;li&gt;If a set of items appears at least s times, so does every subset&lt;/li&gt;
&lt;li&gt;For pairs: if item i does not appear in s baskets, then no pair including i can appear in s baskets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Read baskets and count in main memory the occurrences of each item (Requires only memory proportional to #items)
&lt;ul&gt;
&lt;li&gt;Items that appear at least s times are the frequent items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Read baskets again and count in main memory only those pairs both of which were found in pass 1 to be frequent
&lt;ul&gt;
&lt;li&gt;To count number of item pairs use a hash function&lt;/li&gt;
&lt;li&gt;Requires memory proportional to square of frequent items only, plus a list of the frequent items, plus space for hashing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/APriori_Algorithm.png&#34; alt=&#34;APriori_Algorithm&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One pass for each k&lt;/li&gt;
&lt;li&gt;Needs room in main memory to count each candidate k -set&lt;/li&gt;
&lt;li&gt;For typical market-basket data and reasonable support (e.g., 1%), k = 2 requires the most memory&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pcy-algorithm&#34;&gt;PCY Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Main observation: during pass 1 of A-priori, most memory is idle&lt;/li&gt;
&lt;li&gt;Use that memory to keep additional info to improve storage during pass 2 of A-priori&lt;/li&gt;
&lt;li&gt;Passes &amp;gt; 2 are the same as in A-Priori&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Use a hash function which bucketizes item pairs, that is, maps them to integers in [1,k]&lt;/li&gt;
&lt;li&gt;Each bucket i in [1,k] is associated with a counter ci&lt;/li&gt;
&lt;li&gt;During pass 1, as we examine a basket (e.g. {m,b,d,o})
&lt;ul&gt;
&lt;li&gt;update counters of single items&lt;/li&gt;
&lt;li&gt;Generate all item pairs for that basket, hash each of them and add 1 to the corr. counter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Count all pairs {i, j } that meet the conditions for being a candidate pair
&lt;ul&gt;
&lt;li&gt;Both i and j are frequent items&lt;/li&gt;
&lt;li&gt;The pair {i, j }, hashes to a frequent bucket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ignore all pairs belonging to non-frequent buckets (do not use a counter for them)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;simple-algorithm&#34;&gt;Simple Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Take a random sample of the market baskets
&lt;ul&gt;
&lt;li&gt;give a full pass on the data and keep a basket in main memory with probability p&lt;/li&gt;
&lt;li&gt;A random sample is the best representative of a dataset&lt;/li&gt;
&lt;li&gt;Keeping only the first baskets might not contain iPhones for example&lt;/li&gt;
&lt;li&gt;If we cannot have a sample large enough then
&lt;ul&gt;
&lt;li&gt;Remove false positives with one more pass&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Run A-priori or one of its improvements in main memory, so you don’t pay for disk I/O each time you give a pass on the data
&lt;ul&gt;
&lt;li&gt;Be sure you leave enough space for counts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adjust the support threshold s accordingly&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;son-algorithm&#34;&gt;SON Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Two passes&lt;/li&gt;
&lt;li&gt;No false positives or false negatives&lt;/li&gt;
&lt;li&gt;Divide the dataset into chunks, where each chunk contains a subset of baskets&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Divide the dataset into chunks, where each chunk contains a subset of baskets&lt;/li&gt;
&lt;li&gt;Let pi such that the ith chunk contains a fraction pi of the dataset&lt;/li&gt;
&lt;li&gt;For each chunk i compute all frequent itemsets with support p i x s and store them on disk. This is the set of candidates for next pass&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Read all frequent itemsets found in the previous pass (candidates)&lt;/li&gt;
&lt;li&gt;For each of them count the number of occurrences and output only those with support at least s&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>用OKR的方式梳理自己的学习计划</title>
      <link>https://www.pseudoyu.com/zh/2021/02/11/learning_plan_okr/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/11/learning_plan_okr/</guid>
      
        <description>&lt;h2 id=&#34;用一句话形容理想情况下自己想要达到的状态&#34;&gt;用一句话形容理想情况下，自己想要达到的状态&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;具体目标范围&lt;/strong&gt;：提升编程技术能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时间周期&lt;/strong&gt;：2个月&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;描述&lt;/strong&gt;：我想要成为一名具备过硬的编程能力的开发者，并对技术有持续学习的开放心态 &lt;em&gt;&lt;strong&gt;— 目标O&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;寻找关键词拆解状态为目标&#34;&gt;寻找关键词，拆解状态为目标&lt;/h2&gt;
&lt;h3 id=&#34;我需要提升解决的部分&#34;&gt;我需要提升解决的部分&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;过硬的编程能力&lt;/li&gt;
&lt;li&gt;持续学习的开放心态&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;想要达到的程度&#34;&gt;想要达到的程度&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;能够通过技术创造价值&lt;/li&gt;
&lt;li&gt;对技术有热爱和追求&lt;/li&gt;
&lt;li&gt;B站Up主“是落拓呀”的持续学习状态&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;制定每一个关键词目标的指标&#34;&gt;制定每一个关键词/目标的指标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;过硬的编程能力&lt;/strong&gt;：能够满足目前香港/内地区块链公司，如蚂蚁链、腾讯区块链、杭州趣链科技等目标公司的技术面试要求，并主导完成1-2个完整的项目，深入技术细节 &lt;strong&gt;— KR1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持续学习的开放心态&lt;/strong&gt;：提升对于热门区块链技术平台（Ethereum、Hyperledger）与Java后端技术的理解与学习，并完成多篇原创技术博客 &lt;strong&gt;— KR2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;填充每一个关键指标的todo-list&#34;&gt;填充每一个关键指标的todo list&lt;/h2&gt;
&lt;h3 id=&#34;过硬的编程能力&#34;&gt;过硬的编程能力&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;每天按照分类与难度刷LeetCode算法题
&lt;ol&gt;
&lt;li&gt;白天刷5-10题&lt;/li&gt;
&lt;li&gt;晚上按照节奏复习之前刷过的题的思路&lt;/li&gt;
&lt;li&gt;看关于算法框架思路的书籍，完善&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;完成区块链音乐版权项目毕业设计
&lt;ol&gt;
&lt;li&gt;每天至少2小时学习Ethereum智能合约编写相关&lt;/li&gt;
&lt;li&gt;按照项目进度进行开发&lt;/li&gt;
&lt;li&gt;与导师和同学定期交流，优化项目&lt;/li&gt;
&lt;li&gt;调研市场上区块链产品，思考运营与商业化相关&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;完成开源项目RPC框架的学习
&lt;ol&gt;
&lt;li&gt;每天至少1小时学习课程并实践代码&lt;/li&gt;
&lt;li&gt;撰写关于RPC框架原理和核心知识点的技术博文&lt;/li&gt;
&lt;li&gt;将此作为亮点项目，添加至简历并与同学进行模拟面试&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;针对GitHub与一些书籍的面试经验，学习掌握计算机基础面试知识，和同学每周模拟面试，现场写算法题并讲解，找到问题并提出建议&lt;/li&gt;
&lt;li&gt;参加春招面试，积攒面试经验查漏补缺，总结心得&lt;/li&gt;
&lt;li&gt;和落拓学长交流区块链学习心得和路径，寻求建议&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;持续学习的开放心态&#34;&gt;持续学习的开放心态&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;完成学校COMP7408区块链与分布式账本课程（共计30学时，每周一节3小时的课程）
&lt;ol&gt;
&lt;li&gt;每周一晚上参加线下课程&lt;/li&gt;
&lt;li&gt;课程第二天花3-6小时整理当周课程的知识点与拓展部分&lt;/li&gt;
&lt;li&gt;每周2-3小时将课程中的理论部分通过代码实践&lt;/li&gt;
&lt;li&gt;每天至少3天对之前所有知识点进行复习和查漏补缺（每次30分钟左右）&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Udacity 区块链开发课程并整理笔记（共计约40学时）
&lt;ol&gt;
&lt;li&gt;每天至少2小时学习课程并实践代码&lt;/li&gt;
&lt;li&gt;每天至少3天对之前所有知识点进行复习和查漏补缺（每次30分钟左右）&lt;/li&gt;
&lt;li&gt;阶段性对课程里的项目进行详细整理，添加至简历并针对面试进行准备&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;每天学习间隙整理基础理论知识，并了解一些前沿技术和产品&lt;/li&gt;
&lt;li&gt;完成CSDN关于Spring Boot和其他框架的入门视频并整理&lt;/li&gt;
&lt;li&gt;完成Udacity关于Java开发相关框架的介绍并进行项目实践&lt;/li&gt;
&lt;li&gt;结合自己的理解与学习笔记，撰写针对特定技术的原创博客&lt;/li&gt;
&lt;li&gt;定期和目前从事区块链的同学进行交流讨论，补充项目经验至简历与面试准备&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 2 Spatial Data Management</title>
      <link>https://www.pseudoyu.com/zh/2021/02/06/comp7801_topic2/</link>
      <pubDate>Sat, 06 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/06/comp7801_topic2/</guid>
      
        <description>&lt;h2 id=&#34;spatial-data-management&#34;&gt;Spatial Data Management&lt;/h2&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Spatial Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Location data
&lt;ul&gt;
&lt;li&gt;Check-in service&lt;/li&gt;
&lt;li&gt;Online Maps&lt;/li&gt;
&lt;li&gt;Location-based services&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Location tracking&lt;/li&gt;
&lt;li&gt;Traffic Data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spatial Databases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PostgreSQL with PostGIS&lt;/li&gt;
&lt;li&gt;Neo4J-spatial&lt;/li&gt;
&lt;li&gt;HadoopGIS&lt;/li&gt;
&lt;li&gt;Ingres&lt;/li&gt;
&lt;li&gt;GeoMesa&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spatial Data Management&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spatial Database Systems
&lt;ul&gt;
&lt;li&gt;Manage large collections of multidimensional objects (2D/3D)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A spatial object
&lt;ul&gt;
&lt;li&gt;Contains (at least) one spatial attributes that describes its location and/or geometry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A spatial relation
&lt;ul&gt;
&lt;li&gt;Is an organized collection of spatial objects of the same entity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-data&#34;&gt;Spatial Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Representation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Points (Cities in large-scale map)&lt;/li&gt;
&lt;li&gt;Extent (rivers, forest, etc.)
&lt;ul&gt;
&lt;li&gt;Vector (approximation by geometric objects)&lt;/li&gt;
&lt;li&gt;Raster (A set of pixels in the grid)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Application&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spatial data
&lt;ul&gt;
&lt;li&gt;GIS&lt;/li&gt;
&lt;li&gt;Segemented images&lt;/li&gt;
&lt;li&gt;Components of CAD constructs or VLSI circuit&lt;/li&gt;
&lt;li&gt;Stars on the sky&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial database
&lt;ul&gt;
&lt;li&gt;Users of mobile devices&lt;/li&gt;
&lt;li&gt;Geographers, life scientists&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;features-of-spatial&#34;&gt;Features of spatial&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Dimensionality
&lt;ul&gt;
&lt;li&gt;There is no total ordering of objects in the multidimensional space that preserves spatial proximity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Complex spatial extent&lt;/li&gt;
&lt;li&gt;No standard definitions of spatial operations and algebra&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Relationa indexes (like B+ trees) and query processing methods (sort-merge join, hash-join) are not applicable&lt;/p&gt;
&lt;p&gt;Spatial access methods (SAMs) for spatial data have to be defined&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Index spatial objects&lt;/li&gt;
&lt;li&gt;Facilitate efficient processing of simple spatial query types (e.g. range queries)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-relationships&#34;&gt;Spatial Relationships&lt;/h3&gt;
&lt;p&gt;A spatial relationship associates two objects according to their relative location and extent in space. Sometimes also called &amp;ldquo;spatial relations&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Can refer to a database relation which stores spatial objects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topological relationships&lt;/li&gt;
&lt;li&gt;Distance relationships&lt;/li&gt;
&lt;li&gt;Directional relationships&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;topological-relationships&#34;&gt;Topological relationships&lt;/h4&gt;
&lt;p&gt;Each object is characterized by the space it occupies in the universe (A set of pixels).&lt;/p&gt;
&lt;p&gt;A set of relationsips between their boundaries and interiors&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boundary&lt;/li&gt;
&lt;li&gt;Interior (some may not have, points, line segments, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A hierarchy of relations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intersect (or overlaps)
&lt;ul&gt;
&lt;li&gt;equals&lt;/li&gt;
&lt;li&gt;inside&lt;/li&gt;
&lt;li&gt;contains&lt;/li&gt;
&lt;li&gt;adjacent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;disjoint&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distance-relationships&#34;&gt;Distance relationships&lt;/h4&gt;
&lt;p&gt;Associate two objects based on their geometric (Euclidean distance), and it&amp;rsquo;s usually abstracted into human mind.&lt;/p&gt;
&lt;p&gt;Distance relationships are expressed either explicitly or by some abstract distance class.&lt;/p&gt;
&lt;h4 id=&#34;directional-relationships&#34;&gt;Directional relationships&lt;/h4&gt;
&lt;p&gt;Associates two object based on their relative orientation according to a global reference system.&lt;/p&gt;
&lt;h3 id=&#34;spatial-queries&#34;&gt;Spatial Queries&lt;/h3&gt;
&lt;p&gt;Applied on one (or more) spatial relations to retrieve objects staisfying some spatial relationships&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nearest neighbor query&lt;/li&gt;
&lt;li&gt;Spatial join&lt;/li&gt;
&lt;li&gt;Range query
&lt;ul&gt;
&lt;li&gt;Spatial selction&lt;/li&gt;
&lt;li&gt;window query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-query-processing&#34;&gt;Spatial Query Processing&lt;/h3&gt;
&lt;p&gt;Evaluating spatial relationships on geometric data is slow.&lt;/p&gt;
&lt;p&gt;A spatial object is approximated by its minimum bounding rectangle (MBR)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Filter: The MBR is tested against the query predicate&lt;/li&gt;
&lt;li&gt;Refinement: The exact geometry of objects that pass the filter step is tested for qualification&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;spatial-access-methods-sams&#34;&gt;Spatial Access Methods (SAMs)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The problem of indexing spatial data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No dynamic access method with good theoretical worst-case guarantees for range queries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SAMs aim at the minimization of the expected cost.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Indexing of multidimensional points&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;point-access-methods&#34;&gt;Point access methods&lt;/h4&gt;
&lt;p&gt;Divide the apce into disjoint partitions and group the points according to the regions they belong&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/point_access_methods.png&#34; alt=&#34;point_access_methods&#34;&gt;&lt;/p&gt;
&lt;p&gt;Not effective for extended objects (may need to be clipped into several parts which leads to data redundancy and affects performance negatively).&lt;/p&gt;
&lt;p&gt;Object clipping can be avoided if we allow the regions of object to overlap.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/object_clipping.png&#34; alt=&#34;object_clipping&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Optimization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group the objects below into 3 groups of 4 objects each such that the MBRs of the groups have the minimum overlap&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overlap_region.png&#34; alt=&#34;overlap_region&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard optimization problem&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-r-tree&#34;&gt;The R-tree&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Concept&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group object MBRs to disk blocks hierarchically&lt;/li&gt;
&lt;li&gt;Each group of object is a leaf of the tree&lt;/li&gt;
&lt;li&gt;The MBRs of the leaf nodes are grouped to form nodes at the next level&lt;/li&gt;
&lt;li&gt;Grouping is recursively applied at each level until a single group (the root) is formed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_Tree_example.png&#34; alt=&#34;R_Tree_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Elements&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leaf node entries: &amp;lt;MBR, object-id&amp;gt;, all leaves are in same level&lt;/li&gt;
&lt;li&gt;Non-leaf node entries: &amp;lt;MBR, ptr&amp;gt;, pointing to entries&lt;/li&gt;
&lt;li&gt;Root: have at least two children&lt;/li&gt;
&lt;li&gt;Non-root node parameters
&lt;ul&gt;
&lt;li&gt;M&lt;/li&gt;
&lt;li&gt;m&lt;/li&gt;
&lt;li&gt;m &amp;lt;= M/2&lt;/li&gt;
&lt;li&gt;Usually m = 0.4 M&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;range-searching-using-an-r-tree&#34;&gt;Range searching using an R-tree&lt;/h4&gt;
&lt;p&gt;Range_query (query W, R-tree node n)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If n is not a leaf node
&lt;ul&gt;
&lt;li&gt;For each index entry e in n such that e.MBR intersects W
&lt;ul&gt;
&lt;li&gt;Visit node n&#39; pointed  by e.ptr&lt;/li&gt;
&lt;li&gt;Range_query (W, n&#39;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If n is a leaf
&lt;ul&gt;
&lt;li&gt;For each index entry e in n such that e.MBR intersects W
&lt;ul&gt;
&lt;li&gt;Visit object o pointed by e.object-id&lt;/li&gt;
&lt;li&gt;Test range query against exact geometry of o; If o intersects W, report o&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;May follow multiple paths during search&lt;/li&gt;
&lt;li&gt;Different search predicates are used for different realtionships with W&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/range_search.png&#34; alt=&#34;range_search&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;construction-of-the-r-tree&#34;&gt;Construction of the R-tree&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Dynamically constructed/maintained&lt;/li&gt;
&lt;li&gt;Insertions/deletions interleave with search operations
&lt;ul&gt;
&lt;li&gt;Insertion similiar to B+ Tree, but with special optimization algorithms
&lt;ul&gt;
&lt;li&gt;Choose the path where a new MBR is inserted&lt;/li&gt;
&lt;li&gt;Split overflow nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Underflows in deletions
&lt;ul&gt;
&lt;li&gt;Deleting the underflow leaf node&lt;/li&gt;
&lt;li&gt;Re-insert the remaining entries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;r-tree&#34;&gt;R*-tree&lt;/h3&gt;
&lt;p&gt;Only different in the insertion algorithm (compared to R-tree), aiming at constructing a tree of high quality&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A good tree&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nodes with small MBRs&lt;/li&gt;
&lt;li&gt;nodes with small overlap&lt;/li&gt;
&lt;li&gt;nodes that look like squares&lt;/li&gt;
&lt;li&gt;nodes as full as possible&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;optimization&#34;&gt;Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Minimize the area covered by an index rectangle (small area means small dead space)&lt;/li&gt;
&lt;li&gt;Minimize overlap between node MBRs (Minimizes the number of traversed paths)&lt;/li&gt;
&lt;li&gt;Minimize the margins of node MBRs (Square-like nodes, smaller number of intersections for a random query, better structure)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/margin_minimization.png&#34; alt=&#34;margin_minimization&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimize the storage utilization
&lt;ul&gt;
&lt;li&gt;Nodes in tree should be filled as much as possible&lt;/li&gt;
&lt;li&gt;Minimizes tree height and potentially decreases dead space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Insertion heuristics (Select the path)
&lt;ul&gt;
&lt;li&gt;Least MBR enlargement after insertion
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/MBR_enlargement.png&#34; alt=&#34;MBR_enlargement&#34;&gt;&lt;/li&gt;
&lt;li&gt;Least MBR overlap after insertion
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/MBR_overlap.png&#34; alt=&#34;MBR_overlap&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node-spliting&#34;&gt;Node Spliting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Determine the split axis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each axis (i.e. x and y axis)
&lt;ul&gt;
&lt;li&gt;Sum=0;&lt;/li&gt;
&lt;li&gt;sort entries by the lower value, then by upper value&lt;/li&gt;
&lt;li&gt;for each sorting (e.g. lower value)
&lt;ul&gt;
&lt;li&gt;for k=m to M+1-m&lt;/li&gt;
&lt;li&gt;place first k entries in group A, and the remaining ones in group B&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Sum = Sum + margin(A) + margin(B)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Choose axis with the minimum Sum&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Distribute entries along axis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Along the split axis, choose the distribution with minimum overlap&lt;/li&gt;
&lt;li&gt;If there are multiple groupings with minimal overlap choose &amp;lt;A,B&amp;gt; such that area(A)+area(B) is minimized&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;insertion-heuristics-forced-reinsert&#34;&gt;Insertion heuristics: Forced Reinsert&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/forced_reinsert.png&#34; alt=&#34;forced_reinsert&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forced Reinsert
&lt;ul&gt;
&lt;li&gt;When R*-tree node n overflows, instead of splitting n immediately, try to see if some entries in n could possibly fit better in another node&lt;/li&gt;
&lt;li&gt;Find the 30% furthest entries from the center of the group&lt;/li&gt;
&lt;li&gt;Re-insert them to the tree (not to be repeated if another overflow occurs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slightly more expensive, but better tree structure:
&lt;ul&gt;
&lt;li&gt;less overlap&lt;/li&gt;
&lt;li&gt;more space is utilized (more full nodes)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bulk-loading-r-trees&#34;&gt;Bulk-loading R-trees&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/bulk_loading_R_tree.png&#34; alt=&#34;bulk_loading_R_tree&#34;&gt;&lt;/p&gt;
&lt;p&gt;Given a static set S of rectangles, build an R-tree that indexes S.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Method 1: iteratively insert rectangles into an initially empty tree
&lt;ul&gt;
&lt;li&gt;Feature
&lt;ul&gt;
&lt;li&gt;tree reorganization is slow&lt;/li&gt;
&lt;li&gt;tree nodes are not as full as possible: more space occupied for the tree&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 2 (x-sorting): bulk-load the rectangles into the tree using some fast (sort or hash-based) process
&lt;ul&gt;
&lt;li&gt;sort rectangles using the x-coordinate of their center&lt;/li&gt;
&lt;li&gt;pack M consecutive rectangles in leaf nodes&lt;/li&gt;
&lt;li&gt;build tree bottom-up&lt;/li&gt;
&lt;li&gt;Feature
&lt;ul&gt;
&lt;li&gt;R-tree is built fast&lt;/li&gt;
&lt;li&gt;good space utilization&lt;/li&gt;
&lt;li&gt;results in leaf nodes that are have long stripes as MBRs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 3 (Hilbert sorting): use a space-filling curve to order the rectangles
&lt;ul&gt;
&lt;li&gt;much better structure, but still the nodes have large overlap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 4 (sort-tile-recursive): Sort using one axis first and then groups of sqrt(n) rectangles using the other axis
&lt;ul&gt;
&lt;li&gt;Usually the best structure compared to other bulk-loading methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;k-nearest-neighbor-search&#34;&gt;K Nearest Neighbor Search&lt;/h3&gt;
&lt;p&gt;Given a spatial relation R, a query object q, and a number k &amp;lt;|R|, find the k-nearest neighbors of q in R.&lt;/p&gt;
&lt;p&gt;We can have more than one k-NN sets (with multiple possible equidistant furthest points in them).&lt;/p&gt;
&lt;h4 id=&#34;distance-measures-and-mbrs&#34;&gt;Distance measures and MBRs&lt;/h4&gt;
&lt;p&gt;Distances between MBRs lower-bound the distances between the corresponding objects&lt;/p&gt;
&lt;p&gt;dist(MBR(oi),MBR(oj)) ≤ dist(oi, oj)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/distance_mbr.png&#34; alt=&#34;distance_mbr&#34;&gt;&lt;/p&gt;
&lt;p&gt;Distances between R-tree node MBRs lower-bound the distances between the entries in them&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/min_distance_mbr.png&#34; alt=&#34;min_distance_mbr&#34;&gt;&lt;/p&gt;
&lt;p&gt;The distance between a query object q and an R-tree node MBR lower-bounds the distances between q and the objects indexed under this node&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/q_distance_mbr.png&#34; alt=&#34;q_distance_mbr&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;depth-first-nn-search-using-an-r-tree&#34;&gt;Depth-first NN search using an R-tree&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Start from the root and visit the node nearest to q&lt;/li&gt;
&lt;li&gt;Continue recursively, until a leaf node nl is visited.&lt;/li&gt;
&lt;li&gt;Find the NN of q in nl.&lt;/li&gt;
&lt;li&gt;Continue visiting other nodes after backtracking as long there are nodes closer to q than the current NN.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/DFNNS_code.png&#34; alt=&#34;DFNNS_code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large space can be pruned by avoiding visiting R-tree nodes and their sub-trees&lt;/li&gt;
&lt;li&gt;Should order the entries of a node in increasing distance from q to maximize potential for a good NN found fast&lt;/li&gt;
&lt;li&gt;Can be easily adapted for k-NN search&lt;/li&gt;
&lt;li&gt;Requires at most one tree path to be currently in memory – good for small memory buffers
&lt;ul&gt;
&lt;li&gt;Characteristic of all depth-first search algorithms&lt;/li&gt;
&lt;li&gt;Recall that the range search algorithm is also DF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;However, does not visit the least possible number of nodes&lt;/li&gt;
&lt;li&gt;Also, not incremental – more on this later…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/DFNNS_example.png&#34; alt=&#34;DFNNS_example&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. visit root
dist(q,M1)&amp;lt;dist(q,oNN)
must visit node M1

2. visit M1
dist(q,m1)&amp;lt;dist(q,oNN)
must visit node m1

3. visit m1
check a,b,c
found new NN:
oNN = a, dist(q,oNN) = sqrt(5)

4. backtrack to M1
check m2dist(q,m2) = 3 &amp;gt;= sqrt(5):
No need to visit node m2
check m3dist(q,m3) = sqrt(5) &amp;gt;= sqrt(5):
No need to visit node m3

5. backtrack to root
check M2dist(q,M2) = sqrt(2) &amp;lt; sqrt(5):
must visit node M2

6. visit M2
check m4dist(q,m4) = sqrt(2) &amp;lt; sqrt(5):
must visit node m4

7. visit m4
check i,j,k
found new NN:
oNN = k, dist(q,oNN) = sqrt(2)

8. backtrack to M2
check m5dist(q,m5) &amp;gt;= sqrt(2):
No need to visit node m5
check m6dist(q,m6) &amp;gt;= sqrt(2):
No need to visit node m6

9. backtrack to root
check M3dist(q,M3) &amp;gt;= sqrt(2):
No need to visit node M3

10. backtrack from root
Algorithm terminates
oNN =k with dist(q,oNN)= sqrt(2) found
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;best-first-nn-search&#34;&gt;Best-first NN search&lt;/h4&gt;
&lt;p&gt;Put all entries in a priority queue and always “open” the closest one, independently of the node that contains it.&lt;/p&gt;
&lt;p&gt;Thus the best (i.e., closest) entry is always visited first.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A more efficient algorithm (given large enough memory)&lt;/li&gt;
&lt;li&gt;Optimal in the number of R-tree nodes visited for a given query q&lt;/li&gt;
&lt;li&gt;Uses a priority queue to organize seen entries and prioritize the next node to be visited&lt;/li&gt;
&lt;li&gt;Adaptable for k-NN search and incremental NN search&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/BFNNS_code.png&#34; alt=&#34;BFNNS_code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the previous example, we have visited fewer nodes compared to DF-NN algorithm
&lt;ul&gt;
&lt;li&gt;Only nodes whose MBR intersect the disk centered at q with radius the real NN distance are visited (see if you can you prove this)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The algorithm can be adapted for incremental NN search
&lt;ul&gt;
&lt;li&gt;After having found the NN can we easily (incrementally) find the next NN without starting search from the beginning?
&lt;ul&gt;
&lt;li&gt;put objects on the heap&lt;/li&gt;
&lt;li&gt;never prune, but wait until an object comes out&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The algorithm can be used for k-NN search
&lt;ul&gt;
&lt;li&gt;use a second heap to organize the NN found so far (same can be done for DF-NN)&lt;/li&gt;
&lt;li&gt;no need if we just use the inc. version of the algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;… but: The heap can grow very large until the algorithm terminates&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/BFNNS_example.png&#34; alt=&#34;BFNNS_example&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Step 1: put all entries of root on heap Q
Q = M1(1), M2(sqrt(2)), M3(sqrt(8))

Step 2: get closest entry (top element of Q):
M1(1). Visit node M1. Put all entries of 
visited node on heap Q
Q = M2(sqrt(2)), m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3)

Step 3: get closest entry (top element of Q):
M2(sqrt(2)). Visit node M2. Put all entries of 
visited node on heap Q
Q =m4(sqrt(2)), m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3), 	m5(sqrt(13)), m5(sqrt(17))

Step 4: get closest entry (top element of Q):
m4(sqrt(2)). Visit node m4. m4 is a leaf node, so update NN if some object in m4 is closer than the current NN:
oNN = k, dist(q,oNN)= sqrt(2)
Q =m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3), 	m5(sqrt(13)), m5(sqrt(17))

Step 5: get closest entry (top element of Q):
m1(sqrt(5)). Since sqrt(5) &amp;gt;= dist(q,oNN)= sqrt(2), search stops and oNN is returned as the NN of q
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;incremental NN search&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example 1: find the nearest large city (&amp;gt;10,000 residents) to my current position
&lt;ul&gt;
&lt;li&gt;Solution 1:
&lt;ul&gt;
&lt;li&gt;find all large cities&lt;/li&gt;
&lt;li&gt;apply NN search on the result&lt;/li&gt;
&lt;li&gt;could be slow if many such cities&lt;/li&gt;
&lt;li&gt;also R-tree may not be available for large cities only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution 2:
&lt;ul&gt;
&lt;li&gt;incrementally find NN and check if the large city requirement is satisfied; if not get the next NN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example 2: find the nearest hotel; see if you like it; if not get the next one; see if you like it; …&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-joins&#34;&gt;Spatial Joins&lt;/h3&gt;
&lt;p&gt;Most algorithms focus on the efficient processing of the filter step.&lt;/p&gt;
&lt;p&gt;Most spatial predicates on actual objects reduce to intersection of MBRs in the filter step. Thus all algorithms consider mainly the intersect predicate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Types&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intersection joins&lt;/li&gt;
&lt;li&gt;Semi-join: Find the cities that intersect a river&lt;/li&gt;
&lt;li&gt;Similarity join: Find pairs of hotels, restaurants close to each other (with distance smaller than 100m)&lt;/li&gt;
&lt;li&gt;Closest pairs: Find the closest pair of hotels, restaurants&lt;/li&gt;
&lt;li&gt;All-NN: For each hotel find the nearest restaurant&lt;/li&gt;
&lt;li&gt;Iceberg distance join: Find hotels close to at least 10 restaurants&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Three categories of spatial join algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both inputs are indexed (e.g., synchronized tree traversal)&lt;/li&gt;
&lt;li&gt;One input is indexed (e.g., indexed nested loops)&lt;/li&gt;
&lt;li&gt;Neither input is indexed (e.g., spatial hash join)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;r-tree-intersection-join&#34;&gt;R-tree (Intersection) Join&lt;/h4&gt;
&lt;p&gt;Applies on two R-trees of spatial relations R and S&lt;/p&gt;
&lt;p&gt;Node MBRs at the high level of the trees can prune object combinations to be checked&lt;/p&gt;
&lt;p&gt;This pseudo-code version assumes that the trees have same height&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_code.png&#34; alt=&#34;R_tree_join_code&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run for root(RA), root(RB)&lt;/li&gt;
&lt;li&gt;for every intersecting pair there (e.g., A1, B1) run recursively for pointed nodes&lt;/li&gt;
&lt;li&gt;intersecting pairs of leaf nodes are qualifying object MBR pairs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_example.png&#34; alt=&#34;R_tree_join_example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;optimization-1&#34;&gt;Optimization&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;space restriction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If an entry in n1 does not intersect the MBR of n2 it may not intersect any entry in n2.&lt;/li&gt;
&lt;li&gt;Perform two scans in n1 and n2 to prune such entries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_optimization.png&#34; alt=&#34;R_tree_join_optimization&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;plane sweep&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sort entries in both nodes on their lower-x value (lower bound of x-projection)&lt;/li&gt;
&lt;li&gt;Sweep a line to find fast all entry pairs that qualify x-intersection
&lt;ul&gt;
&lt;li&gt;for each of them check y-intersection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_optimization2.png&#34; alt=&#34;R_tree_join_optimization2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worst-case sub-optimal. But very effective on the average&lt;/li&gt;
&lt;li&gt;Worst-case optimal algorithms require advanced data structures for y-intersection. Large hidden constants, thus high cost for this problem size&lt;/li&gt;
&lt;li&gt;Can be used with other spatial join algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;R-tree join&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The most efficient algorithm (assuming that the relations are indexed)&lt;/li&gt;
&lt;li&gt;Cannot be used for non-indexed inputs&lt;/li&gt;
&lt;li&gt;unless we build on-the-fly R-trees&lt;/li&gt;
&lt;li&gt;Comes with some I/O scheduling techniques for minimizing the page accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;joining-non-indexed-inputs&#34;&gt;Joining non-indexed inputs&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Spatial hash join&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/spatial_hash_join.png&#34; alt=&#34;spatial_hash_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Partition based spatial merge join&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/spatial_merge_join.png&#34; alt=&#34;spatial_merge_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Indexed Nested Loops&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexed_nest_loops.png&#34; alt=&#34;indexed_nest_loops&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Seeded tree join and Bulk-load and Match build an on-the-fly R-tree&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/seeded_tree_join.png&#34; alt=&#34;seeded_tree_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slot-index spatial join applies hash-join using the entries of a high R-tree level&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/slot_index_spatial_join.png&#34; alt=&#34;slot_index_spatial_join&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-refinement-step&#34;&gt;The refinement step&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_step.png&#34; alt=&#34;refinement_step&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: find MBR pairs that intersect&lt;/li&gt;
&lt;li&gt;Step 2: compare some more detailed approximations to make conclusions (a.k.a. geometric filter)
&lt;ul&gt;
&lt;li&gt;conservative approximations
&lt;ul&gt;
&lt;li&gt;e.g., convex hull&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;progressive approximation
&lt;ul&gt;
&lt;li&gt;e.g., maximum enclosed rectangle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_detailed_approximations.png&#34; alt=&#34;refinement_detailed_approximations&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: if still join predicate inconclusive, perform expensive refinement step
&lt;ul&gt;
&lt;li&gt;can be processed by computational geometry algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-step processing (R-tree join as example)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_multi_step.png&#34; alt=&#34;refinement_multi_step&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链隐私问题概述</title>
      <link>https://www.pseudoyu.com/zh/2021/01/30/blockchain_note_privacy/</link>
      <pubDate>Sat, 30 Jan 2021 05:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/30/blockchain_note_privacy/</guid>
      
        <description>&lt;h2 id=&#34;区块链隐私问题概述&#34;&gt;区块链隐私问题概述&lt;/h2&gt;
&lt;h3 id=&#34;区块链透明性&#34;&gt;区块链透明性&lt;/h3&gt;
&lt;p&gt;所有人都能看到交易细节/历史记录&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用场景：供应链 （食品、药品、酒&amp;hellip;）&lt;/li&gt;
&lt;li&gt;隐私风险：个人信息（账户余额、交易信息&amp;hellip;）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;隐私分类&#34;&gt;隐私分类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;发送方匿名&lt;/li&gt;
&lt;li&gt;交易匿名/机密&lt;/li&gt;
&lt;li&gt;接收方匿名&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;比特币隐私建议&#34;&gt;比特币隐私建议&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;不要重复使用地址&lt;/li&gt;
&lt;li&gt;在同一比交易中不要将多个输出（UTXO）作为输入&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;隐私保护技术&#34;&gt;隐私保护技术&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;混币&lt;/li&gt;
&lt;li&gt;匿名签名
&lt;ul&gt;
&lt;li&gt;环签（小组中每一个人都可以签名，但不知道被谁签名）&lt;/li&gt;
&lt;li&gt;可链接环签名（依然不知道被谁签名，但是可以知道被同一个签名者签，可检测双花）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;零知识证明 （在不让其他人知道额外信息的前提下证明正确性）&lt;/li&gt;
&lt;li&gt;加密
&lt;ul&gt;
&lt;li&gt;同态加密（以太坊智能合约在区块链存储上提供了同态加密）&lt;/li&gt;
&lt;li&gt;基于属性的加密（Attribute-based encryption(ABE)）
&lt;ul&gt;
&lt;li&gt;每个用户有一些属性（角色）&lt;/li&gt;
&lt;li&gt;权限控制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可信执行环境（Trusted execution environment(TEE)）
&lt;ul&gt;
&lt;li&gt;安全硬件（如Intel SGX）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;基于隐私保护的交易平台&#34;&gt;基于隐私保护的交易平台&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_privacy_market_place.png&#34; alt=&#34;blockchain_privacy_market_place&#34;&gt;&lt;/p&gt;
&lt;p&gt;现有平台不支持对于加密数据的计算（区块链多方计算）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加密搜索&lt;/li&gt;
&lt;li&gt;统计计算/数据挖掘&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 1b Database Indexing</title>
      <link>https://www.pseudoyu.com/zh/2021/01/30/comp7801_topic1b/</link>
      <pubDate>Sat, 30 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/30/comp7801_topic1b/</guid>
      
        <description>&lt;h2 id=&#34;database-indexing&#34;&gt;Database Indexing&lt;/h2&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Indexing mechanisms used to speed up access to desired data&lt;/li&gt;
&lt;li&gt;Search Key
&lt;ul&gt;
&lt;li&gt;An attribute or a set of attributes used to look up records in a file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An index file consists of records (called index entries) of the form &lt;code&gt;search key - pointer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Index files are typically much smaller than the original file&lt;/li&gt;
&lt;li&gt;Two basic kinds of indices
&lt;ul&gt;
&lt;li&gt;Ordered indices:  search keys are stored in sorted order&lt;/li&gt;
&lt;li&gt;Hash indices:  search keys are distributed across &amp;ldquo;buckets&amp;rdquo; using a &amp;ldquo;hash function&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexing_example.png&#34; alt=&#34;indexing_example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;good-index&#34;&gt;Good Index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Index quality is evaluated by several factors
&lt;ul&gt;
&lt;li&gt;Access types supported by the index efficiently
&lt;ul&gt;
&lt;li&gt;records with a specified value in the attribute (equality query)&lt;/li&gt;
&lt;li&gt;or records with an attribute value falling in a specified range of values (range query)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Access time – query response time&lt;/li&gt;
&lt;li&gt;Insertion time – data record insertion time&lt;/li&gt;
&lt;li&gt;Deletion time – data record deletion time&lt;/li&gt;
&lt;li&gt;Space overhead – size of the index file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;classification-of-indexes&#34;&gt;Classification of Indexes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Primary index
&lt;ul&gt;
&lt;li&gt;In a sequentially ordered file, the index whose search key specifies the sequential order of the file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary index
&lt;ul&gt;
&lt;li&gt;an index whose search key specifies an order different from the sequential order of the file&lt;/li&gt;
&lt;li&gt;Also called non-clustered index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/classification_of_indexing.png&#34; alt=&#34;classification_of_indexing&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dense index
&lt;ul&gt;
&lt;li&gt;Index record appears for every search-key value in the file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sparse Index
&lt;ul&gt;
&lt;li&gt;Contains index records for only some search-key values&lt;/li&gt;
&lt;li&gt;Applicable when records are sequentially ordered on search-key&lt;/li&gt;
&lt;li&gt;Less space and less maintenance overhead for insertions and deletions&lt;/li&gt;
&lt;li&gt;Generally slower than dense index for locating records&lt;/li&gt;
&lt;li&gt;Good tradeoff: sparse index with an index entry for every block in file, corresponding to least search-key value in the block&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/classification_of_indexing_2.png&#34; alt=&#34;classification_of_indexing_2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;primary-and-secondary-indices&#34;&gt;Primary and Secondary Indices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Secondary indices have to be dense&lt;/li&gt;
&lt;li&gt;Indices offer substantial benefits when searching for records
&lt;ul&gt;
&lt;li&gt;Index is much smaller than relation file (cheap scan)&lt;/li&gt;
&lt;li&gt;Index can be ordered (fast search)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;When a file is modified, every index on the file must be updated
&lt;ul&gt;
&lt;li&gt;Updating indices imposes overhead on database modification&lt;/li&gt;
&lt;li&gt;Indexes should be used with care&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential scan using primary index is efficient, but a sequential scan using a secondary index is expensive
&lt;ul&gt;
&lt;li&gt;Each record access may fetch a new block from disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multilevel-index&#34;&gt;Multilevel Index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If index does not fit in memory, access becomes expensive&lt;/li&gt;
&lt;li&gt;To reduce number of disk accesses to index records, treat 1st level of index kept on disk as a sequential file and construct a sparse index on it
&lt;ul&gt;
&lt;li&gt;outer index – a sparse index on 1st-level index file&lt;/li&gt;
&lt;li&gt;inner index – the 1st-level index file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If even outer index is too large to fit in main memory, yet another level of index can be created, and so on&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/multilevel_index_example.png&#34; alt=&#34;multilevel_index_example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;b-tree-index-files&#34;&gt;B+-Tree Index Files&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A dynamic, multi-level index&lt;/li&gt;
&lt;li&gt;Advantage
&lt;ul&gt;
&lt;li&gt;automatically reorganizes itself with small local changes, in the face of insertions and deletions&lt;/li&gt;
&lt;li&gt;Reorganization of entire file is not required to maintain performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disadvantage of B+-trees
&lt;ul&gt;
&lt;li&gt;Extra insertion and deletion overhead, space overhead&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Advantages of B+-trees outweigh disadvantages, and they are used extensively&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;basic-properties&#34;&gt;Basic Properties&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Disk-based tree structure
&lt;ul&gt;
&lt;li&gt;every node of the tree is a block and has an address (block-id) on the disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiway tree
&lt;ul&gt;
&lt;li&gt;each node has multiple children (between n/2 and n, where n/2 is the order or degree of the tree)&lt;/li&gt;
&lt;li&gt;Therefore, at least 50% of the space in a node is guaranteed to be occupied (this rule may not apply to tree root)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Balanced tree
&lt;ul&gt;
&lt;li&gt;all paths from the root to a leaf have the same length&lt;/li&gt;
&lt;li&gt;guarantees good search performance (to be seen later)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disjoint partition of attribute domain into ranges
&lt;ul&gt;
&lt;li&gt;each sub-tree indexes a range in the attribute domain&lt;/li&gt;
&lt;li&gt;the entries of a directory node define the separators between domain intervals&lt;/li&gt;
&lt;li&gt;leaf nodes store index entries and pointers to the relation file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Example.png&#34; alt=&#34;B_Plus_Tree_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;non-leaf-nodes-in-b-trees&#34;&gt;Non-Leaf Nodes in B+-Trees&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Each non-leaf node contains up to n-1 search key values and up to n pointers&lt;/li&gt;
&lt;li&gt;All non-leaf nodes (except root) contain at least n/2 pointers (n/2 is sometimes called the minimum fan-out or degree)&lt;/li&gt;
&lt;li&gt;Non leaf nodes form a multi-level sparse index on the leaf nodes.  For a non-leaf node with m pointers
&lt;ul&gt;
&lt;li&gt;All the search-keys in the subtree to which P1 points are less than K1&lt;/li&gt;
&lt;li&gt;For 2 &amp;lt;= i &amp;lt;= n – 1, all the search-keys in the subtree to which Pi points have values greater than or equal to Ki–1 and smaller than Km–1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Non_Leaf_Node.png&#34; alt=&#34;B_Plus_Tree_Non_Leaf_Node&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;leaf-node-in-a-b-tree&#34;&gt;Leaf Node in a B+-Tree&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Contains between (n-1)/2 and n-1 entries&lt;/li&gt;
&lt;li&gt;Each index entry is a search key value + a record-id&lt;/li&gt;
&lt;li&gt;If Li, Lj are leaf nodes and i &amp;lt; j, Li’s search-key values are all smaller than Lj’s search-key values&lt;/li&gt;
&lt;li&gt;Each leaf node is linked with a pointer to the next node&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;observations&#34;&gt;Observations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Since the inter-node connections are done by pointers, &amp;ldquo;logically&amp;rdquo; close blocks need not be “physically” close
&lt;ul&gt;
&lt;li&gt;Nodes of the tree are dynamically created/deleted, so we cannot guarantee physical closeness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The non-leaf levels of the B+-tree form a hierarchy of sparse indices&lt;/li&gt;
&lt;li&gt;The B+-tree contains a relatively small number of levels (logarithmic in the size of the main file), thus searches can be conducted efficiently&lt;/li&gt;
&lt;li&gt;Insertions and deletions to the main file can be handled efficiently (in logarithmic time)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;queries&#34;&gt;Queries&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Find all records with a search-key value of k&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start with the root node
&lt;ul&gt;
&lt;li&gt;Examine the node for the smallest search-key value &amp;gt; k&lt;/li&gt;
&lt;li&gt;If such a value exists, assume it is Ki.  Then follow Pi to the child node. (E.g. P2 is for keys in  K1 &amp;lt;= Keys &amp;lt; K2 )&lt;/li&gt;
&lt;li&gt;Otherwise k &amp;gt;= Kn–1, where there are n pointers in the node.  Then follow Pn to the child node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the node reached by following the pointer above is not a leaf node, repeat the above procedure on the node, and follow the corresponding pointer&lt;/li&gt;
&lt;li&gt;Eventually reach a leaf node.  If for some i, key Ki = k  follow pointer Pi  to the desired record.  Else no record with search-key value k exists&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In processing a query, a path is traversed in the tree from the root to some leaf node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If there are K search-key values in the file, the path is not longer than log(n/2)(K). (The degree of a node is no less than n/2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A node has generally the same size of a disk block, typically 4 kilobytes, and n is typically around 100 (40 bytes per index entry)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With 1 million search key values and n/2 = 50, at most log50(1,000,000) = 4 nodes are accessed in a lookup&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Contrast this with a balanced binary tree with 1 million search key values — around 20 nodes are accessed in a lookup&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(log2(1,000,000) ~= 20)&lt;/li&gt;
&lt;li&gt;above difference is significant since every node access may need a disk I/O, costing around 10 milliseconds!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similar result for a binary search of an ordered sequential file&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;range-queries&#34;&gt;Range Queries&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find all records with a search-key value between k and m (k&amp;lt;m)
&lt;ul&gt;
&lt;li&gt;Start with the root node
&lt;ul&gt;
&lt;li&gt;Examine the node for the smallest search-key value &amp;gt; k&lt;/li&gt;
&lt;li&gt;If such a value exists, assume it is Kj
&lt;ul&gt;
&lt;li&gt;Then follow Pi to the child node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Otherwise k &amp;gt;= Kn–1, where there are n pointers in the node
&lt;ul&gt;
&lt;li&gt;Then follow Pn to the child node.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the node reached by following the pointer above is not a leaf node, repeat the above procedure on the node, and follow the corresponding pointer&lt;/li&gt;
&lt;li&gt;Eventually reach a leaf node.  If for some i, k &amp;lt;= Ki &amp;lt;= m follow pointer Pi  to the desired record. Continue with next entry Ki+1, while Ki+1 &amp;lt;= m. If at end of leaf node follow pointer to next node, until Ki &amp;gt;m or end of index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Range_Query.png&#34; alt=&#34;B_Plus_Tree_Range_Query&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;insertion&#34;&gt;Insertion&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the leaf node in which the search-key value to be inserted  would appear&lt;/li&gt;
&lt;li&gt;If the search-key value is already there in the leaf node, record is added to file and if necessary one more pointer is associated with the search key value&lt;/li&gt;
&lt;li&gt;If the search-key value is not there, then add the record to the main file. Then
&lt;ul&gt;
&lt;li&gt;If there is room in the leaf node, insert (key-value, pointer) pair in the leaf node&lt;/li&gt;
&lt;li&gt;Otherwise, split the node (along with the new (key-value, pointer) entry) as discussed in the next slides&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Insertion.png&#34; alt=&#34;B_Plus_Tree_Insertion&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;splitting&#34;&gt;Splitting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Splitting a node
&lt;ul&gt;
&lt;li&gt;take the (search-key value, pointer) pairs (including the one being inserted) in sorted order.  Place the first n/2 in the original node, and the rest in a new node&lt;/li&gt;
&lt;li&gt;let the new node be p, and let k be the least key value in p.  Insert (k,p) in the parent of the node being split. If the parent is full, split it and propagate the split further up&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The splitting of nodes proceeds upwards till a node that is not full is found.  In the worst case the root node may be split increasing the height of the tree by 1&lt;/li&gt;
&lt;li&gt;Non-leaf node splitting
&lt;ul&gt;
&lt;li&gt;Overflown node has n+1 pointers and n values&lt;/li&gt;
&lt;li&gt;Leave first n/2 key values and n/2+1 pointers to original node&lt;/li&gt;
&lt;li&gt;Move last n/2 key values and n/2+1 pointers to new node&lt;/li&gt;
&lt;li&gt;insert (middle key value, pointer to new node) to parent node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_splitting.png&#34; alt=&#34;B_Plus_Tree_splitting&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;deletion&#34;&gt;Deletion&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the record to be deleted, and remove it from the relation file&lt;/li&gt;
&lt;li&gt;Remove (search-key value, record-id) of deleted record from the leaf node of the B+-tree&lt;/li&gt;
&lt;li&gt;If the node has too few entries due to the removal, and the entries in the node and a sibling fit into a single node, then
&lt;ul&gt;
&lt;li&gt;Insert all the search-key values in the two nodes into a single node (the one on the left), and delete the other node. (Deletion triggers a merge)&lt;/li&gt;
&lt;li&gt;Delete the pair (Ki–1, Pi), where Pi is the pointer to the deleted node, from its parent, recursively using the above procedure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Otherwise, if the node has too few entries due to the removal, and the entries in the node and a sibling does not fit into a single node, then
&lt;ul&gt;
&lt;li&gt;Redistribute the pointers between the node and a sibling such that both have more than the minimum number of entries. (Deletion and rebalancing)&lt;/li&gt;
&lt;li&gt;Update the corresponding search-key value in the parent of the node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The node deletions may cascade upwards until a node which has n/2 or more pointers is found.  If the root node has only one pointer after deletion, it is deleted and the sole child becomes the root&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_deletion.png&#34; alt=&#34;B_Plus_Tree_deletion&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;static-hashing&#34;&gt;Static Hashing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A bucket is a unit of storage containing one or more records (a bucket is typically a disk block)&lt;/li&gt;
&lt;li&gt;In a hash file organization we obtain the bucket of a record directly from its search-key value using a hash function&lt;/li&gt;
&lt;li&gt;Hash function h is a function from the set of all search-key values K to the set of all bucket addresses B&lt;/li&gt;
&lt;li&gt;Hash function is used to locate records for access, insertion as well as deletion&lt;/li&gt;
&lt;li&gt;Records with different search-key values may be mapped to the same bucket; thus entire bucket has to be searched sequentially to locate a record. (Collision)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexing_hashing.png&#34; alt=&#34;indexing_hashing&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;hash-function&#34;&gt;Hash Function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Worst case has function maps all search-key values to the same bucket; this makes access time proportional to the number of search-key values in the file&lt;/li&gt;
&lt;li&gt;An ideal hash function is uniform, i.e., each bucket is assigned the same number of search-key values from the set of all possible values&lt;/li&gt;
&lt;li&gt;Ideal hash function is random, so each bucket will have the same number of records assigned to it irrespective of the actual distribution of search-key values in the file&lt;/li&gt;
&lt;li&gt;Typical hash functions perform computation on the internal binary representation of the search-key
&lt;ul&gt;
&lt;li&gt;For example, for a string search-key, the binary representations of all the characters in the string could be added and the sum modulo the number of buckets could be returned&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;handling-of-bucket-overflows&#34;&gt;Handling of Bucket Overflows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Bucket overflow can occur because of
&lt;ul&gt;
&lt;li&gt;Insufficient buckets&lt;/li&gt;
&lt;li&gt;Skew in distribution of records.  This can occur due to two reasons
&lt;ul&gt;
&lt;li&gt;multiple records have same search-key value&lt;/li&gt;
&lt;li&gt;chosen hash function produces non-uniform distribution of key values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Although the probability of bucket overflow can be reduced, it cannot be eliminated; it is handled by using overflow buckets&lt;/li&gt;
&lt;li&gt;Overflow chaining / closed hashing – the overflow buckets of a given bucket are chained together in a linked list&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hash-indices&#34;&gt;Hash Indices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Hashing can be used not only for file organization, but also for index-structure creation&lt;/li&gt;
&lt;li&gt;A hash index organizes the search keys, with their associated record pointers, into a hash file structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hash_Index.png&#34; alt=&#34;Hash_Index&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;deficiencies-of-static-hashing&#34;&gt;Deficiencies of Static Hashing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In static hashing, function h maps search-key values to a fixed set of B of bucket addresses
&lt;ul&gt;
&lt;li&gt;Databases grow with time.  If initial number of buckets is too small, performance will degrade due to too much overflows&lt;/li&gt;
&lt;li&gt;If file size at some point in the future is anticipated and number of buckets allocated accordingly, significant amount of space will be wasted initially&lt;/li&gt;
&lt;li&gt;If database shrinks, again space will be wasted&lt;/li&gt;
&lt;li&gt;One option is periodic re-organization of the file with a new hash function, but it is very expensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;These problems can be avoided by using techniques that allow the number of buckets to be modified dynamically (dynamic hashing)&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 1 Introduction</title>
      <link>https://www.pseudoyu.com/zh/2021/01/28/comp7103_topic1/</link>
      <pubDate>Thu, 28 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/28/comp7103_topic1/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-1-introduction&#34;&gt;Topic 1 Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Decision-Support System (DSS)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A decision-support system (DSS) is a system that assists decision makers to make important decisions for an organization or business&lt;/li&gt;
&lt;li&gt;KDD and data mining are important components in many DSS&amp;rsquo;s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data and Knowledge&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;A collecion of facts about certain group of objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pattern
&lt;ul&gt;
&lt;li&gt;Certain characteristics of data that are frequently observed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Knowledge
&lt;ul&gt;
&lt;li&gt;Some general rules about the objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Warehouse&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An integration of various departmental databases (organization-wide data)&lt;/li&gt;
&lt;li&gt;Avoids overloading local operational databases&lt;/li&gt;
&lt;li&gt;A convenient place where KDD and data mining applications are performed&lt;/li&gt;
&lt;li&gt;Provide data mining algorithms an easy access to the required data&lt;/li&gt;
&lt;li&gt;Wrappers
&lt;ul&gt;
&lt;li&gt;Extract&lt;/li&gt;
&lt;li&gt;Transform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can also be used to support other DSS tools, e.g. On-Line Analytical Processing (OLAP) - analyze large amount of data, Online Transaction Processing (OLTP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Mining and KDD&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KDD (Knowledge Discovery in Databases)
&lt;ul&gt;
&lt;li&gt;A process of discovering useful knowledge from big collection of data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Mining
&lt;ul&gt;
&lt;li&gt;A step within the KDD process in which interesting patterns are found. Some of these patterns are then interpreted and transformed into useful knowledge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Data Mining is a step in the whole KDD process&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;KDD is a process of identifying patterns in data and deriving knowledge from them&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;valid&lt;/li&gt;
&lt;li&gt;novel&lt;/li&gt;
&lt;li&gt;potentially useful&lt;/li&gt;
&lt;li&gt;understandable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Mining&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/data_mining_system.png&#34; alt=&#34;data_mining_system&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Databases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bottom layer of the architecture&lt;/li&gt;
&lt;li&gt;Contains data sources (raw data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Traditional Database usually only provides the functions of storing and retrieving facts&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The knowledge resulting from data mining should carry certain degree of predictive ability or descriptive (explanatory) ability (or both)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Mining Engine&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applies data mining algorithms on data&lt;/li&gt;
&lt;li&gt;Provides multiple functionality&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Evaluation Module&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow users to specify what is/isn&amp;rsquo;t interesting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Knowledge Base&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Capture domain specific knowledge&lt;/li&gt;
&lt;li&gt;Stores the rules generated by data mining&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Graphical User Interface&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Presents mined patterns and rules to users in an easy-to-visualize way&lt;/li&gt;
&lt;li&gt;Provides feedback mechanisms for the users to specify the criteria of interestingness&lt;/li&gt;
&lt;li&gt;Provides a query language or query interface for users to select and retrieve&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Challenges of Data Mining&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technical
&lt;ul&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Dimensionality&lt;/li&gt;
&lt;li&gt;Data stream&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Complex and heterogeneous data&lt;/li&gt;
&lt;li&gt;Data quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Privacy
&lt;ul&gt;
&lt;li&gt;Data ownership and distribution&lt;/li&gt;
&lt;li&gt;Privacy preservation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Results
&lt;ul&gt;
&lt;li&gt;Interpretation of patterns&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The KDD Process&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kdd_process.png&#34; alt=&#34;kdd_process&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: Goal Setting
&lt;ul&gt;
&lt;li&gt;Understand your application domain&lt;/li&gt;
&lt;li&gt;Obtain prior known knowledge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 2: Data Collection
&lt;ul&gt;
&lt;li&gt;Characteristics&lt;/li&gt;
&lt;li&gt;Where to find&lt;/li&gt;
&lt;li&gt;How to store&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 3: Data Cleaning and Preprocessing
&lt;ul&gt;
&lt;li&gt;Missing data&lt;/li&gt;
&lt;li&gt;Incorrect data (noise)&lt;/li&gt;
&lt;li&gt;Outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 4: Data Reduction and Transformation (or Preparation)
&lt;ul&gt;
&lt;li&gt;Compact data into a form&lt;/li&gt;
&lt;li&gt;Improve data mining algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 5: Data Mining
&lt;ul&gt;
&lt;li&gt;Pick a data mining model&lt;/li&gt;
&lt;li&gt;Pick a data mining algorithm&lt;/li&gt;
&lt;li&gt;Apply the algorithm to the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 6: Result Evaluation
&lt;ul&gt;
&lt;li&gt;Check the results and goals&lt;/li&gt;
&lt;li&gt;Refine and re-run (if not)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 7: Knowledge Consolidation
&lt;ul&gt;
&lt;li&gt;Document&lt;/li&gt;
&lt;li&gt;Report&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Iterative and Interactive&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some steps of the process need to be refined, and the whole process be repeated&lt;/li&gt;
&lt;li&gt;Certain amount of human involvement is needed to monitor and to fine tune the steps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uses database records that describe information about past behavior to automatically generate a model (or rule) that can predict future behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Derive patterns that summarize the underlying relationships in data and to describe the characteristics of data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;OLAP (On-Line Analytical Processing)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;View data in a multi-dimensional model (a data cube)&lt;/li&gt;
&lt;li&gt;Fast aggregation&lt;/li&gt;
&lt;li&gt;Summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selection -&amp;gt; Group-by -&amp;gt; Summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Supervised learning&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Unseen records should be assigned a class (accuracy)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approach
&lt;ul&gt;
&lt;li&gt;Given a training set&lt;/li&gt;
&lt;li&gt;Learn classifier&lt;/li&gt;
&lt;li&gt;Find a model&lt;/li&gt;
&lt;li&gt;Test the model using test set&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct Marketing
&lt;ul&gt;
&lt;li&gt;Reduce cost of mailing by targeting a set of consumers likely to buy a new cell-phone product&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Preduct a value of numerical variable based on the values of other variables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predicting sales amounts of new product based on advertising expenditure&lt;/li&gt;
&lt;li&gt;Predicting wind velocities as a function of temperature, humidity, air pressure, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Clustering&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of data objects with a set of attributes and similarity measure&lt;/li&gt;
&lt;li&gt;Find clusters (e.g. distance-based clustering)
&lt;ul&gt;
&lt;li&gt;Maximize the intra-cluster similarity&lt;/li&gt;
&lt;li&gt;Minimize the inter-cluster similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objects in one cluster are more similiar to one another&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/illustrating_cluster.png&#34; alt=&#34;illustrating_cluster&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Document Clustering
&lt;ul&gt;
&lt;li&gt;To find groups of documents that are similar to each other based on the important terms they contain&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Association Rule Discovery&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of records each of which contains some items from a given collection&lt;/li&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Produce dependency rules which predict occurrence of an item based on occurrences of other items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Marketing and Sales Promotion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sequence Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a sequence database contains sequences of events&lt;/li&gt;
&lt;li&gt;Find sequences
&lt;ul&gt;
&lt;li&gt;Interesting&lt;/li&gt;
&lt;li&gt;Frequently occurring&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Predict future behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Renting movies&lt;/li&gt;
&lt;li&gt;Buying habits&lt;/li&gt;
&lt;li&gt;Web serving behavior&lt;/li&gt;
&lt;li&gt;Web log analysis&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链安全问题概述</title>
      <link>https://www.pseudoyu.com/zh/2021/01/25/blockchain_note_security/</link>
      <pubDate>Mon, 25 Jan 2021 05:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/25/blockchain_note_security/</guid>
      
        <description>&lt;h2 id=&#34;区块链安全问题概述&#34;&gt;区块链安全问题概述&lt;/h2&gt;
&lt;h3 id=&#34;风险来源&#34;&gt;风险来源&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;应用层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;与应用程序相关的攻击和安全问题，如数字货币交易所&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;智能合约层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;很多潜在风险，如DAO事件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;激励层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;矿工付出成本 &amp;gt; 奖励，则去中心化系统可能崩溃&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;共识层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bribe Attack&lt;/li&gt;
&lt;li&gt;Long-Range Attack&lt;/li&gt;
&lt;li&gt;Coin age Accumulation Attack&lt;/li&gt;
&lt;li&gt;Precomputing Attack&lt;/li&gt;
&lt;li&gt;Sybil Attack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;网络层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BGP hijacking: 大约60%的比特币流量是通过几个互联网服务提供商，这些互联网服务提供商可以轻松控制和查看流量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;数据层&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;恶意信息攻击（区块链上数据不可变）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;区块链风险分类&#34;&gt;区块链风险分类&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;51%攻击 - 共识机制&lt;/li&gt;
&lt;li&gt;私钥安全 - 加密方案&lt;/li&gt;
&lt;li&gt;违法行为 - 数字货币应用&lt;/li&gt;
&lt;li&gt;双重花费 - 验证机制&lt;/li&gt;
&lt;li&gt;信息传输隐私泄漏 - 交易方案设计缺陷&lt;/li&gt;
&lt;li&gt;恶意智能合约 - 智能合约应用&lt;/li&gt;
&lt;li&gt;智能合约漏洞 - 智能合约开发缺陷&lt;/li&gt;
&lt;li&gt;智能合约执行优化 - 程序执行缺陷&lt;/li&gt;
&lt;li&gt;低成本操作 - EVM设计缺陷&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;风险分析&#34;&gt;风险分析&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;协议&lt;/li&gt;
&lt;li&gt;加密方案&lt;/li&gt;
&lt;li&gt;应用&lt;/li&gt;
&lt;li&gt;程序开发&lt;/li&gt;
&lt;li&gt;系统&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以太坊智能合约漏洞&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solidity 编程语言&lt;/li&gt;
&lt;li&gt;EVM 以太坊虚拟机&lt;/li&gt;
&lt;li&gt;Blockchain 区块链&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;著名安全事件&#34;&gt;著名安全事件&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Youbit&lt;/li&gt;
&lt;li&gt;Bitfinex
&lt;ul&gt;
&lt;li&gt;DDoS攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ICO攻击
&lt;ul&gt;
&lt;li&gt;对ICO钱包地址进行攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mt. Gox事件
&lt;ul&gt;
&lt;li&gt;占据70%比特币交易&lt;/li&gt;
&lt;li&gt;US$450M比特币被盗&lt;/li&gt;
&lt;li&gt;利用了比特币transaction malleability&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DAO事件
&lt;ul&gt;
&lt;li&gt;一个众筹智能合约应用&lt;/li&gt;
&lt;li&gt;利用了Solidity语言的脆弱性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;transaction-malleability攻击概述&#34;&gt;Transaction Malleability攻击概述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;每一笔交易都被数字签名&lt;/li&gt;
&lt;li&gt;创建Hash作为交易ID&lt;/li&gt;
&lt;li&gt;在早期的实现中，对于padding数据没有严格标准，hash创建使用&amp;lt;$,form, to, padding string&amp;gt;&lt;/li&gt;
&lt;li&gt;攻击者可以改变padding字符串从而改变交易ID&lt;/li&gt;
&lt;li&gt;攻击者要求交易所转出1美元&lt;/li&gt;
&lt;li&gt;交易所会通知攻击者关于交易ID&lt;/li&gt;
&lt;li&gt;攻击者更改ID，存入金额，并声明交易丢失，欺骗交易所重新发送&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;智能合约安全&#34;&gt;智能合约安全&lt;/h3&gt;
&lt;p&gt;E.g. 低成本攻击&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础
&lt;ul&gt;
&lt;li&gt;智能合约&lt;/li&gt;
&lt;li&gt;以太坊Gas机制
&lt;ul&gt;
&lt;li&gt;收取用户执行合约费用，以避免智能合约占用大量计算资源&lt;/li&gt;
&lt;li&gt;每个操作都分配有特定的Gas单位&lt;/li&gt;
&lt;li&gt;用户可以指定每单位Gas的数量和限额&lt;/li&gt;
&lt;li&gt;执行智能合约代码的矿工获得Gas费用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;攻击思路
&lt;ul&gt;
&lt;li&gt;识别较低Gas费的操作&lt;/li&gt;
&lt;li&gt;重复执行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;实例
&lt;ul&gt;
&lt;li&gt;EXTCODESIZE&lt;/li&gt;
&lt;li&gt;SUICIDE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;更通用的安全解决方案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建一个自动检查器来检查代码以识别恶意代码&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 1a Relational Database</title>
      <link>https://www.pseudoyu.com/zh/2021/01/23/comp7801_topic1a/</link>
      <pubDate>Sat, 23 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/23/comp7801_topic1a/</guid>
      
        <description>&lt;h2 id=&#34;relational-databases&#34;&gt;Relational Databases&lt;/h2&gt;
&lt;h3 id=&#34;structure-of-relational-databases&#34;&gt;Structure of Relational Databases&lt;/h3&gt;
&lt;h4 id=&#34;basic-structure&#34;&gt;Basic structure&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Given sets D1, D2, …. Dn&lt;/li&gt;
&lt;li&gt;A relation r is a subset of D1 x  D2  x … x Dn&lt;/li&gt;
&lt;li&gt;A relation is a set of n-tuples (a1, a2, …, an) where each ai  &lt;!-- raw HTML omitted --&gt; Di&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;customer-name = {Jones, Smith, Curry, Lindsay}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;customer-street = {Main, North, Park}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;customer-city = {Harrison, Rye, Pittsfield}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Then
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;r = {(Jones, Main, Harrison), (Smith, North, Rye), (Curry, North, Rye), (Lindsay, Park, Pittsfield)}&lt;/code&gt; is a relation over customer-name x customer-street x customer-city&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;attribute-types&#34;&gt;Attribute Types&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Each attribute of a relation has a name&lt;/li&gt;
&lt;li&gt;The set of allowed values for each attribute is called the domain of the attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;relation-schema&#34;&gt;Relation Schema&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A1, A2, …, An are attributes&lt;/li&gt;
&lt;li&gt;R = (A1, A2, …, An ) is a relation schema
&lt;ul&gt;
&lt;li&gt;E.g. &lt;code&gt;Account-schema = (account-number, branch-name, balance)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;r(R) is a relation on the relation schema R
&lt;ul&gt;
&lt;li&gt;E.g. &lt;code&gt;customer(Customer-schema)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;relation-instance&#34;&gt;Relation Instance&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The current values (relation instance) of a relation are specified by a table&lt;/li&gt;
&lt;li&gt;An element t of r is a tuple, represented by a row in a table&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/relation_instance.png&#34; alt=&#34;relation_instance&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;database&#34;&gt;Database&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A database consists of multiple relations which are inter-related&lt;/li&gt;
&lt;li&gt;Information about an enterprise is broken up into parts, with each relation storing one part of the information&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/database_overview.png&#34; alt=&#34;database_overview&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;query-language&#34;&gt;Query language&lt;/h4&gt;
&lt;p&gt;Language in which user requests information from the database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Categories
&lt;ul&gt;
&lt;li&gt;procedural&lt;/li&gt;
&lt;li&gt;non-procedural&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pure languages
&lt;ul&gt;
&lt;li&gt;Relational Algebra
&lt;ul&gt;
&lt;li&gt;The operators take one or more relations as inputs and give a new relation as a result&lt;/li&gt;
&lt;li&gt;Operations
&lt;ul&gt;
&lt;li&gt;select&lt;/li&gt;
&lt;li&gt;project&lt;/li&gt;
&lt;li&gt;union&lt;/li&gt;
&lt;li&gt;set-Intersection&lt;/li&gt;
&lt;li&gt;set difference&lt;/li&gt;
&lt;li&gt;cartesian product&lt;/li&gt;
&lt;li&gt;rename&lt;/li&gt;
&lt;li&gt;Natural Join&lt;/li&gt;
&lt;li&gt;Aggregate Functions
&lt;ul&gt;
&lt;li&gt;avg:  average value&lt;/li&gt;
&lt;li&gt;min:  minimum value&lt;/li&gt;
&lt;li&gt;max:  maximum value&lt;/li&gt;
&lt;li&gt;sum:  sum of values&lt;/li&gt;
&lt;li&gt;count:  number of values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relational Calculus&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL is based on set and relational operations with certain modifications and enhancements&lt;/li&gt;
&lt;li&gt;A typical SQL query has the form
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select A1, A2, ..., Anfrom r1, r2, ..., rm where P&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The result of an SQL query is a multiset of tuples&lt;/li&gt;
&lt;li&gt;Clauses
&lt;ul&gt;
&lt;li&gt;select
&lt;ul&gt;
&lt;li&gt;To force the elimination of duplicates, insert the keyword &lt;code&gt;distinct&lt;/code&gt; after &lt;code&gt;select&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;where
&lt;ul&gt;
&lt;li&gt;The where clause specifies conditions that the result must satisfy
&lt;ul&gt;
&lt;li&gt;Comparison results can be combined using the logical connectives and, or, and not&lt;/li&gt;
&lt;li&gt;Comparisons can be applied to results of arithmetic expressions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;from
&lt;ul&gt;
&lt;li&gt;The from clause lists the relations involved in the query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aggregate Functions
&lt;ul&gt;
&lt;li&gt;Group By
&lt;ul&gt;
&lt;li&gt;Find the number of depositors for each branch
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select branch-name,count (distinct customer-name)from depositor,account where depositor.account-number = account.account-numbergroup by branch-name&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Having
&lt;ul&gt;
&lt;li&gt;formation of groups whereas predicates in the where clause are applied before forming groups&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Query Evaluation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basic operations
&lt;ul&gt;
&lt;li&gt;Selections&lt;/li&gt;
&lt;li&gt;Joins&lt;/li&gt;
&lt;li&gt;Other operations (projection, aggregation)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Transformation of queries into a tree of operations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Query Optimizationh&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many equivalent expressions to the original query can be derived&lt;/li&gt;
&lt;li&gt;The query optimizer uses statistical data and appropriate algorithms to compute an expression of low evaluation cost&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;storage-of-databases&#34;&gt;Storage of databases&lt;/h3&gt;
&lt;h4 id=&#34;physical-storage-media&#34;&gt;Physical Storage Media&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cache
&lt;ul&gt;
&lt;li&gt;fastest and most costly form of storage&lt;/li&gt;
&lt;li&gt;volatile&lt;/li&gt;
&lt;li&gt;managed by the computer system hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Main memory
&lt;ul&gt;
&lt;li&gt;fast access&lt;/li&gt;
&lt;li&gt;generally too small (or too expensive) to store the entire database&lt;/li&gt;
&lt;li&gt;Volatile
&lt;ul&gt;
&lt;li&gt;contents of main memory are usually lost if a power failure or system crash occurs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Magnetic-disk
&lt;ul&gt;
&lt;li&gt;Data is stored on spinning disk, and read/written magnetically&lt;/li&gt;
&lt;li&gt;Primary medium for the long-term storage of data&lt;/li&gt;
&lt;li&gt;typically stores entire database&lt;/li&gt;
&lt;li&gt;Data must be moved from disk to main memory for access, and written back for storage
&lt;ul&gt;
&lt;li&gt;Much slower access than main memory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;direct-access –  possible to read data on disk in any order, unlike magnetic tape&lt;/li&gt;
&lt;li&gt;Capacities range up to several TB currently&lt;/li&gt;
&lt;li&gt;Survives power failures and system crashes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;storage-hierarchy&#34;&gt;Storage Hierarchy&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Primary storage
&lt;ul&gt;
&lt;li&gt;Fastest media but volatile (cache, main memory).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary storage&lt;/li&gt;
&lt;li&gt;Next level in hierarchy, non-volatile, moderately fast access time
&lt;ul&gt;
&lt;li&gt;Also called on-line storage, E.g. flash memory, magnetic disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tertiary storage: lowest level in hierarchy, non-volatile, slow access time
&lt;ul&gt;
&lt;li&gt;Also called off-line storage, E.g. magnetic tape, optical storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/memory_hierarchy.png&#34; alt=&#34;memory_hierarchy&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;magnetic-disks&#34;&gt;Magnetic Disks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Read-write head
&lt;ul&gt;
&lt;li&gt;Positioned very close to the platter surface (almost touching it)&lt;/li&gt;
&lt;li&gt;Reads or writes magnetically encoded information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Surface of platter divided into circular tracks
&lt;ul&gt;
&lt;li&gt;Over 16,000 tracks per platter on typical hard disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each track is divided into sectors
&lt;ul&gt;
&lt;li&gt;A sector is the smallest unit of data that can be read or written&lt;/li&gt;
&lt;li&gt;Sector size typically 512 bytes&lt;/li&gt;
&lt;li&gt;Typical sectors per track: 200 (on inner tracks) to 400 (on outer tracks)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To read/write a sector
&lt;ul&gt;
&lt;li&gt;disk arm swings to position head on right track&lt;/li&gt;
&lt;li&gt;platter spins continually; data is read/written as sector passes under head&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Head-disk assemblies
&lt;ul&gt;
&lt;li&gt;multiple disk platters on a single spindle (typically 2 to 4)&lt;/li&gt;
&lt;li&gt;one head per platter, mounted on a common arm.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cylinder i consists of ith track of all the platters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/magnetic_hard_disk.png&#34; alt=&#34;magnetic_hard_disk&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;performance-measures-of-disks&#34;&gt;Performance Measures of Disks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Access time – the time it takes from when a read or write request is issued to when data transfer begins
&lt;ul&gt;
&lt;li&gt;Seek time – time it takes to reposition the arm over the correct track
&lt;ul&gt;
&lt;li&gt;Average seek time is 1/2 the worst case seek time
&lt;ul&gt;
&lt;li&gt;Would be 1/3 if all tracks had the same number of sectors, and we ignore the time to start and stop arm movement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;4 to 10 milliseconds on typical disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rotational latency – time it takes for the sector to be accessed to appear under the head
&lt;ul&gt;
&lt;li&gt;Average latency is 1/2 of the worst case latency&lt;/li&gt;
&lt;li&gt;4 to 11 milliseconds on typical disks (5400 to 15000 r.p.m.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data-transfer rate – the rate at which data can be retrieved from or stored to the disk
&lt;ul&gt;
&lt;li&gt;4 to 8 MB per second is typical&lt;/li&gt;
&lt;li&gt;Multiple disks may share a controller, so rate that controller can handle is also important&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;optimization-of-disk-block-access&#34;&gt;Optimization of Disk-Block Access&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Block – a contiguous sequence of sectors from a single track
&lt;ul&gt;
&lt;li&gt;data is transferred between disk and main memory in blocks&lt;/li&gt;
&lt;li&gt;sizes range from 512 bytes to several kilobytes
&lt;ul&gt;
&lt;li&gt;Smaller blocks: more transfers from disk&lt;/li&gt;
&lt;li&gt;Larger blocks:  more space wasted due to partially filled blocks&lt;/li&gt;
&lt;li&gt;Typical block sizes today range from 4 to 16 kilobytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disk-arm-scheduling algorithms order pending accesses to tracks so that disk arm movement is minimized&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;storage-access&#34;&gt;Storage Access&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A database file is partitioned into fixed-length storage units called blocks.  Blocks are units of both storage allocation and data transfer. Typical size of a block ranges between 4Kb-16Kb&lt;/li&gt;
&lt;li&gt;Database system seeks to minimize the number of block transfers between the disk and memory.  We can reduce the number of disk accesses by keeping as many blocks as possible in main memory&lt;/li&gt;
&lt;li&gt;Buffer
&lt;ul&gt;
&lt;li&gt;portion of main memory available to store copies of disk blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Buffer manager
&lt;ul&gt;
&lt;li&gt;subsystem responsible for allocating buffer space in main memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/storage_access.png&#34; alt=&#34;storage_access&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;buffer-manager&#34;&gt;Buffer manager&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Programs call on the buffer manager when they need a block from disk
&lt;ul&gt;
&lt;li&gt;If the block is already in the buffer, the requesting program is given the address of the block in main memory&lt;/li&gt;
&lt;li&gt;If the block is not in the buffer
&lt;ul&gt;
&lt;li&gt;the buffer manager allocates space in the buffer for the block, replacing (throwing out) some other block, if required, to make space for the new block&lt;/li&gt;
&lt;li&gt;The block that is thrown out is written back to disk only if it was modified since the most recent time that it was written to/fetched from the disk&lt;/li&gt;
&lt;li&gt;Once space is allocated in the buffer, the buffer manager reads the block from the disk to the buffer, and passes the address of the block in main memory to requester&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Buffer-Replacement Policies&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most operating systems replace the block least recently used (LRU strategy)&lt;/li&gt;
&lt;li&gt;Idea behind LRU – use past pattern of block references as a predictor of future references. If a block has not been recently used, then it is unlikely that it will be used in the near future&lt;/li&gt;
&lt;li&gt;This replacement policy is also used at different applications. A proxy server keeps in the most recently used web pages in a local cache. If a user requests again a page he has seen, it does not need to be downloaded again in the future&lt;/li&gt;
&lt;li&gt;LRU works well for unpredicted access patterns&lt;/li&gt;
&lt;li&gt;However, queries have well-defined access patterns (such as sequential scans), and a database system can use the information in a user’s query to predict future references&lt;/li&gt;
&lt;li&gt;LRU can be a bad strategy for certain access patterns involving repeated scans of data. Mixed strategy with hints on replacement strategy provided by the query optimizer is preferable&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;file-organization&#34;&gt;File Organization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The database is stored as a collection of files. Each file is a sequence of records. A record is a sequence of fields&lt;/li&gt;
&lt;li&gt;Each record has an address in the file, which is called record pointer or record id (simply rid)&lt;/li&gt;
&lt;li&gt;A simple approach
&lt;ul&gt;
&lt;li&gt;assume record size is fixed&lt;/li&gt;
&lt;li&gt;each file has records of one particular type only&lt;/li&gt;
&lt;li&gt;different files are used for different relations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Organization of Records in Files&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Heap
&lt;ul&gt;
&lt;li&gt;a record can be placed anywhere in the file where there is space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential
&lt;ul&gt;
&lt;li&gt;store records in sequential order, based on the value of the search key of each record&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hashing
&lt;ul&gt;
&lt;li&gt;a hash function computed on some attribute of each record; the result specifies in which block of the file the record should be placed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Records of each relation may be stored in a separate file. In a  clustered file organization  records of several different relations can be stored in the same file
&lt;ul&gt;
&lt;li&gt;Motivation: store related records on the same block to minimize I/O&lt;/li&gt;
&lt;li&gt;However, not good for queries accessing only a few relations&lt;/li&gt;
&lt;li&gt;In general, this representation is barely used&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>比特币数据模型概述</title>
      <link>https://www.pseudoyu.com/zh/2021/01/22/blockchain_note_bitcoin_data/</link>
      <pubDate>Fri, 22 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/22/blockchain_note_bitcoin_data/</guid>
      
        <description>&lt;h2 id=&#34;比特币数据模型概述&#34;&gt;比特币数据模型概述&lt;/h2&gt;
&lt;h3 id=&#34;区块头&#34;&gt;区块头&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;前一个区块的哈希值&lt;/li&gt;
&lt;li&gt;时间戳&lt;/li&gt;
&lt;li&gt;Merkle Root&lt;/li&gt;
&lt;li&gt;Nonce&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;block-body&#34;&gt;Block Body&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction.png&#34; alt=&#34;blockchain_bitcoin_data_transaction&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交易
&lt;ul&gt;
&lt;li&gt;输入
&lt;ul&gt;
&lt;li&gt;UTXO: Unspent outputs from another Transaction
&lt;ul&gt;
&lt;li&gt;必须以整体被花费，不能划分，多余部分转回源账户&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有输入都可以追溯至输出&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;输出&lt;/li&gt;
&lt;li&gt;双重Hash形式
&lt;ul&gt;
&lt;li&gt;SHA256(SHA256(源交易)) = Transhaction Hash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;交易模型&#34;&gt;交易模型&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction_detail.png&#34; alt=&#34;blockchain_bitcoin_data_transaction_detail&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Version&lt;/li&gt;
&lt;li&gt;Input count&lt;/li&gt;
&lt;li&gt;Input info - Unlocking Script
&lt;ul&gt;
&lt;li&gt;Input来源&lt;/li&gt;
&lt;li&gt;核对Input是否可用&lt;/li&gt;
&lt;li&gt;Input info细节
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction_input_info.png&#34; alt=&#34;blockchain_bitcoin_data_transaction_input_info&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Previous output hash&lt;/strong&gt; - 所有输入都能追溯回一个输出(UTXO)，这指向包含将在该输入中花费的UTXO，该UTXO的哈希值在这里以相反的顺序保存&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Previous output index&lt;/strong&gt; - 一个交易可以有多个由它们的索引号引用的UTXO，第一个索引是0&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unlocking Script Size&lt;/strong&gt; - Unlocking Script的字节大小&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unlocking Script&lt;/strong&gt; - 满足UTXO Unlocking Script的哈希&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sequence Number&lt;/strong&gt; - 默认为ffffffff&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Output Count&lt;/li&gt;
&lt;li&gt;Output Info - Locking Script
&lt;ul&gt;
&lt;li&gt;输出了多少比特币&lt;/li&gt;
&lt;li&gt;未来支出的条件&lt;/li&gt;
&lt;li&gt;存储在输出信息中的数据
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_data_transaction_output_info.png&#34; alt=&#34;blockchain_bitcoin_data_transaction_output_info&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Amount&lt;/strong&gt; - 以Satoshis(最小的比特币单位)表示的输出比特币数量，10^8 Satoshis = 1比特币&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locking Script Size&lt;/strong&gt; - 这是Locking Script的字节大小&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locking Script&lt;/strong&gt; - 这是Locking Script的哈希，它指定了使用此输出必须满足的条件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Locktime
&lt;ul&gt;
&lt;li&gt;一个交易可以被最早添加到区块链的时间/块&lt;/li&gt;
&lt;li&gt;如果 &amp;lt;500 million，读取块高度&lt;/li&gt;
&lt;li&gt;如果 &amp;gt;500 million，读取时间戳&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币脚本&#34;&gt;比特币脚本&lt;/h2&gt;
&lt;p&gt;记录在每个交易中的指令列表，当被执行时确定交易是否有效以及比特币是否可以使用&lt;/p&gt;
&lt;h3 id=&#34;脚本&#34;&gt;脚本&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_detail.png&#34; alt=&#34;blockchain_bitcoin_script_detail&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&amp;lt;sig&amp;gt; &amp;lt;pubKey&amp;gt; OP_DUP OP_HASH160 &amp;lt;pubKeyHash&amp;gt; OP_EQUALVERIFY OP_CHECKSIG
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;基于Stack&lt;/li&gt;
&lt;li&gt;存储常数&lt;/li&gt;
&lt;li&gt;使用Opcodes
&lt;ul&gt;
&lt;li&gt;Push (Add)&lt;/li&gt;
&lt;li&gt;Pop (Remove)&lt;/li&gt;
&lt;li&gt;Etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;从左至右执行&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;交易&#34;&gt;交易&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_locking_unlocking.png&#34; alt=&#34;blockchain_bitcoin_script_locking_unlocking&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_relationship.png&#34; alt=&#34;blockchain_bitcoin_script_relationship&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;标准脚本符号&#34;&gt;标准脚本符号&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lt;&amp;gt;包含的是要被推入stack的数据&lt;/li&gt;
&lt;li&gt;没有&amp;lt;&amp;gt;包含，以OP_为前缀的是操作符（OP可省略）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;脚本的特征&#34;&gt;脚本的特征&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;非图灵完备
&lt;ul&gt;
&lt;li&gt;没有循环或者复杂的流程控制&lt;/li&gt;
&lt;li&gt;执行是确定性的&lt;/li&gt;
&lt;li&gt;简单、安全&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;无状态验证
&lt;ul&gt;
&lt;li&gt;脚本执行之前或之后没有保存任何状态&lt;/li&gt;
&lt;li&gt;脚本之间是独立的&lt;/li&gt;
&lt;li&gt;无论脚本在哪里执行，都提供可预测性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;可以嵌入数据&#34;&gt;可以嵌入数据&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_embedding_data.png&#34; alt=&#34;blockchain_bitcoin_script_embedding_data&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Bitcoin Core客户端入门</title>
      <link>https://www.pseudoyu.com/zh/2021/01/19/blockchain_note_bitcoin_core/</link>
      <pubDate>Tue, 19 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/19/blockchain_note_bitcoin_core/</guid>
      
        <description>&lt;h3 id=&#34;bitcoin-core客户端入门&#34;&gt;Bitcoin Core客户端入门&lt;/h3&gt;
&lt;p&gt;比特币的实现&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bitcoin-QT&lt;/li&gt;
&lt;li&gt;Satoshi-client&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;连接至比特币网络&lt;/li&gt;
&lt;li&gt;可验证区块链&lt;/li&gt;
&lt;li&gt;可以发送与接收区块链&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;网络&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mainnet&lt;/li&gt;
&lt;li&gt;Testnet&lt;/li&gt;
&lt;li&gt;Regnet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_core_network.png&#34; alt=&#34;blockchain_bitcoin_core_network&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_core_mainnet_testnet.png&#34; alt=&#34;blockchain_bitcoin_core_mainnet_testnet&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_core_regnet_testnet.png&#34; alt=&#34;blockchain_bitcoin_core_regnet_testnet&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;debug-console&#34;&gt;Debug Console&lt;/h3&gt;
&lt;p&gt;与比特币区块链交互的工具&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blockchain&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getblockchaininfo: 返回有关区块链处理的各种状态信息&lt;/li&gt;
&lt;li&gt;getblockcount: 返回区块链中的块数&lt;/li&gt;
&lt;li&gt;verifychain: 验证区块链数据库&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Hash&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getblockhash: 返回所提供的区块哈希值&lt;/li&gt;
&lt;li&gt;getnetworkhashps: 基于指定数量的最近块，返回每秒网络哈希数&lt;/li&gt;
&lt;li&gt;getbestblockhash: 返回最佳块的哈希值&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Blocks&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getblock: 返回块信息的详细信息&lt;/li&gt;
&lt;li&gt;getblockheader: 返回有关区块头信息&lt;/li&gt;
&lt;li&gt;generate: 立即将指定数量的块挖矿到钱包中的一个地址&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Wallet&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getwalletinfo: 返回一个对象，该对象包含有关钱包状态的各种信息&lt;/li&gt;
&lt;li&gt;listwallets: 返回当前加载的钱包列表&lt;/li&gt;
&lt;li&gt;walletpassphrasechange: 更改钱包密码&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mempool&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getmempoolinfo: 返回内存池活动状态的详细信息&lt;/li&gt;
&lt;li&gt;getrawmempool: 返回内存池中的所有交易详细信息&lt;/li&gt;
&lt;li&gt;getmempoolentry: 返回给定交易的内存池数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Transaction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getchaintxstats: 计算关于链中交易总数和速率的统计数据&lt;/li&gt;
&lt;li&gt;getrawtransaction: 返回原始交易数据&lt;/li&gt;
&lt;li&gt;listtransactions: 返回给定帐户的交易列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Signature&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;signrawtransaction: 签署原始交易的输入&lt;/li&gt;
&lt;li&gt;signmessage: 使用地址的私钥对信息进行签名&lt;/li&gt;
&lt;li&gt;dumpprivkey: 获取私钥&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Network&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getnetworkinfo: 返回P2P网络的状态信息&lt;/li&gt;
&lt;li&gt;getpeerinfo: 返回每个连接网络节点的数据&lt;/li&gt;
&lt;li&gt;getconnectioncount: 返回节点的连接数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Mining&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;getmininginfo: 返回包含挖掘相关信息的对象&lt;/li&gt;
&lt;li&gt;getblocktemplate: 返回构造块所需的数据&lt;/li&gt;
&lt;li&gt;prioritisetransaction: 以较高或较低的优先级接受交易进入挖掘的块&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>比特币基础原理</title>
      <link>https://www.pseudoyu.com/zh/2021/01/15/blockchain_note_bitcoin_basic/</link>
      <pubDate>Fri, 15 Jan 2021 03:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/15/blockchain_note_bitcoin_basic/</guid>
      
        <description>&lt;h2 id=&#34;比特币基础原理&#34;&gt;比特币基础原理&lt;/h2&gt;
&lt;h3 id=&#34;哈希指针-hash-pointers&#34;&gt;哈希指针 Hash Pointers&lt;/h3&gt;
&lt;p&gt;哈希指针指向一个结构体的哈希值（整个区块+其H()一起算出下一个值）&lt;/p&gt;
&lt;p&gt;特征&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tamper-evident log&lt;/li&gt;
&lt;li&gt;如果这个区块被篡改，则会影响后续所有区块，最终导致和本地存储的哈希指针对不上&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;默克尔树-merkle-tree&#34;&gt;默克尔树 Merkle Tree&lt;/h3&gt;
&lt;p&gt;比特币中，每个数据块其实是一种交易transaction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;区块
&lt;ul&gt;
&lt;li&gt;Block header 块头：有根哈希值，没有交易具体内容&lt;/li&gt;
&lt;li&gt;Block body 块身：有交易列表&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Merkle Tree&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;节点类型
&lt;ul&gt;
&lt;li&gt;Full Node 全节点：保存Block header和Block body&lt;/li&gt;
&lt;li&gt;Light Node 轻节点：只保存Block Header，如手机上的比特币钱包&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;只要存放root hash，就能检测出树中任意节点的修改&lt;/li&gt;
&lt;li&gt;Merkle proof：如何向轻节点证明某个交易写入区块链（复杂度为O(logN)，Proof of Membership）&lt;/li&gt;
&lt;li&gt;Proof of non-membership
&lt;ul&gt;
&lt;li&gt;遍历验证，复杂度为O(n)&lt;/li&gt;
&lt;li&gt;可以对叶节点按哈希值大小进行排序，用二分法对相邻的数据块分别向上取哈希值，直到root hash验证，复杂度为O(logN)，称为sorted merkle tree，比特币没有采用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;问题央行如何发行数字货币&#34;&gt;问题：央行如何发行数字货币&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;谁有权力发行&lt;/li&gt;
&lt;li&gt;怎么验证交易有效性，防止双花攻击
&lt;ul&gt;
&lt;li&gt;数字货币交易
&lt;ul&gt;
&lt;li&gt;Input：说明币的来源和支付人的公钥&lt;/li&gt;
&lt;li&gt;Output：说明接收者的公钥Hash（即地址）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;交易信息写进区块链
&lt;ul&gt;
&lt;li&gt;账本的内容需要取得分布式共识（Distributed consensus）&lt;/li&gt;
&lt;li&gt;分布式哈希表，即系统里许多节点共同维护&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FLP Impossibility：在一个异步系统里，网络传输延迟没有上限，哪怕系统中有一个进程失败，无法达成共识&lt;/p&gt;
&lt;p&gt;CAP Theorem，三个要素最多只能同时实现两点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一致性 Consistency&lt;/li&gt;
&lt;li&gt;可用性 Availability&lt;/li&gt;
&lt;li&gt;分区容错性 Partition tolerance&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;比特币共识协议&#34;&gt;比特币共识协议&lt;/h3&gt;
&lt;p&gt;解决系统中有部分节点是恶意的，解决思路为过半数同意，其中谁有投票权&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;风险：Sybil attack 女巫攻击，利用少数节点控制多个虚假身份&lt;/li&gt;
&lt;li&gt;比特币解决方案：工作量证明机制（算力投票机制）
&lt;ul&gt;
&lt;li&gt;全网广播新的数据记录&lt;/li&gt;
&lt;li&gt;全网执行共识算法，即暴力求解数学难题&lt;/li&gt;
&lt;li&gt;率先解出难题的矿工获得记账权，产生新区块&lt;/li&gt;
&lt;li&gt;对外广播新区块，其他节点验证通过后加至主链&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最长合法链
&lt;ul&gt;
&lt;li&gt;分叉攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;同时挖到矿，出现两个等长区块，则会维持一段时间，看哪个区块先被接上&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币系统的实现&#34;&gt;比特币系统的实现&lt;/h2&gt;
&lt;p&gt;基于交易的账本模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UTXO: Unspent Transaction Outputs，未花费交易输出&lt;/li&gt;
&lt;li&gt;比特币系统中，要确认一个地址的余额需要回顾以前所有的交易，并且找到所有给自己的比特币并相加&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;预防双花的机制&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设Alice收了了两笔交易，共计5 BTC（2+3）&lt;/li&gt;
&lt;li&gt;Alice拥有了两笔UTXO，可作为未来转钱给别人的input&lt;/li&gt;
&lt;li&gt;当Alice想要转账给别人，矿工需要验证的是有没有在其他交易在先前的区块中已经使用过这笔Unspent Output&lt;/li&gt;
&lt;li&gt;如果同一笔输出已经被发送过，就不是Unspent了&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;区块链是不可篡改的账本的特性只是概率上的保证，刚写入block的区块是容易篡改的，比特币采用6个confirmation来保障。&lt;/p&gt;
&lt;h2 id=&#34;比特币网络工作原理&#34;&gt;比特币网络工作原理&lt;/h2&gt;
&lt;h3 id=&#34;设计原则&#34;&gt;设计原则&lt;/h3&gt;
&lt;p&gt;simple, robust but not efficient&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用层 - 运行Bitcoin Blockchain&lt;/li&gt;
&lt;li&gt;网络层 - 运行P2P Overlay Network&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;节点工作流程&#34;&gt;节点工作流程&lt;/h3&gt;
&lt;p&gt;每个节点都要维护一个等待上链的交易的集合，一个区块大小为1M，需要几秒才能传到大多数节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;监听到A→B的交易，就将其写入集合&lt;/li&gt;
&lt;li&gt;如果同时有A→C的双花攻击，该节点不会再写入&lt;/li&gt;
&lt;li&gt;如果监听到有同样一笔A→B交易，会将该集合中的该笔交易删除&lt;/li&gt;
&lt;li&gt;如果监听到有一笔A→C的交易（同一个币来源），也会将该集合中A→这笔交易删除&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币挖矿&#34;&gt;比特币挖矿&lt;/h2&gt;
&lt;p&gt;为什么要挖矿&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Block reward 出块奖励：coinbase tx是唯一一个产生新币的途径&lt;/li&gt;
&lt;li&gt;矿工费&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;挖矿：不断尝试nonce值，是Block header里的hash值≤给定的目标阈值&lt;/p&gt;
&lt;p&gt;H(block header) ≤ target （target是难度为1的时候所对应的阈值，target越小，挖矿难度越大）&lt;/p&gt;
&lt;p&gt;difficulty = (difficulty - 1 - target) / target&lt;/p&gt;
&lt;p&gt;挖矿过程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每一次挖矿过程都是随机测试&lt;/li&gt;
&lt;li&gt;每次试nonce构成了无记忆性&lt;/li&gt;
&lt;li&gt;次数很多，但是成功率很低&lt;/li&gt;
&lt;li&gt;出块时间服从指数分布&lt;/li&gt;
&lt;li&gt;从任何一点开始，成功概率不变，所以给予算力成比例优势&lt;/li&gt;
&lt;li&gt;挖矿并不是解数学题，挖矿难度是人为设定的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么要调整难度&#34;&gt;为什么要调整难度&lt;/h3&gt;
&lt;p&gt;出块时间太短容易出现分叉，分叉过多则会影响系统达成共识，危害系统安全性&lt;/p&gt;
&lt;p&gt;BTC的出块速度是10分钟，ETH出块速度是15秒（意味着ETH需要新的协议，ghost → orphan block不能简单丢弃，而是要给奖励，uncle reward）&lt;/p&gt;
&lt;h3 id=&#34;如何调整挖矿难度&#34;&gt;如何调整挖矿难度&lt;/h3&gt;
&lt;p&gt;每2016个区块（约两周）调整一次目标阈值，存在Block header中，有个nbits，是编码的版本&lt;/p&gt;
&lt;p&gt;target = target * (actual time / expected time)&lt;/p&gt;
&lt;p&gt;actual time → 系统中产生2016个区块花费的时间&lt;/p&gt;
&lt;p&gt;expected time → 产生2016个区块预计花费的时间（约14天）&lt;/p&gt;
&lt;p&gt;恶意节点不调整代码中的target的话，诚实的矿工则不会认可&lt;/p&gt;
&lt;p&gt;全节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一直在线&lt;/li&gt;
&lt;li&gt;在本地硬盘上维护完整的区块链信息&lt;/li&gt;
&lt;li&gt;在内存里维护UTXO集合，以便于快速检验交易的正确性&lt;/li&gt;
&lt;li&gt;监听比特币网络上的交易信息，验证每个交易的合法性&lt;/li&gt;
&lt;li&gt;决定哪些交易会被打包到区块里&lt;/li&gt;
&lt;li&gt;监听别的矿工挖出来的区块，验证其合法性&lt;/li&gt;
&lt;li&gt;挖矿
&lt;ul&gt;
&lt;li&gt;决定沿着哪条链挖下去&lt;/li&gt;
&lt;li&gt;当出现等长的分叉时，选择哪一个分叉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;轻节点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不是一直在线&lt;/li&gt;
&lt;li&gt;不用保存整个区块链，只需要保存每个区块的块头&lt;/li&gt;
&lt;li&gt;不用保存全部交易，只需要保存与自己有关的交易&lt;/li&gt;
&lt;li&gt;无法检验大多交易的合法性，只能检验与自己相关的那些交易的合法性&lt;/li&gt;
&lt;li&gt;无法检测网上发布区块的正确性&lt;/li&gt;
&lt;li&gt;可以验证挖矿的难度&lt;/li&gt;
&lt;li&gt;只能检测哪个是最长链，不知道哪个是最长合法链&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;挖矿设备&#34;&gt;挖矿设备&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CPU&lt;/li&gt;
&lt;li&gt;GPU → 主要用于通用并行计算&lt;/li&gt;
&lt;li&gt;ASIC → Application Specific Integrated circuit&lt;/li&gt;
&lt;li&gt;大型矿池
&lt;ul&gt;
&lt;li&gt;Pool Manager：负责全节点要做的事&lt;/li&gt;
&lt;li&gt;Miner：计算hash值，通过POW分配收益&lt;/li&gt;
&lt;li&gt;如矿池达到51%以上算力
&lt;ul&gt;
&lt;li&gt;Forking attack，回滚交易&lt;/li&gt;
&lt;li&gt;Boycott，全网抵制与B有关的任何交易&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币分叉&#34;&gt;比特币分叉&lt;/h2&gt;
&lt;h3 id=&#34;分叉类型&#34;&gt;分叉类型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;state fork
&lt;ul&gt;
&lt;li&gt;forking attack (deliberate fork)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;protocol fork（因为对BTC协议产生分歧而造成的分叉）
&lt;ul&gt;
&lt;li&gt;hard fork
&lt;ul&gt;
&lt;li&gt;例如对block size limit的变化 1M  → 4M&lt;/li&gt;
&lt;li&gt;产生了永久性分叉&lt;/li&gt;
&lt;li&gt;两条链平行发展，各挖各的，互不认可，形成两种币&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;soft fork
&lt;ul&gt;
&lt;li&gt;例如对block size limit的变化 1M  → 0.5M&lt;/li&gt;
&lt;li&gt;新节点挖小区块，即使旧节点挖出了大区块，也会被放弃，再次出现分叉&lt;/li&gt;
&lt;li&gt;旧节点挖大区块&lt;/li&gt;
&lt;li&gt;出现软分叉的情况
&lt;ul&gt;
&lt;li&gt;coinbase内容修改&lt;/li&gt;
&lt;li&gt;P2SH: Pay to Script Hash&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;比特币的匿名性&#34;&gt;比特币的匿名性&lt;/h2&gt;
&lt;h3 id=&#34;破坏匿名性的方法&#34;&gt;破坏匿名性的方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;即使一笔交易生成多个inputs和outputs，这些inputs和outputs的地址也可能被人关联&lt;/li&gt;
&lt;li&gt;地址账户和现实世界中的真实身份也可能产生关联
&lt;ul&gt;
&lt;li&gt;防范比特币洗钱：盯住资金转入转出链&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;提高匿名性的方法&#34;&gt;提高匿名性的方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Application Layer: coin mixing 把各种人混在一起&lt;/li&gt;
&lt;li&gt;Network Layer: 多路径转发以避免从节点的ip地址推算出真实身份&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;零知识证明&#34;&gt;零知识证明&lt;/h3&gt;
&lt;p&gt;一方（证明者）向另一方（验证者）证明一个陈述是正确的，而无需透露除该陈述是正确的以外的人和信息&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同态隐藏
&lt;ul&gt;
&lt;li&gt;给定E(x)和E(y)，可以很容易计算出某些关于x,y的加密函数值（同态运算）
&lt;ul&gt;
&lt;li&gt;Alice把E(x)和E(y)发给Bob&lt;/li&gt;
&lt;li&gt;Bob通过收到的E(x)和E(y)计算出E(x+y)的值&lt;/li&gt;
&lt;li&gt;Bob同时计算E(7)的值，如果E(x+y)和E(7)相等，验证通过&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;盲签
&lt;ul&gt;
&lt;li&gt;用户提供SerialNum（暗文），银行在不知道SerialNum的情况下返回签名Token，减少A的存款&lt;/li&gt;
&lt;li&gt;用户A把SerialNum和Token交给B完成交易&lt;/li&gt;
&lt;li&gt;用户B拿SerialNum和Token给银行验证，银行验证通过，增加B的存款&lt;/li&gt;
&lt;li&gt;银行无法把A和B联系起来&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例如：证明某个比特币账户是我的（不泄露私钥） - 由私钥产生一个签名来证明所有权&lt;/li&gt;
&lt;li&gt;BTC的每一笔转账交易都要说明币的来源&lt;/li&gt;
&lt;li&gt;Zerocoin可以证明花的币是合法存在的，但不知道具体是哪一个&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结思考&#34;&gt;总结思考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;转账交易不需要接收者在线&lt;/li&gt;
&lt;li&gt;私钥丢失则失去对币的所有权，除非存在交易所中，但交易所有风险&lt;/li&gt;
&lt;li&gt;私钥泄漏需要立即将账户中的钱转到另外的账户&lt;/li&gt;
&lt;li&gt;转账时写错地址无法取消交易，也没办法追回&lt;/li&gt;
&lt;li&gt;既然所有要写入区块链的交易都需要被验证正确性，为什么proof of burn中OP_RETURN会被区块接受：
&lt;ul&gt;
&lt;li&gt;对于某个交易，我们需要验证输入脚本和输出脚本，而OP_RETURN是写在当前交易的输出脚本的，因此在本次验证中不会被检查到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在coinbase transaction中有收款人的地址，矿工如果想要偷答案则需要修改地址，会导致merkle tree发生改变，从而改变root hash，block header会发生改变，nonce也作废了&lt;/li&gt;
&lt;li&gt;比特币系统里并没有取得严格意义上的共识，如分叉&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链基本框架</title>
      <link>https://www.pseudoyu.com/zh/2021/01/11/blockchain_note_framework/</link>
      <pubDate>Mon, 11 Jan 2021 08:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/11/blockchain_note_framework/</guid>
      
        <description>&lt;h2 id=&#34;区块链框架&#34;&gt;区块链框架&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;交易&lt;/li&gt;
&lt;li&gt;钱包&lt;/li&gt;
&lt;li&gt;签名&lt;/li&gt;
&lt;li&gt;内存池&lt;/li&gt;
&lt;li&gt;网络&lt;/li&gt;
&lt;li&gt;共识机制&lt;/li&gt;
&lt;li&gt;哈希&lt;/li&gt;
&lt;li&gt;区块&lt;/li&gt;
&lt;li&gt;区块链&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;哈希&#34;&gt;哈希&lt;/h3&gt;
&lt;p&gt;区块链使用的是SHA256(Secure Hashing Algorithm 256 bits)
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_sha256.png&#34; alt=&#34;blockchain_sha256&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;crypto-js/sha256&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;data1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Blockchain Rock!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;dataObject&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;With Object Works too&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;Date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;getTime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;toString&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;slice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;function&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;JSON&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;stringify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;obj&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`SHA256 Hash: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;data1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;************************************&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`SHA256 Hash: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;dataObject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;区块&#34;&gt;区块&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;区块头&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前一个区块的Hash&lt;/li&gt;
&lt;li&gt;时间戳&lt;/li&gt;
&lt;li&gt;Merkle Root&lt;/li&gt;
&lt;li&gt;Nonce
&lt;ul&gt;
&lt;li&gt;Block Data + Nonce = Hash value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;挖矿难度&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;000000HASHVALUE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;区块大小&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1MB (Bitcoin)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;哈希&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;即使数据产生很微小的变化，哈希值也会截然不同，如以下Demo所示&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;crypto-js/sha256&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;kr&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;constructor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;nonce&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;144444&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;body&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hash&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;self&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
        &lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;promise&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;Promise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;resolve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;reject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
          &lt;span class=&#34;nx&#34;&gt;setTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
          &lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hash&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;SHA256&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
            &lt;span class=&#34;nx&#34;&gt;resolve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

          &lt;span class=&#34;nx&#34;&gt;setTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nx&#34;&gt;reject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;SOMETHING WRONG!!!&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;},&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;});&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;promise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;module&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;exports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-javascript&#34; data-lang=&#34;javascript&#34;&gt;&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;BlockClass&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;./block.js&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;kr&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;block&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;BlockClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Block&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Test Block&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;block&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;generateHash&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;then&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`Block Hash: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;hash&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
  &lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`Block: &lt;/span&gt;&lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;JSON&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;stringify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}).&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;catch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;console&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;区块链&#34;&gt;区块链&lt;/h3&gt;
&lt;p&gt;存储网络中所有交易历史记录的账本
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_overview.png&#34; alt=&#34;blockchain_overview&#34;&gt;
&lt;a href=&#34;https://andersbrownworth.com/blockchain/blockchain&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;network&#34;&gt;Network&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;P2P网络：不同用户之间共享信息和资源的一种分布式网络&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分布式网络：分布在不同地域的网络互相连接
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_network.png&#34; alt=&#34;blockchain_network&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;中心化网络：所有人都连接至一个（或一组）中心化网络&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;去中心化网络：没有一个单点网络可以拥有所有的信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分布式网络：每个人都得到一份信息备份，且都拥有访问权限&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;内存池&#34;&gt;内存池&lt;/h3&gt;
&lt;p&gt;交易脱离内存池的原因&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;交易过期（14天）&lt;/li&gt;
&lt;li&gt;在以交易费排序的结构中交易处于内存池底部&lt;/li&gt;
&lt;li&gt;交易已经被一个区块包含&lt;/li&gt;
&lt;li&gt;交易有未确认的祖先区块被区块包含&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;共识机制&#34;&gt;共识机制&lt;/h3&gt;
&lt;p&gt;网络如何对交易达成信任/一致&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PoW(Proof of Work)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算消耗大（算力），但是很容易检验正确性&lt;/li&gt;
&lt;li&gt;比特币网络
&lt;ul&gt;
&lt;li&gt;10分钟左右（6个确认）&lt;/li&gt;
&lt;li&gt;动态调整难度&lt;/li&gt;
&lt;li&gt;消耗大量能源&lt;/li&gt;
&lt;li&gt;如果矿工（矿池）拥有大量资源则有中心化风险&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;PoS (Proof of Stake)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过与系统相关的用户（权益持有者）投票来达成共识&lt;/li&gt;
&lt;li&gt;Nothing at Stake问题：在所有区块都投注
&lt;ul&gt;
&lt;li&gt;同时在多个链上创建区块的用户会遭到惩罚&lt;/li&gt;
&lt;li&gt;在错误链上创建区块的用户会遭到惩罚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以太坊正在向PoS转变&lt;/li&gt;
&lt;li&gt;DASH&lt;/li&gt;
&lt;li&gt;LISK
&lt;ul&gt;
&lt;li&gt;DPoS (Delegated Proof of Stake)委任权益证明&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DBFT (Delegated Byzantine Fault Tolerance)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过对节点分配不同的角色来达成共识&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;降低开销&lt;/li&gt;
&lt;li&gt;避免分叉&lt;/li&gt;
&lt;li&gt;问题
&lt;ul&gt;
&lt;li&gt;不诚实的发言者&lt;/li&gt;
&lt;li&gt;不诚实的委任者&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;钱包&#34;&gt;钱包&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;私钥&lt;/li&gt;
&lt;li&gt;公钥&lt;/li&gt;
&lt;li&gt;钱包地址&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;ECDSA (One-way Elliptic Curve Digital Signature Algorithm)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过私钥生成公钥&lt;/li&gt;
&lt;li&gt;单向，不能逆推&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;生成钱包地址&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过SHA256和RIPEMD160来生成钱包地址&lt;/li&gt;
&lt;li&gt;通过Base58Check来保障其可读性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;流程&lt;/strong&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_generate1.png&#34; alt=&#34;blockchain_wallet_generate1&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_generate2.png&#34; alt=&#34;blockchain_wallet_generate2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;钱包类型&lt;/strong&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_type.png&#34; alt=&#34;blockchain_wallet_type&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non-Deterministic Wallet&lt;/li&gt;
&lt;li&gt;Deterministic Wallet
&lt;ul&gt;
&lt;li&gt;Sequential Deterministic Wallet&lt;/li&gt;
&lt;li&gt;Hierarchical Deterministic (HD) Wallet
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_wallet_hd.png&#34; alt=&#34;blockchain_wallet_hd&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;私钥&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个256位随机数，介于1和2^256之间&lt;/li&gt;
&lt;li&gt;格式
&lt;ul&gt;
&lt;li&gt;Hex&lt;/li&gt;
&lt;li&gt;WIF(Base58Check)&lt;/li&gt;
&lt;li&gt;WIF-Compressed(Base58Check added suffix 0x01 before encoding)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Entropy 熵&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;混乱与不可预测状态&lt;/li&gt;
&lt;li&gt;应用
&lt;ul&gt;
&lt;li&gt;Python: Random&lt;/li&gt;
&lt;li&gt;Java: SecureRandom&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;签名&#34;&gt;签名&lt;/h3&gt;
&lt;p&gt;为区块链上每笔交易提供证明&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;私钥签名&lt;/li&gt;
&lt;li&gt;公钥验证&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;交易周期&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Inputs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Outputs
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_transaction_lifecycle.png&#34; alt=&#34;blockchain_transaction_lifecycle&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;UTXO (Unspent transaction output in bitcoin)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;广播到区块链&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链基础原理</title>
      <link>https://www.pseudoyu.com/zh/2021/01/07/blockchain_note_concept/</link>
      <pubDate>Thu, 07 Jan 2021 05:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/07/blockchain_note_concept/</guid>
      
        <description>&lt;h2 id=&#34;区块链基础原理&#34;&gt;区块链基础原理&lt;/h2&gt;
&lt;p&gt;区块链是一种分布式账本技术，由于是一群人来记账，所以修改这个账本的难度比较高。&lt;/p&gt;
&lt;p&gt;单式记账 → 复式记账 → 数字化记账 → 分布式记账&lt;/p&gt;
&lt;p&gt;传统中心化数字记账依赖于某个组织的可信度，而区块链是通过共识机制来共同记账，由区块链技术来保障信任机制，具有去中心化、难以篡改、可追溯等特点。&lt;/p&gt;
&lt;p&gt;难以篡改是区块链主要特征，相比传统数据库（传统数据库包含了增删改查），区块链只有增加和查询，是一种“历史记录不可篡改的数据库”。&lt;/p&gt;
&lt;h3 id=&#34;传统数据库-vs-区块链数据库&#34;&gt;传统数据库 vs. 区块链数据库&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;传统数据库&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网络
&lt;ul&gt;
&lt;li&gt;中心化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;功能
&lt;ul&gt;
&lt;li&gt;Create 创建&lt;/li&gt;
&lt;li&gt;Read 读取&lt;/li&gt;
&lt;li&gt;Update 更新&lt;/li&gt;
&lt;li&gt;Delete 删除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可变性
&lt;ul&gt;
&lt;li&gt;可变&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;权限
&lt;ul&gt;
&lt;li&gt;中心化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透明度
&lt;ul&gt;
&lt;li&gt;低&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;区块链数据库&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网络
&lt;ul&gt;
&lt;li&gt;去中心化
&lt;ul&gt;
&lt;li&gt;给予节点控制权&lt;/li&gt;
&lt;li&gt;必须达成共识&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;功能
&lt;ul&gt;
&lt;li&gt;Read，Append，Validate
&lt;ul&gt;
&lt;li&gt;具有准确的历史记录&lt;/li&gt;
&lt;li&gt;读取和写入更快&lt;/li&gt;
&lt;li&gt;必须达成共识&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可变性
&lt;ul&gt;
&lt;li&gt;不可变
&lt;ul&gt;
&lt;li&gt;永久保存历史记录&lt;/li&gt;
&lt;li&gt;占据较大存储空间&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;权限
&lt;ul&gt;
&lt;li&gt;分布式
&lt;ul&gt;
&lt;li&gt;安全性高&lt;/li&gt;
&lt;li&gt;不能撤回交易&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透明度
&lt;ul&gt;
&lt;li&gt;高
&lt;ul&gt;
&lt;li&gt;每个人都能看到&lt;/li&gt;
&lt;li&gt;没有权限控制机制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;是否需要区块链&#34;&gt;是否需要区块链&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;是否需要数据库？&lt;/li&gt;
&lt;li&gt;是否需要共享写入权限？&lt;/li&gt;
&lt;li&gt;是否需要多方达成信任？&lt;/li&gt;
&lt;li&gt;能否脱离第三方机构运作？&lt;/li&gt;
&lt;li&gt;能否脱离权限控制机制运作？&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;适合区块链的应用场景&#34;&gt;适合区块链的应用场景&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;需要建立一个共享数据库，且有多方参与&lt;/li&gt;
&lt;li&gt;参与业务的各方没有建立起信任&lt;/li&gt;
&lt;li&gt;现有业务中信任一个或多个信任机构&lt;/li&gt;
&lt;li&gt;现有业务中有加密认证的业务需求&lt;/li&gt;
&lt;li&gt;数据需要集成到不同数据库且业务数字化和一致性的需求迫切&lt;/li&gt;
&lt;li&gt;对于系统参与者有统一的规则&lt;/li&gt;
&lt;li&gt;多方决策是透明的&lt;/li&gt;
&lt;li&gt;需要客观、不可改变的记录&lt;/li&gt;
&lt;li&gt;非实时性处理业务&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果以下条件则不适合采用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据无法公开&lt;/li&gt;
&lt;li&gt;数据很大&lt;/li&gt;
&lt;li&gt;业务规则经常变化&lt;/li&gt;
&lt;li&gt;需要外部服务来收集、存储数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;区块链类型&#34;&gt;区块链类型&lt;/h3&gt;
&lt;p&gt;区块链分为&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公链：交易是否要公开&lt;/li&gt;
&lt;li&gt;私链：是否需要其他公司（机构）访问数据&lt;/li&gt;
&lt;li&gt;联盟链：权限控制&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;越靠近公有链则对节点的认证和权限管理要求越少、去中心化程度越高&lt;/p&gt;
&lt;p&gt;公有链主流共识机制有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;工作量证明 PoW&lt;/li&gt;
&lt;li&gt;权益证明 PoS&lt;/li&gt;
&lt;li&gt;委任权益证明 DPoS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;共识机制核心是记账权的争夺，公链的设计思路是让恶意节点的攻击成本远远大于诚实节点的受益。一般采取拜占庭容错机制，解决了节点故障和节点作恶的情况下还是能达成共识。&lt;/p&gt;
&lt;h4 id=&#34;公链&#34;&gt;公链&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;比特币：第一个成功的去中心化数字货币系统&lt;/li&gt;
&lt;li&gt;以太坊：可编程、可运算的智能合约&lt;/li&gt;
&lt;li&gt;EOS：超越货币、经济的去中心话应用操作系统&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;联盟链&#34;&gt;联盟链&lt;/h4&gt;
&lt;p&gt;联盟链节点需要经过认证才能参与到区块链网络，交易速度更快、拓展性更高、并能很好地保护交易隐私。联盟链因为节点数有限且需要认证，为了提升效率，弱化了节点作恶，重点考虑1/3节点故障下系统共识机制的达成，且一般不需要代币作为激励机制，而是每个部门作为记账节点，实现跨部门之间的业务协同给大家带来经济效益。&lt;/p&gt;
&lt;p&gt;联盟链的代表是Hyperledger，这是首个面向企业应用场景的开源分布式账本平台，而Hyperledger Fabric是其中发展的最好的子项目。&lt;/p&gt;
&lt;p&gt;Hyperledger Fabric定位是面向企业的分布式账本平台，引入了权限管理机制，设计上支持可插拔、可拓展，具备良好的设计架构、完善的文档、清晰的代码。&lt;/p&gt;
&lt;h4 id=&#34;私有链&#34;&gt;私有链&lt;/h4&gt;
&lt;p&gt;而私有链是在某一领域、某一企业运行的区块链，一般用于解决部门间的信任问题。&lt;/p&gt;
&lt;h4 id=&#34;应用场景&#34;&gt;应用场景&lt;/h4&gt;
&lt;p&gt;长期来看，公有链和联盟链在技术上会趋于融合，界限也会越来越模糊，一般将需要信任的数据放在公有链上，而一些行业数据、私有数据放在联盟链上。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
