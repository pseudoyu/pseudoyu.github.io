<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:webfeeds="http://webfeeds.org/rss/1.0">
  <channel>
    <title>Pseudoyu</title>
    <link>https://www.pseudoyu.com/zh/</link>
    <description>Recent content on Pseudoyu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 10 May 2021 19:30:25 +0800</lastBuildDate>
    
    <atom:link href="https://www.pseudoyu.com/zh/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>关于</title>
      <link>https://www.pseudoyu.com/zh/about/</link>
      <pubDate>Thu, 04 Mar 2021 16:03:46 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/about/</guid>
      
        <description>&lt;h2 id=&#34;hi我是-yu-zhanghttpswwwpseudoyucom&#34;&gt;Hi，我是 &lt;a href=&#34;https://www.pseudoyu.com&#34;&gt;Yu Zhang&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;在香港大学计算机系读研，正在学习区块链，空闲也折腾Notion等效率工具，欢迎交流。&lt;/p&gt;
&lt;p&gt;希望不断学习，不断成长。现阶段的目标是能够在忙碌的闲隙里不断思考，多阅读写作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/dino.gif&#34; alt=&#34;picture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;个人希望&#34;&gt;个人希望&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;生活方面&lt;/strong&gt;&lt;/em&gt;，希望能够和现在的挚友一直相互支持走下去，和家人保持现在这样亦亲亦友的关系，和在意的人一起面对人生的挑战，同时也能认识更多有趣的人。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;专业方面&lt;/strong&gt;&lt;/em&gt;，希望一直有所进步，能够在开源世界留下一些痕迹。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;经济方面&lt;/strong&gt;&lt;/em&gt;，希望能自主无虞，足够支撑做自己想做的事，探索更多元的未来生活。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;社会方面&lt;/strong&gt;&lt;/em&gt;，希望有机会做参与一些公益活动或其他形式的善举，为世界带来一些微小的改变。&lt;/p&gt;
&lt;h2 id=&#34;关于网站&#34;&gt;关于网站&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; 是我的第一个网站，主要用来记录生活、学习与零碎的一些想法。最早基于WordPress并放在自己的个人服务器上，后又迁移至同名微信公众号，最后出于稳定性和自由度考虑还是决定用Hugo生成自己的静态网页，托管于GitHub并绑定 &lt;a href=&#34;https://www.pseudoyu.com/zh/&#34;&gt;pseudoyu.com&lt;/a&gt; 域名。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; 的命名很巧合，在HKU入学注册时因为自己名字过于常见而很难抉择使用什么uid，后取用了一个前缀「&lt;a href=&#34;https://www.oxfordlearnersdictionaries.com/definition/english/pseudo&#34;&gt;pseudo&lt;/a&gt;」，&lt;a href=&#34;https://www.oxfordlearnersdictionaries.com/definition/english/pseudonym&#34;&gt;pseudonym&lt;/a&gt; 有「笔名、假名」的含义，编程里常用到的 &lt;a href=&#34;https://www.lexico.com/definition/pseudocode&#34;&gt;pseudocode&lt;/a&gt; 是「伪码」的含义，而很喜欢的日漫 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%81%BD%E7%89%A9%E8%AA%9E&#34;&gt;&lt;em&gt;物语系列 - 伪物语&lt;/em&gt;&lt;/a&gt; 中也不乏对「真物」与「伪物」的探究，那为什么不能有一个 pseudo 的 yu（我）呢？&lt;/p&gt;
&lt;p&gt;我常辗转于自我怀疑之中，在与挚友聊天时谈及「初心」或是「意义」时总是选择逃避，即使取得一些世俗的小成就也很难从心底感受到喜悦或满足，总觉得一切都如同「伪物」一样毫无意义。而随着年岁与经历的增长，我在另一篇文章 &lt;a href=&#34;https://www.pseudoyu.com/zh/2020/06/06/23%E5%B2%81%E7%9A%84%E8%87%AA%E7%99%BD%E5%8E%BB%E8%BF%BD%E5%AF%BB%E6%84%8F%E4%B9%89/&#34;&gt;&lt;em&gt;23岁的自白：去追寻意义&lt;/em&gt;&lt;/a&gt; 中写道，「&lt;em&gt;也许思考本身就是建构意义的过程，让我不再期待某个瞬间能够顿悟，只是希望继续向前，体验和追寻着自己的人生.&lt;/em&gt;」&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pseudoyu&lt;/strong&gt; 这个名字也是寓意自己不应该再时常纠结意义，而是要不断去学习、体验与挑战新的事物，即使被评价「变了」、「不像自己」也能欣然接受。&lt;/p&gt;
&lt;p&gt;希望自己能多输入一些新的知识和想法，多写一些小文章。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>Uright - 区块链音乐版权管理ÐApp</title>
      <link>https://www.pseudoyu.com/zh/2021/05/10/uright_case_study/</link>
      <pubDate>Mon, 10 May 2021 19:30:25 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/05/10/uright_case_study/</guid>
      
        <description>&lt;h1 id=&#34;uright---区块链音乐版权管理ðapp&#34;&gt;Uright - 区块链音乐版权管理ÐApp&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_chain.png&#34; alt=&#34;uright_chain&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;基于Angular+Solidity+Web3.js，应用IPFS、ENS、Oracles等技术，通过Truffle部署于Ethereum的音乐版权管理Decentralized Application (ÐApp)。&lt;/p&gt;
&lt;p&gt;Uright去中心化应用允许音乐人（内容所有者）将他们的作品注册为&amp;quot;Manifestations&amp;quot;并登记至以太坊区块链。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Manifestations&amp;quot;将音乐人的作品展现为内容片段，用以证明作者身份及所有权。这是通过&amp;quot;Manifestations&amp;quot;智能合约完成的，该智能合约记录显示作品内容的IPFS哈希、标题(计划附加元数据)以及注册时间，这些信息可以用来证明作者身份，并且内容可以从IPFS文件存储系统中检索到。&lt;/p&gt;
&lt;p&gt;然而，仅仅注册一个&amp;quot;Manifestations&amp;quot;是不够的，还应提供支撑材料，否则该&amp;quot;Manifestations&amp;quot;将于一天后失效。这些支持材料通常由音乐人（作品上传者）注册，但任何其他人都可以添加支撑材料，支撑材料可以是任何类型的文件，如截图、PDF文档等。&amp;ldquo;UploadEvidences&amp;quot;智能合约会将支撑材料上传至IPFS文件系统。&lt;/p&gt;
&lt;p&gt;此外，&amp;ldquo;YouTubeEvidences&amp;quot;智能合约允许音乐人在YouTube等视频/音乐平台的上传简介中声明作品&amp;quot;Manifestations&amp;rdquo;，智能合约将自动检测作为支撑材料。&lt;/p&gt;
&lt;p&gt;（开发中&amp;hellip;）如果有其他人已经注册了音乐人的原创作品/支持材料，音乐人可以进行申诉，合约功能已实现，但在Web应用尚不可用。&lt;/p&gt;
&lt;p&gt;（开发中&amp;hellip;）通过NFT技术对音乐人作品进行代币化。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&#34;https://github.com/pseudoyu/Uright&#34;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;架构&#34;&gt;架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_architecture.png&#34; alt=&#34;uright_architecture&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;核心技术&#34;&gt;核心技术&lt;/h3&gt;
&lt;h4 id=&#34;ipfs&#34;&gt;IPFS&lt;/h4&gt;
&lt;p&gt;当音乐人使用数字文件（如.mp3格式文件）注册自己的作品时，文件将被上传至IPFS且其生成的IPFS标识符(哈希值)用于在Ethereum区块链中注册作品。用户可以选择将作品上传至IPFS网络，也可以保持作品的私密性，设置将内容不上传至IPFS网络，而只生成作品哈希值。&lt;/p&gt;
&lt;p&gt;用户需要保留与生成作品哈希时使用的完全相同的文件，可在以后用作拥有数字文件的证据，以便于哈希检验。IPFS哈希值也将用于检索上传的内容。&lt;/p&gt;
&lt;h4 id=&#34;ethereum-naming-system-ens&#34;&gt;Ethereum Naming System (ENS)&lt;/h4&gt;
&lt;p&gt;Uright项目集成了ethereum-ens包，可作用于以太坊主网、Ropsten、Rinkeby测试网及本地测试网。ensdomains/ens包用于设置地址名称。&lt;/p&gt;
&lt;h4 id=&#34;oracles&#34;&gt;Oracles&lt;/h4&gt;
&lt;p&gt;Oracle模块集成在上传YouTube证据的智能合约，通过YouTube的视频ID (&lt;a href=&#34;https://www.youtube.com/watch?v=VIDEO_ID&#34;&gt;https://www.youtube.com/watch?v=VIDEO_ID&lt;/a&gt;) 来检索该视频描述中是否含有特定作品哈希。&lt;/p&gt;
&lt;p&gt;因此，该功能允许音乐人证明该作品同时存在于YouTube平台并属于自己（因为仅上传者可以编辑视频描述，使其包含作品哈希值）&lt;/p&gt;
&lt;p&gt;可使用Oraclize提供的在线服务进行查询: &lt;a href=&#34;http://app.oraclize.it/home/test_query&#34;&gt;http://app.oraclize.it/home/test_query&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;可升级性&#34;&gt;可升级性&lt;/h4&gt;
&lt;p&gt;为了使作品注册合约具备可升级性，引入ZeppelinOS中的AdminUpgradeabilityProxy，通过中继代理的方式实现了委任模式。&lt;/p&gt;
&lt;h3 id=&#34;设计模式&#34;&gt;设计模式&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_design_architecture.png&#34; alt=&#34;uright_design_architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;Uright项目智能合约的设计有利于模块化和可重用性。比如，将验证过期功能实现为一个实体库；以及&amp;quot;Evidencable&amp;quot;库使注册作品可累积多项支持材料，也可以在后续申诉功能等研发中提供便利。&lt;/p&gt;
&lt;p&gt;此外，将这些功能作为库提供可以降低部署成本。&lt;/p&gt;
&lt;h4 id=&#34;circuit-breaker-断路器模式--emergency-stop&#34;&gt;Circuit Breaker (断路器模式) / Emergency Stop&lt;/h4&gt;
&lt;p&gt;断路器的模式可以防止一个应用程序反复尝试执行一个可能会失败的操作，让它继续不等待故障的纠正或浪费处理器周期，而它决定了故障是长期持久的。断路器的模式也使一个应用程序来检测故障是否已得到解决。如果出现问题，该应用程序可以尝试调用操作。&lt;/p&gt;
&lt;h4 id=&#34;automatic-deprecation&#34;&gt;Automatic Deprecation&lt;/h4&gt;
&lt;p&gt;此外，对已登记的作品实行了类似于&amp;quot;Automatic Deprecation&amp;quot;的模式。这样，如果一个
用户注册了作品但不提供支持材料，其注册将在设定的固定时间后过期，在这种情况下，过期意味着该作品可以被另一个用户重新注册覆盖。&lt;/p&gt;
&lt;h3 id=&#34;安全措施&#34;&gt;安全措施&lt;/h3&gt;
&lt;p&gt;所有智能合约都已使用Remix和Solhint工具进行了代码检查，通过这两种工具检查常见的安全问题，如可重入性或时间戳依赖性等。&lt;/p&gt;
&lt;p&gt;SafeMath库用于避免整数上溢和下溢问题。&lt;/p&gt;
&lt;p&gt;最后，Solhint被设置为定义的连续集成和部署工作流中的一个步骤，这样，每次代码被推送到GitHub时，travis都会运行所有的测试(对于合同和Angular前端)，如果所有测试都通过，则负责部署。&lt;/p&gt;
&lt;p&gt;此外，Solhint工具也会在测试之前执行，用于跟踪任何可能出现的安全问题。&lt;/p&gt;
&lt;h3 id=&#34;相关库&#34;&gt;相关库&lt;/h3&gt;
&lt;p&gt;Uright项目从ZeppelinOS和OpenZeppelin包中导入了一些库用于功能实现&lt;/p&gt;
&lt;h4 id=&#34;zeppelinos&#34;&gt;ZeppelinOS&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;AdminUpgradeabilityProxy: 实现智能合约的可升级性&lt;/li&gt;
&lt;li&gt;Initializable: 通过可升级的智能合约拓展实现代理的初始化&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;openzeppelin&#34;&gt;OpenZeppelin&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Pausable: 实现&amp;quot;Circuit Breaker (断路器模式) / Emergency Stop&amp;quot;设计模式，通过拓展Ownable以实现只有拥有者可以停止&lt;/li&gt;
&lt;li&gt;SafeMath: 用于避免整数上溢和下溢问题&lt;/li&gt;
&lt;li&gt;OraclizeAPI包，usingOraclize，用于检验YouTube视频是否属于特定用户且绑定至版权作品&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;智能合约详解&#34;&gt;智能合约详解&lt;/h3&gt;
&lt;h4 id=&#34;manifestationssol&#34;&gt;Manifestations.sol&lt;/h4&gt;
&lt;p&gt;此智能合约用于注册作品，通过将作品元数据（目前为标题）及内容的IPFS 哈希值与作者身份（即以太坊账户地址）进行关联，以证明作品所有权，同一作品可声明为单人作者或联合作者。此外，如用一个已经注册的内容哈希重新注册新作品，系统会检测为失败。&lt;/p&gt;
&lt;h4 id=&#34;uploadevidencessol&#34;&gt;UploadEvidences.sol&lt;/h4&gt;
&lt;p&gt;此智能合约主要用于支持材料登记，通过将作品文件内容上传至IPFS文件系统进行证据登记。对于同一个作品，可以添加多个证据（但不能重复添加）。&lt;/p&gt;
&lt;h4 id=&#34;expirablelibsol&#34;&gt;ExpirableLib.sol&lt;/h4&gt;
&lt;p&gt;此智能合约主要用于管理作品创建和到期时间的项目逻辑，实现作品注册（或申诉）的时效性。&lt;/p&gt;
&lt;h3 id=&#34;功能&#34;&gt;功能&lt;/h3&gt;
&lt;p&gt;Uright ÐApp通过Web客户端对音乐人和用户提供音乐版权管理服务&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;版权注册：以作品文件生成唯一哈希值，将音乐人的作品注册上链，以此证明作品版权&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_register.png&#34; alt=&#34;uright_register&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注册从未注册的新作品&lt;/li&gt;
&lt;li&gt;注册已存在注册记录的作品并进行申诉&lt;/li&gt;
&lt;li&gt;添加支撑材料来证明作品版权&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_evidence_upload.png&#34; alt=&#34;uright_evidence_upload&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_youtube_evidence.png&#34; alt=&#34;uright_youtube_evidence&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;版权检索：通过哈希值检查一个作品是否已被注册&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_music_search.png&#34; alt=&#34;uright_music_search&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我的：查找当前音乐人的所有注册作品&lt;/li&gt;
&lt;li&gt;版权库：查找链上所有已注册作品&lt;/li&gt;
&lt;li&gt;详细信息：单击“详细信息”查看详细信息，包括所有已上传证据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/uright_music_library.png&#34; alt=&#34;uright_music_library&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>BlockchainGuide - 区块链核心知识库</title>
      <link>https://www.pseudoyu.com/zh/2021/04/03/blockchain_guide/</link>
      <pubDate>Sat, 03 Apr 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/04/03/blockchain_guide/</guid>
      
        <description>&lt;h1 id=&#34;blockchainguide&#34;&gt;BlockchainGuide&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;一个不断更新的区块链核心知识库&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pseudoyu/BlockchainGuide&#34;&gt;源项目地址&lt;/a&gt; | &lt;a href=&#34;https://www.pseudoyu.com/BlockchainGuide/&#34;&gt;在线阅读&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目录&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#blockchainguide&#34;&gt;BlockchainGuide&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86&#34;&gt;基础知识&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%8C%BA%E5%9D%97%E9%93%BE%E5%9F%BA%E7%A1%80&#34;&gt;区块链基础&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E6%AF%94%E7%89%B9%E5%B8%81&#34;&gt;比特币&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E4%BB%A5%E5%A4%AA%E5%9D%8A&#34;&gt;以太坊&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hyperledger-fabric&#34;&gt;Hyperledger Fabric&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E7%83%AD%E9%97%A8%E6%8A%80%E6%9C%AF&#34;&gt;热门技术&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ipfs&#34;&gt;IPFS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98&#34;&gt;开发实战&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80&#34;&gt;编程语言&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7&#34;&gt;开发工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE&#34;&gt;个人项目&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%85%B6%E4%BB%96&#34;&gt;其他&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#%E5%85%B3%E4%BA%8E%E6%88%91&#34;&gt;关于我&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;基础知识&#34;&gt;基础知识&lt;/h2&gt;
&lt;h3 id=&#34;区块链基础&#34;&gt;区块链基础&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/02/12/blockchain_basic/&#34;&gt;区块链基础知识与关键技术&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;比特币&#34;&gt;比特币&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/02/17/blockchain_bitcoin_basic/&#34;&gt;比特币核心技术解读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bitcoin.org/en/&#34;&gt;官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bitcoin.org/bitcoin.pdf&#34;&gt;白皮书&lt;/a&gt; (&lt;a href=&#34;https://bitcoin.org/files/bitcoin-paper/bitcoin_zh_cn.pdf&#34;&gt;中译&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bitcoin/bitcoin&#34;&gt;源码&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;以太坊&#34;&gt;以太坊&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/02/20/blockchain_ethereum_basic/&#34;&gt;Ethereum核心技术解读&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ethereum.org/en/&#34;&gt;官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ethereum.org/en/whitepaper/&#34;&gt;白皮书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ethereum.org/en/developers/docs/&#34;&gt;文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ethereum/go-ethereum&#34;&gt;源码&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;hyperledger-fabric&#34;&gt;Hyperledger Fabric&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/20/blockchain_hyperledger_fabric_structure/&#34;&gt;Hyperledger Fabric系统架构详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/23/blockchain_hyperledger_fabric_network/&#34;&gt;Hyperledger Fabric网络与安全体系浅析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.hyperledger.org/use/fabric&#34;&gt;官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hyperledger-fabric.readthedocs.io/en/release-2.2/&#34;&gt;文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hyperledger/fabric#releases&#34;&gt;源码&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;热门技术&#34;&gt;热门技术&lt;/h2&gt;
&lt;h3 id=&#34;ipfs&#34;&gt;IPFS&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/25/blockchain_ipfs_structure/&#34;&gt;IPFS分布式存储协议分析与思考&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/27/blockchain_ipfs_practice/&#34;&gt;IPFS本地节点搭建（命令行）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ipfs.io&#34;&gt;官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ipfs.io/ipfs/QmR7GSQM93Cx5eAg6a6yRzNde1FQv7uL6X1o4k7zrJa3LX/ipfs.draft3.pdf&#34;&gt;白皮书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.ipfs.io&#34;&gt;文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ipfs/ipfs&#34;&gt;源码&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;开发实战&#34;&gt;开发实战&lt;/h2&gt;
&lt;h3 id=&#34;编程语言&#34;&gt;编程语言&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.soliditylang.org/en/v0.8.4/&#34;&gt;Solidity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://golang.org&#34;&gt;Go&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;开发工具&#34;&gt;开发工具&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://metamask.io/&#34;&gt;MetaMask&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.trufflesuite.com&#34;&gt;Truffle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web3js.readthedocs.io/en/v1.3.4/&#34;&gt;Web3.js&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openzeppelin.com&#34;&gt;OpenZeppelin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://infura.io&#34;&gt;Infura&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;个人项目&#34;&gt;个人项目&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Uright (&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/05/10/uright_case_study/&#34;&gt;文档&lt;/a&gt; | &lt;a href=&#34;https://github.com/pseudoyu/Uright&#34;&gt;GitHub&lt;/a&gt;) - 一款基于以太坊区块链的音乐版权管理应用（ÐApp）&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;
&lt;h3 id=&#34;关于我&#34;&gt;关于我&lt;/h3&gt;
&lt;p&gt;个人网站：&lt;a href=&#34;https://www.pseudoyu.com&#34;&gt;Pseudoyu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;个人公众号：&amp;quot;&lt;strong&gt;Pseudoyu&lt;/strong&gt;&amp;quot;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>MySQL基础知识与相关操作</title>
      <link>https://www.pseudoyu.com/zh/2021/03/29/database_mysql_basic/</link>
      <pubDate>Mon, 29 Mar 2021 00:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/29/database_mysql_basic/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;数据库不论在基础知识学习还是真实企业业务场景中都很常用，也有很多调侃说日常工作总是离不开CRUD，熟练主流关系型与数据库的使用是一个开发者基本的操作。本文将在MacOS系统下对MySQL这个流行的关系性数据库的基础知识与相关操作进行整理，以便于查阅。&lt;/p&gt;
&lt;h2 id=&#34;数据与数据库概述&#34;&gt;数据与数据库概述&lt;/h2&gt;
&lt;h3 id=&#34;数据&#34;&gt;数据&lt;/h3&gt;
&lt;p&gt;首先，数据其实本质上是一种事实或者观察到的结果，是对客观事务的逻辑上的归纳总结，是信息的一种表现形式和载体。人们从很早的时候就开始管理数据（即使还没有这个概念），最初是由人工管理，而后来渐渐有了文件系统（就像图书馆一样，分门别类地管理不同信息），而随着计算机技术的发展，最后形成了用数据库进行管理的这种较为便捷高效的模式。&lt;/p&gt;
&lt;h3 id=&#34;数据库&#34;&gt;数据库&lt;/h3&gt;
&lt;p&gt;数据库是按照一定的数据结构来组织、存储和管理数据的一个仓库，主要特征为&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结构化&lt;/li&gt;
&lt;li&gt;可共享&lt;/li&gt;
&lt;li&gt;冗余度小&lt;/li&gt;
&lt;li&gt;独立性高&lt;/li&gt;
&lt;li&gt;易于拓展&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很好理解的是，按照不同关系/结构组织起来的数据具备不同的特征，同时也适用于不同的应用场景，目前主要分为层次数据库、网状数据库和关系数据库三种，而我们要着重介绍的MySQL就数据关系数据库。&lt;/p&gt;
&lt;h3 id=&#34;数据库管理系统dbms&#34;&gt;数据库管理系统(DBMS)&lt;/h3&gt;
&lt;p&gt;数据库管理系统(DBMS)是对数据库进行各种操作的一个系统，一具有建立和维护数据库、对数据的存储进行组织管理、对数据库进行控制、定义数据、操纵数据以及管理数据之间的通信等核心功能，不同的数据库管理系统对数据库和数据的处理方式不同，数据呈现方式也不同，也往往需要根据数据规模、业务需求等场景选择合适的数据库管理系统，如在海量数据和高并发数据读写的情况下，关系性数据库的性能会下降得很厉害。&lt;/p&gt;
&lt;h2 id=&#34;关系性数据库rdbms&#34;&gt;关系性数据库(RDBMS)&lt;/h2&gt;
&lt;h3 id=&#34;主要特征&#34;&gt;主要特征&lt;/h3&gt;
&lt;p&gt;关系性数据库主要以数据表的形式呈现，每一行为一条记录，每一列则为记录名称所对应的数据域(Field)。许多行列组成一张单表，而若干单表则组成数据库。用户/系统通过SQL(结构化查询语言对数据库进行查询。&lt;/p&gt;
&lt;p&gt;有些关系型数据库的操作具有事务性，即ACID规则&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原子性(Atomicity)&lt;/li&gt;
&lt;li&gt;一致性(Consistency)&lt;/li&gt;
&lt;li&gt;隔离性(Isolation)&lt;/li&gt;
&lt;li&gt;持久性(Durability)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原子性是指一系列事务操作要么都完成，要么都失败，不存在完成了一部分这样的情况，例如银行转账这样的场景里，转账行为发生后，发送方余额减少，而如果数据库出现了操作错误，接收方余额未增加，则会造成严重的问题。&lt;/p&gt;
&lt;p&gt;一致性是指在事务执行完成后，整个数据库的数据是一致的，不应存在数据库内同一数据不同步的情况。&lt;/p&gt;
&lt;p&gt;隔离性则是指不同的事务之间应该独立进行运行、互不干扰的，当然，这样会牺牲一定的效率，但对数据的准确性等提供了较好保障。&lt;/p&gt;
&lt;p&gt;持久性则是指当一个事务执行完成后，它对数据库进行的更改、对系统产生的影响是永久的。&lt;/p&gt;
&lt;h3 id=&#34;数据完整性&#34;&gt;数据完整性&lt;/h3&gt;
&lt;p&gt;数据完整性是数据库很重要的一个要求和属性，是指存储在数据库中的数据应该保持一致性和可靠性，主要分为以下四种&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实体完整性&lt;/li&gt;
&lt;li&gt;域完整性&lt;/li&gt;
&lt;li&gt;参照完整性&lt;/li&gt;
&lt;li&gt;用户定义完整性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实体完整性要求每张数据表都有一个唯一的标识符，每张表中的主键字段不能为空且不能重复，这主要是指表中的数据都可以被唯一区分。&lt;/p&gt;
&lt;p&gt;域完整性则是通过对表中列做一些额外限制，如限制数据类型、检查约束、设置默认值、是否允许空值以及值域范围等。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;在创建表时对字段进行唯一性的约束&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;person&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;auto_increment&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;primary&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;varchar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;id_number&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;varchar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;18&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;unique&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参照完整性是指数据库不允许引用不存在的实体，数据库的表与其他表之间往往存在一些关联，可以通过外键约束来保障其完整性。&lt;/p&gt;
&lt;p&gt;而用户自定义完整性则是根据具体应用场景和涉及到数据来对数据进行一些语义方面的限制，如余额不能为负数等，一般用设定规则、存储过程和触发器等来进行约束和限制。&lt;/p&gt;
&lt;h3 id=&#34;主流rdbms&#34;&gt;主流RDBMS&lt;/h3&gt;
&lt;p&gt;目前主流的关系型数据库有以下几种&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL Server&lt;/li&gt;
&lt;li&gt;Sybase&lt;/li&gt;
&lt;li&gt;DB2&lt;/li&gt;
&lt;li&gt;Oracle&lt;/li&gt;
&lt;li&gt;MySQL&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;企业和个人用得比较多的是Oracle和MySQL两种，接下来也会以MySQL为例进行详细的操作讲解。&lt;/p&gt;
&lt;h2 id=&#34;mysql&#34;&gt;MySQL&lt;/h2&gt;
&lt;h3 id=&#34;安装与启动&#34;&gt;安装与启动&lt;/h3&gt;
&lt;p&gt;MySQL是由Sun公司（后被Oracle公司收购）开发维护的一种很流行的小型数据库系统，由于体积很小且运行数据快，被很多中小型企业/网站采用，也具备较完整的开发和维护生态。&lt;/p&gt;
&lt;p&gt;作为个人用户学习使用，可以下载社区版（开源）进行使用本地搭建环境，可以根据不同的系统选择不同的版本，也具备较便捷的图形界面供大家进行服务的开启、关闭、重启以及进行相关的配置等。本文以MacOS系统下的&lt;code&gt;MySQL 8.0.21&lt;/code&gt;为例，在安装及进行基本设置后，就可以对本机MySQL服务进行管理，版本可能会略有差别，但核心功能差别不大。&lt;/p&gt;
&lt;h4 id=&#34;图形界面&#34;&gt;图形界面&lt;/h4&gt;
&lt;p&gt;打开系统偏好设置，可以看到如下界面&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mac_mysql_manage.png&#34; alt=&#34;mac_mysql_manage&#34;&gt;&lt;/p&gt;
&lt;p&gt;点击MySQL图标即可进入详细管理界面&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mac_mysql_service.png&#34; alt=&#34;mac_mysql_service&#34;&gt;&lt;/p&gt;
&lt;p&gt;在这个管理界面可以很方便地进行MySQL服务的开启与关闭，也可以将其设置为开机自启等操作，&lt;code&gt;Configuration&lt;/code&gt;中也可以进行进一步的设置，但更建议在命令行进行。&lt;/p&gt;
&lt;h4 id=&#34;命令行界面&#34;&gt;命令行界面&lt;/h4&gt;
&lt;p&gt;当然，也可以在命令行中进行启动&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;//启动MySQL
sudo /usr/local/mysql/support-files/mysql.server start

//关闭MySQL
sudo /usr/local/mysql/support-files/mysql.server stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;效果如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mac_mysql_cli.png&#34; alt=&#34;mac_mysql_cli&#34;&gt;&lt;/p&gt;
&lt;p&gt;当然也可以通过设置一些alias来简化命令，但是既然有比较方便的管理界面了，也就不折腾了，如果在一些没有图形界面的linux环境下进行操作，则需要命令行操作。&lt;/p&gt;
&lt;h3 id=&#34;连接mysql&#34;&gt;连接MySQL&lt;/h3&gt;
&lt;p&gt;安装和启动完成后 即可通过命令行连接MySQL并进行一些基本操作了&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;mysql -h localhost -u root -p

//输入安装时设置的密码

//查看状态
status&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_connect.png&#34; alt=&#34;mysql_connect&#34;&gt;&lt;/p&gt;
&lt;p&gt;而除了通过命令行连接外，MacOS平台上也有一个很好用的客户端&lt;code&gt;Sequel Pro&lt;/code&gt;，提供了大多数需要的功能，而由于正式版存在崩溃问题且已经不再维护，建议下载测试版 &lt;a href=&#34;https://sequelpro.com/test-builds&#34;&gt;Sequel Pro测试版&lt;/a&gt;，可以很方便地连接至本地/远程服务器MySQL服务&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/sequel_pro_connect.png&#34; alt=&#34;sequel_pro_connect&#34;&gt;&lt;/p&gt;
&lt;p&gt;并查询数据库的结构、内容及执行SQL命令&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/sequel_pro_manage.png&#34; alt=&#34;sequel_pro_manage&#34;&gt;&lt;/p&gt;
&lt;p&gt;这是目前我使用下来非常强大且轻量级的一个客户端，建议大家使用！&lt;/p&gt;
&lt;h3 id=&#34;sql命令&#34;&gt;SQL命令&lt;/h3&gt;
&lt;p&gt;经过了本地MySQL配置与连接后，我们就可以对数据库进行一些操作了，SQL语言主要分为以下四类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DDL数据定义语言（Data Definition Language）&lt;/li&gt;
&lt;li&gt;DML数据操纵语言（Data Manipulation Language）&lt;/li&gt;
&lt;li&gt;DQL数据查询语言（Data Query Language）&lt;/li&gt;
&lt;li&gt;DCL数据控制语言（Data Control Language）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来我们将通过实战完成一系列操作&lt;/p&gt;
&lt;h4 id=&#34;ddl操作&#34;&gt;DDL操作&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;创建数据库&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;database&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;learn_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;显示所有数据库&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;show&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;databases&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;删除数据库&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;drop&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;database&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mydb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_ddl.png&#34; alt=&#34;mysql_ddl&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;进入某个数据库&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;use&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;learn_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;创建一个简单的数据表&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;create&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;null&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;auto_increment&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;primary&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;varchar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;phone&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;varchar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;添加字段&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;alter&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;add&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;varchar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;修改字段&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;alter&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;modify&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tinyint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;删除字段&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;alter&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;drop&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;column&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;删除全表&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;drop&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了方便演示，这些操作都将在&lt;code&gt;Sequel Pro&lt;/code&gt;客户端中进行，操作后我们的表结构如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_learn_test_ddl.png&#34; alt=&#34;mysql_learn_test_ddl&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;dml操作&#34;&gt;DML操作&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;插入多条数据&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;insert&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;into&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;phone&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;张三&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;13100000000&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;李四&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;13100000001&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;王五&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;13100000002&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;修改数据内容&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;update&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;set&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;王五&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;删除数据内容&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;delete&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;dql操作&#34;&gt;DQL操作&lt;/h4&gt;
&lt;p&gt;MySQL可以通过&lt;code&gt;select&lt;/code&gt;命令来对表进行查询，最常用的查看全表命令为&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;查看表的全部数据&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;还可以通过&lt;code&gt;where&lt;/code&gt;关键字来进行条件查询、以及多个条件的组合查询&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;组合条件进行查询&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;李四&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_dql.png&#34; alt=&#34;mysql_contacts_dql&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IN&lt;/code&gt;和&lt;code&gt;LIKE&lt;/code&gt;也是两个可以很灵活用于查询的关键字。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IN&lt;/code&gt;可以帮助我们过滤某个字段的多个值&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;查询&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id在&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;中的数据&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_dql_in.png&#34; alt=&#34;mysql_contacts_dql_in&#34;&gt;&lt;/p&gt;
&lt;p&gt;同时，&lt;code&gt;IN&lt;/code&gt;和&lt;code&gt;EXISTS&lt;/code&gt;也可以用于子查询&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;子查询&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;student&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stu_no&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stu_no&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;子查询&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;EXISTS&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;student&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;exists&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;score&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stu_no&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;no&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;LIKE&lt;/code&gt;可以帮助我们进行一些包含关系的模糊搜索，&lt;code&gt;%&lt;/code&gt;可以匹配任一个字符，&lt;code&gt;_&lt;/code&gt;可以匹配单个字符&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;查询所有姓张的联系人&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;like&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;张%&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_dql_like_2.png&#34; alt=&#34;mysql_contacts_dql_like_2&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;查询所有名字以四结尾且为两个字的的联系人&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;like&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;_四&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_dql_like.png&#34; alt=&#34;mysql_contacts_dql_like&#34;&gt;&lt;/p&gt;
&lt;p&gt;实际应用中，往往数据表的数据量非常庞大，会对数据根据相应条件进行分组，这就要用到&lt;code&gt;GROUP BY&lt;/code&gt;关键字，以及&lt;code&gt;HAVING&lt;/code&gt;用于进一步筛选条件。&lt;code&gt;GROUP BY&lt;/code&gt;需要配合聚合函数进行使用。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;统计男联系人数量&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;男&amp;#34;&lt;/span&gt; 
            &lt;span class=&#34;k&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;女&amp;#34;&lt;/span&gt; 
            &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;未知&amp;#34;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;性别&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;人数&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;by&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;having&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_dql_group_by.png&#34; alt=&#34;mysql_contacts_dql_group_by&#34;&gt;&lt;/p&gt;
&lt;p&gt;而也可以通过&lt;code&gt;GROUP_CONCAT&lt;/code&gt;来结合一些具体的数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;按性别显示不同性别联系人的列表及总数&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;男&amp;#34;&lt;/span&gt; 
            &lt;span class=&#34;k&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;女&amp;#34;&lt;/span&gt; 
            &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;未知&amp;#34;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;性别&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;group_concat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;order&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;by&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;desc&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;separator&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39; | &amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;人数&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;group&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;by&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_dql_group_concat.png&#34; alt=&#34;mysql_contacts_dql_group_concat&#34;&gt;&lt;/p&gt;
&lt;p&gt;有时候我们只需要返回唯一值，而需要去掉重复数据，则可以使用&lt;code&gt;DISTINCT&lt;/code&gt;关键字&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;在查询时对字段进行去重&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;distinc&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在实际应用中，还很有可能会需要对某些商品交易量进行排名、对一些数值进行排列或博客文章中按照时间线后进行顺序显示等，这就需要用到&lt;code&gt;ORDER BY&lt;/code&gt;这一关键字，它默认为&lt;code&gt;ASC&lt;/code&gt;升序排列，可以通过手动设置&lt;code&gt;DESC&lt;/code&gt;来实现降序。&lt;/p&gt;
&lt;p&gt;同时，有的数据库数据量非常大，一次返回所有的数据比较消耗资源，因此也可以使用&lt;code&gt;LIMIT&lt;/code&gt;关键字来约束返回的记录数，同时，也可以实现分页。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;order&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;by&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;desc&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;limit&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_dql_order_by_limit.png&#34; alt=&#34;mysql_dql_order_by_limit&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;内置函数&#34;&gt;内置函数&lt;/h3&gt;
&lt;p&gt;MySQL也有很多常见的内置函数，可以帮助用户更方便处理各种数据，简化操作，大多数功能都很直观，不作一一说明了&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_functions.png&#34; alt=&#34;mysql_functions&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中值得注意的是，聚合函数是对一组值进行计算并返回单个值。&lt;/p&gt;
&lt;h3 id=&#34;流程控制&#34;&gt;流程控制&lt;/h3&gt;
&lt;p&gt;MySQL有一种类似于编程语言中的if else或switch的流程控制语句，以实现复杂的应用逻辑&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;选取数据并且把性别以中文标识&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;phone&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;
                        &lt;span class=&#34;k&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;男&amp;#34;&lt;/span&gt;
                        &lt;span class=&#34;k&#34;&gt;when&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;then&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;女&amp;#34;&lt;/span&gt;
                        &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;未知&amp;#34;&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;end&lt;/span&gt;
                    &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sex&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;contacts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_contacts_flow_control.png&#34; alt=&#34;mysql_contacts_flow_control&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;表的连接&#34;&gt;表的连接&lt;/h3&gt;
&lt;p&gt;不同的表可以通过一定连接条件发生关联，主要有自连接、内连接和外连接三种，其中外连接又分为左外连接、右外连接和全外连接三种，他们的区别如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/mysql_table_join.png&#34; alt=&#34;mysql_table_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;而自连接是一种特殊的连接方式，通过在逻辑上生成多张表以实现复杂的层次结构，常应用于区域表、菜单表和商品分类表等，语法如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;o&#34;&gt;#&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;自连接语法&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cloumn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;column&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;table&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;where&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;column&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;column&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;学完了关系型数据库，那非关系型数据库又是怎样的呢？后续将会对Redis这一使用广泛的非关系性数据库进行整理，敬请期待！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mysql.com&#34;&gt;MySQL官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sequelpro.com&#34;&gt;Sequel Pro官网&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS本地节点搭建（命令行）</title>
      <link>https://www.pseudoyu.com/zh/2021/03/27/blockchain_ipfs_practice/</link>
      <pubDate>Sat, 27 Mar 2021 18:46:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/27/blockchain_ipfs_practice/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;上一篇《&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/25/blockchain_ipfs_structure/&#34;&gt;IPFS分布式文件存储原理&lt;/a&gt;》对于IPFS系统的设计理念、功能、工作原理及IPNS做了详细的介绍，那么，如何在本地搭建一个IPFS节点呢？&lt;/p&gt;
&lt;p&gt;本文在&lt;code&gt;macOS 11.2.3&lt;/code&gt;系统上搭建了一个IPFS节点（命令行版本），并对文件上传、下载、网络同步、&lt;code&gt;pin&lt;/code&gt;、&lt;code&gt;GC&lt;/code&gt;、&lt;code&gt;IPNS&lt;/code&gt;等进行了实际操作，以加深对IPFS工作原理的理解。&lt;/p&gt;
&lt;h2 id=&#34;代码实践&#34;&gt;代码实践&lt;/h2&gt;
&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;wget https://dist.ipfs.io/go-ipfs/v0.8.0/go-ipfs_v0.8.0_darwin-amd64.tar.gz
tar -xvzf go-ipfs_v0.8.0_darwin-amd64.tar.gz
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; go-ipfs
./install.sh
ipfs --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动&#34;&gt;启动&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 启动节点&lt;/span&gt;
ipfs init

&lt;span class=&#34;c1&#34;&gt;# 上传文件&lt;/span&gt;
ipfs add ipfs_init_readme.png

&lt;span class=&#34;c1&#34;&gt;# 上传文件并且只输出哈希值&lt;/span&gt;
ipfs add -q ipfs_init_readme.png

&lt;span class=&#34;c1&#34;&gt;# 上传目录&lt;/span&gt;
ipfs add -r &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查看文件&lt;/span&gt;
ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/readme
ipfs cat /ipfs/QmQPeNsJPyVWPFDVHb77w8G42Fvo15z4bG2X8D2GhfbSXc/quick-start

&lt;span class=&#34;c1&#34;&gt;# 查看自己上传的文件&lt;/span&gt;
ipfs cat QmaP3QS6ZfBoEaUJZ3ZfRKoBm3GGuhQSnUWtkVCNc8ZLTj

&lt;span class=&#34;c1&#34;&gt;# 查看图片并输出到文件&lt;/span&gt;
ipfs cat QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH &amp;gt; ipfsTest.png

&lt;span class=&#34;c1&#34;&gt;# 下载文件&lt;/span&gt;
ipfs get QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH -o ipfsTest.png

&lt;span class=&#34;c1&#34;&gt;# 压缩并下载文件&lt;/span&gt;
ipfs get QmfViXYw7GA296brLwid255ivDp1kmTiXJw1kmZVsg7DFH -Cao ipfsTest.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_init_readme.png&#34; alt=&#34;ipfs_init_readme&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;开启加入服务&#34;&gt;开启/加入服务&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看当前节点信息 &lt;/span&gt;
ipfs id

&lt;span class=&#34;c1&#34;&gt;# 查看IPFS配置信息&lt;/span&gt;
ipfs config show

&lt;span class=&#34;c1&#34;&gt;# 开启节点服务器&lt;/span&gt;
ipfs daemon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;API服务，默认在5001端口，可以通过 http://localhost:5001/webui 进行访问&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_webui.png&#34; alt=&#34;ipfs_webui&#34;&gt;&lt;/p&gt;
&lt;p&gt;网关服务，默认在8080端口，在浏览器里访问文件需要借助于IPFS提供的网关服务，由浏览器先访问到网关，网关去获取IPFS网络杀过了的文件。通过 http://localhost:8080/ipfs/[File Hash] 来访问上传到ipfs的文件&lt;/p&gt;
&lt;h3 id=&#34;文件操作&#34;&gt;文件操作&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 列出文件&lt;/span&gt;
ipfs files ls

&lt;span class=&#34;c1&#34;&gt;# 创建目录&lt;/span&gt;
ipfs files mkdir

&lt;span class=&#34;c1&#34;&gt;# 删除文件&lt;/span&gt;
ipfs files rm

&lt;span class=&#34;c1&#34;&gt;# 拷贝文件&lt;/span&gt;
ipfs files cp &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; /&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dest Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 移动文件&lt;/span&gt;
ipfs files mv &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; /&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Dest Dir&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 状态&lt;/span&gt;
ipfs files stat

&lt;span class=&#34;c1&#34;&gt;# 读取&lt;/span&gt;
ipfs files &lt;span class=&#34;nb&#34;&gt;read&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;使用ipns来解决文件更新问题&#34;&gt;使用IPNS来解决文件更新问题&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 使用IPNS发布内容以自动更新&lt;/span&gt;
ipfs name publish &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查询节点id指向的Hash&lt;/span&gt;
ipfs name resolve

&lt;span class=&#34;c1&#34;&gt;# 有多个站点需要更新，可以新产生一个秘钥对，使用新的key发布&lt;/span&gt;
ipfs key gen --type&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;rsa --size&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2048&lt;/span&gt; mykey
ipfs name publish --key&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mykey  &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pinning&#34;&gt;Pinning&lt;/h3&gt;
&lt;p&gt;当我们向IPFS网络请求文件时，IPFS会把内容先同步的本地提供服务，使用Cache机制处理文件以防止存储空间不断增长，如果文件一段时间未被使用则会被“回收”，Pining的作用就是确保文件在本地不被“回收”。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# pin一个文件&lt;/span&gt;
ipfs pin add &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查询某一个Hash是否被pin&lt;/span&gt;
ipfs pin ls &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 删除pin的状态&lt;/span&gt;
ipfs pin rm -r &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;File Hash&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# GC操作&lt;/span&gt;
ipfs repo gc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文主要在本地部署了IPFS文件系统并对基本操作进行了尝试，基于&lt;code&gt;macOS 11.2.3&lt;/code&gt;和&lt;code&gt;go-ipfs_v0.8.0_darwin-amd64&lt;/code&gt;版本，不同系统操作可能会因版本或依赖问题不一样，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://ipfs.io&#34;&gt;IPFS官网&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>IPFS分布式存储协议分析与思考</title>
      <link>https://www.pseudoyu.com/zh/2021/03/25/blockchain_ipfs_structure/</link>
      <pubDate>Thu, 25 Mar 2021 16:30:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/25/blockchain_ipfs_structure/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;最近在做学校的Case Study项目，是一个基于&lt;code&gt;Ethereum&lt;/code&gt;平台的音乐版权管理项目，其中对于音乐作品、版权证明文件等上传用到了IPFS分布式文件存储技术，主要是利用其去重的特性来检测侵权行为。对IPFS这个系统产生了兴趣，阅读了&lt;a href=&#34;https://tech.hyperchain.cn&#34;&gt;QTech平台&lt;/a&gt;上的&lt;a href=&#34;https://tech.hyperchain.cn/tag/ipfs/&#34;&gt;IPFS系列文章&lt;/a&gt;，也查询了一些相关资料，通过本文梳理一下，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;p&gt;我们日常使用网盘或其他服务时大多都是访问文件所在的特定的服务器（IP地址），请求文件并下载到本地，通过的是HTTP协议，本质上是基于位置寻址的，访问URL来得到一层层找到具体的文件，这种方式固然便捷，但是存在一些问题。文件依托于特定的服务器，因此一旦中心化的服务器宕机或者文件被删除了，内容将永久丢失，并且如果离服务器很远/同时访问文件的人很多的话访问速度也会比较慢；而且同样一份文件可能重复存储在不同的服务器中，造成资源的浪费；此外就是存在严重的安全隐患，DDoS、XSS、CSRF等攻击都可能对文件安全性造成威胁。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那有没有更好的解决方案呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;试想我们把文件存储在一个分布式网络里，每个节点都可以存储文件，用户可以通过访问一个类似目录索引的方式来向最近的节点互相请求文件。这就是IPFS星际文件系统的解决思路，它是一个点对点的超媒体文件存储、索引、交换协议，由Juan Benet在2014年5月发起。&lt;/p&gt;
&lt;h3 id=&#34;特点&#34;&gt;特点&lt;/h3&gt;
&lt;p&gt;IPFS想把全世界所有部署了相同文件系统的计算设备链接在一起，构建一个分布式网络来替代传统中心化的服务器模式，每个节点都可以存储文件，用户通过&lt;code&gt;DHT(Distributed Hash Table)&lt;/code&gt;分布式哈希表来获取文件，速度更快、更安全，网络安全性更强。&lt;/p&gt;
&lt;p&gt;因为通过IPFS存储的文件内容是通过分块求Hash值存储为地址的，本质上是通过多重哈希来确定文件的地址，这是一种去中心化但是基于内容寻址的方式，通过对数据本身进行加密，生成独一无二的Hash以供查找，这种方式下，即使是微小的改变，也会造成Hash结果截然不同，因此很容易能够从Hash检测内容是否被篡改，甚至不用访问文件本身。&lt;/p&gt;
&lt;p&gt;不同于传统的服务器模式，IPFS是一个统一的网络，因此已经上传的相同内容的文件不会重复存储（可以通过Hash值检验），极大地节约了整体网络资源，也更加高效。而且理论上只要节点达到一定规模，文件将永久保存，且同一个文件可以从多个（也更近）的节点下载，通讯效率也会更高。&lt;/p&gt;
&lt;p&gt;除此之外，因为是分布式网络进行存储，也可以天然地避免传统DDoS等攻击。&lt;/p&gt;
&lt;h3 id=&#34;功能&#34;&gt;功能&lt;/h3&gt;
&lt;p&gt;除了文件存储外，IPFS还有DHT组网、Bitswap文件交换等功能，之后也会单独写博文进行讲解。&lt;/p&gt;
&lt;h2 id=&#34;工作原理&#34;&gt;工作原理&lt;/h2&gt;
&lt;p&gt;作为一个文件存储系统，上传文件和下载文件是两个最基本的操作，我们分别讲一下原理。&lt;/p&gt;
&lt;h3 id=&#34;ipfs-add命令&#34;&gt;IPFS add命令&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;在IPFS系统中执行add操作就完成了上传操作，那是怎么上传的呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在IPFS文件存储系统中，每当上传一个新文件，系统会将单个文件拆分成若干个256KB的block，每个block会有一个专属的CID进行标识，这个后面会详细讲；然后计算每一个block的Hash值，并存储再一个数组中，最后对这个数组求Hash得到文件的最终Hash值；接着将文件的Hash和所有的blocks Hash的数组组成成一个对象，也就形成了一种索引结构；最后把文件block和这个索引结构全部上传到IPFS节点，同步到IPFS网络。&lt;/p&gt;
&lt;p&gt;文件上传时有两个值得注意的情况：1.文件特别小，如果文件小于1KB的话就不浪费一个block了，会直接和Hash一起上传到IPFS。2.文件特别大，比如之前上传了一个1G的视频，之后又加了几KB的字幕文件，这种情况下未变化的1G部分是不会重新分配新的空间的，而只会为追加的字母文件部分分配新的block，再重新上传Hash。&lt;/p&gt;
&lt;p&gt;因此，很好理解的是，即使是不同文件的相同部分也只会存储一份，很多文件的索引会指向同一个block，所形成的结构就是MerkleDAG数据结构。&lt;/p&gt;
&lt;p&gt;值得注意的是，当节点执行add操作时，会保留到本地blockstore中，但不会立刻主动上传到IPFS网络中，也就是说，与其连接的节点并不会存储这个文件，除非有某个节点请求过该block数据！因此，它并不是一个自动备份数据的分布式数据库。IPFS这种设计是出于网络带宽、可靠性等方面的考虑。&lt;/p&gt;
&lt;p&gt;还有一个细节就是，当节点在执行&lt;code&gt;add&lt;/code&gt;命令时，还会广播自己的块信息，并维护一个所有发给这个节点的block请求列表，一旦add命令添加到数据满足这个列表，就会主动向对应的节点发送数据并且更新列表。&lt;/p&gt;
&lt;h3 id=&#34;ipfs-get命令&#34;&gt;IPFS get命令&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;那文件上传后，要怎么查找访问呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这就关系到上文所提到的IPFS索引结构是&lt;code&gt;DHT&lt;/code&gt;（分布式哈希表），通过对&lt;code&gt;DHT&lt;/code&gt;进行访问可以很快访问得到数据。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_dht.png&#34; alt=&#34;ipfs_dht&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那如果想要查找一个本地没有的数据呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_get.gif&#34; alt=&#34;ipfs_get&#34;&gt;&lt;/p&gt;
&lt;p&gt;在IPFS系统中，所有和当前节点连接的节点会构成一个swarm网络，当节点发送一个文件请求(即&lt;code&gt;get&lt;/code&gt;)时，首先会在本地的blockstore里查找请求的数据，如果没找到的话，就会向swarm网络发出一个请求，通过网络中的&lt;code&gt;DHT Routing&lt;/code&gt;找到拥有该数据的节点。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;怎么知道网络中哪个（哪些）节点拥有这个请求文件呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如上文&lt;code&gt;add&lt;/code&gt;命令所讲的那样，当一个节点加入到IPFS网络中后，会告诉其它节点自己存储了什么内容（通过广播&lt;code&gt;DHT&lt;/code&gt;），这样每当有用户希望检索的内容正好在这个节点上时，其它节点就会告诉用户要从这个节点索取他想要的内容。&lt;/p&gt;
&lt;p&gt;一旦找到拥有这个数据的节点，就会把请求数据反馈回来，这样本地节点会把收到的block数据缓存一份到本地的blockstore中，这样整个网络中相当于多了一份原数据的拷贝，更多节点请求数据的话，查找就变得更容易，因此数据的不可丢失性也是基于这个原理，只要有一个节点保存着这个数据，就可以被全网获取。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在项目中，上传的文件可以通过&lt;code&gt;ipfs.io&lt;/code&gt;网关直接获取到文件，类似于&lt;code&gt;https://ipfs.io/ipfs/Qm.....&lt;/code&gt;这样的网站地址，这个是什么原理呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ipfs_io_get.gif&#34; alt=&#34;ipfs_io_get&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ipfs.io&lt;/code&gt;网关实际上就是一个IPFS节点，当我们打开上述这个网络链接的时候，实际上就是向这个节点发送了一次请求，因此&lt;code&gt;ipfs.io&lt;/code&gt;网关会帮我们去向拥有这个数据的节点请求这个block（如果这个文件是自己刚在本地节点通过&lt;code&gt;add&lt;/code&gt;命令添加的话就会通过这种方式被上传到IPFS网络上），在&lt;code&gt;swarm&lt;/code&gt;网络中通过&lt;code&gt;DHT Routing&lt;/code&gt;获取到数据后，网关会自己先缓存一份，然后将数据通过HTTP协议发给我们，因此，就可以在浏览器直接看到这个文件啦！&lt;/p&gt;
&lt;p&gt;而任何其他机器通过浏览器访问这个链接时，因为&lt;code&gt;ipfs.io&lt;/code&gt;网关已经缓存了这个文件，再次请求的时候，就不需要向原节点来请求数据了，可以直接从缓存中返回数据给浏览器。&lt;/p&gt;
&lt;h3 id=&#34;内容标识符cidcontent-id&#34;&gt;内容标识符CID(Content-ID)&lt;/h3&gt;
&lt;p&gt;现在考虑另一个问题，我们常见的图像为&lt;code&gt;.jpg&lt;/code&gt;、&lt;code&gt;.png&lt;/code&gt;，而常见的视频则是&lt;code&gt;.mp4&lt;/code&gt;一样，可以直接从后缀名判断文件类型。通过IPFS上传的文件也可以是多种类型，也包含了很多信息，怎么进行分辨呢？&lt;/p&gt;
&lt;p&gt;IPFS早期主要使用&lt;code&gt;base58btc&lt;/code&gt;对&lt;code&gt;multihash&lt;/code&gt;进行编码，但是在开发IPLD（主要用来定义数据，给数据建模）的过程中会遇到很多与格式相关的问题，因此使用了一种叫&lt;code&gt;CID&lt;/code&gt;的文件寻址格式来对不同格式的数据进行管理，官方的定义为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;CID&lt;/code&gt;是一种自描述式的内容寻址的识别符，必须使用加密散列函数来得到内容的地址&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说，&lt;code&gt;CID&lt;/code&gt;通过一些机制来对文件所包含的内容进行自描述，包含了版本信息、格式等。&lt;/p&gt;
&lt;h4 id=&#34;cid结构&#34;&gt;CID结构&lt;/h4&gt;
&lt;p&gt;目前&lt;code&gt;CID&lt;/code&gt;有&lt;code&gt;v0&lt;/code&gt;和&lt;code&gt;v1&lt;/code&gt;两种版本，&lt;code&gt;v1&lt;/code&gt;版本的&lt;code&gt;CID&lt;/code&gt;由&lt;code&gt;V1Builder&lt;/code&gt;生成&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&amp;lt;cidv1&amp;gt; ::&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &amp;lt;mb&amp;gt;&amp;lt;version&amp;gt;&amp;lt;mcp&amp;gt;&amp;lt;mh&amp;gt;
&lt;span class=&#34;c1&#34;&gt;# or, expanded:&lt;/span&gt;
&amp;lt;cidv1&amp;gt; ::&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &amp;lt;multibase-prefix&amp;gt;&amp;lt;cid-version&amp;gt;&amp;lt;multicodec-packed-content-type&amp;gt;&amp;lt;multihash-content-address&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如上面列举的代码所示，采用的机制叫&lt;code&gt;multipleformats&lt;/code&gt;，主要包括：&lt;code&gt;multibase-prefix&lt;/code&gt;表示&lt;code&gt;CID&lt;/code&gt;编码成字符串，&lt;code&gt;cid-version&lt;/code&gt;表示版本变量，&lt;code&gt;multicodec-packed-content-type&lt;/code&gt;表示内容的类型和格式（类似于后缀，但是作为标识符的一部分，支持的格式有限，且用户是不能随意修改的），&lt;code&gt;multihash-content-address&lt;/code&gt;表示哈希值（让&lt;code&gt;CID&lt;/code&gt;可以使用不同的Hash函数）。&lt;/p&gt;
&lt;p&gt;目前&lt;code&gt;CID&lt;/code&gt;支持的&lt;code&gt;multicodec-packed&lt;/code&gt;编码有原生的&lt;code&gt;protobuf&lt;/code&gt;格式、&lt;code&gt;IPLD CBOR&lt;/code&gt;格式、&lt;code&gt;git&lt;/code&gt;、比特币和以太坊对象等格式，也在逐步开发支持更多格式。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CID&lt;/code&gt;代码详解：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Cid&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;str&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;V0Builder&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;V1Builder&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;Codec&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;MhType&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;MhLength&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Default: -1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Codec&lt;/code&gt;表示内容的编码类型，如&lt;code&gt;DagProtobuf&lt;/code&gt;, &lt;code&gt;DagCBOR&lt;/code&gt;等，&lt;code&gt;MhType&lt;/code&gt;表示哈希算法，如&lt;code&gt;SHA2_256&lt;/code&gt;, &lt;code&gt;SHA2_512&lt;/code&gt;, &lt;code&gt;SHA3_256&lt;/code&gt;, &lt;code&gt;SHA3_512&lt;/code&gt;等，而&lt;code&gt;MhLength&lt;/code&gt;则表示生成哈希的长度。&lt;/p&gt;
&lt;p&gt;而&lt;code&gt;v0&lt;/code&gt;版本的&lt;code&gt;CID&lt;/code&gt;由&lt;code&gt;V0Builder&lt;/code&gt;生成，以&lt;code&gt;Qm&lt;/code&gt;字符串开头，向后兼容，&lt;code&gt;multibase&lt;/code&gt;一直为&lt;code&gt;base58btc&lt;/code&gt;，&lt;code&gt;multicodec&lt;/code&gt;一直为&lt;code&gt;protobuf-mdag&lt;/code&gt;，&lt;code&gt;cid-version&lt;/code&gt;一直为&lt;code&gt;cidv0&lt;/code&gt;，&lt;code&gt;multihash&lt;/code&gt;表示为&lt;code&gt;cidv0 ::= &amp;lt;multihash-content-address&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;设计理念&#34;&gt;设计理念&lt;/h4&gt;
&lt;p&gt;通过&lt;code&gt;CID&lt;/code&gt;这种二进制的特性，大大提高了对于文件Hash的压缩效率，因此可以直接作为URL的一部分进行访问；通过&lt;code&gt;multibase&lt;/code&gt;的编码形式（如&lt;code&gt;base58btc&lt;/code&gt;）缩短了&lt;code&gt;CID&lt;/code&gt;的长度，这样更容易传输；可以表示任意格式、任何哈希函数的结果，十分灵活；可以通过结构中&lt;code&gt;cid-version&lt;/code&gt;参数进行编码版本的升级；不受限于历史内容。&lt;/p&gt;
&lt;h3 id=&#34;ipns&#34;&gt;IPNS&lt;/h3&gt;
&lt;p&gt;如上文所述，IPFS中文件内容的改变会造成其哈希值的变化，在实际应用中，如果通过IPFS托管网站等需要版本更新迭代的应用，每一次都通过更新后的Hash访问很不方便，因此，需要一个映射方案以保证用户体验，这样用户在访问时仅需要访问一个固定地址。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IPNS(Inter-Planetary Naming System)&lt;/code&gt;就提供了这样的服务，它提供了一个被私钥限定的哈希ID（通常是PeerID）来指向具体的IPFS文件，文件更新后会自动更新哈希ID的指向。&lt;/p&gt;
&lt;p&gt;即使哈希值可以固定不变了，但是依然不便于记忆和输入，因此，有了更进一步的解决方案。&lt;/p&gt;
&lt;p&gt;IPNS同样兼容DNS，可以使用&lt;code&gt;DNS TXT&lt;/code&gt;记录域名对应的IPNS哈希ID，就可以域名来替换IPNS哈希ID来进行访问，从而实现更容易读写和记忆。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对IPFS分布式存储原理的梳理，它的组件、存储流程细节、GC机制、数据交换模块Bitswap、网络以及实际应用场景都有很多值得深入挖掘的部分。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;推荐阅读：趣链科技QTech平台《&lt;a href=&#34;https://tech.hyperchain.cn/tag/ipfs/&#34;&gt;IPFS系列文章&lt;/a&gt;》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://ipfs.io&#34;&gt;IPFS官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.hyperchain.cn/ipfs/&#34;&gt;原来IPFS是这样存储文件的&lt;/a&gt;，&lt;em&gt;QTech，趣链科技&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/news/277198&#34;&gt;IPFS到底怎么工作的？&lt;/a&gt;，&lt;em&gt;知辉&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://learnblockchain.cn/2018/12/12/what-is-ipfs&#34;&gt;站在Web3.0理解IPFS是什么&lt;/a&gt;，&lt;em&gt;Tiny熊，登链社区&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@kidinamoto/ipfs-cid-%E7%A0%94%E7%A9%B6-717c4ceb14a0&#34;&gt;IPFS CID研究&lt;/a&gt;，&lt;em&gt;Sophie Huang&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>Hyperledger Fabric网络与安全体系浅析</title>
      <link>https://www.pseudoyu.com/zh/2021/03/23/blockchain_hyperledger_fabric_network/</link>
      <pubDate>Tue, 23 Mar 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/23/blockchain_hyperledger_fabric_network/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;上一篇文章《&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/03/20/blockchain_hyperledger_fabric_structure/&#34;&gt;Hyperledger Fabric架构详解&lt;/a&gt;》对&lt;code&gt;Fabric&lt;/code&gt;的架构和工作原理进行了详细的解读与分析，那作为一个企业级的区块链系统，它是如何根据复杂的业务需求搭建网络，在运行过程中存在哪些安全问题，以及&lt;code&gt;Fabric&lt;/code&gt;是如何从机制上进行预防的呢？&lt;/p&gt;
&lt;p&gt;本文将通过实例阐释一个简化版的企业&lt;code&gt;Fabric&lt;/code&gt;网络是如何构建的，并对其网络与安全体系进行分析，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;hyperledger-fabric网络&#34;&gt;Hyperledger Fabric网络&lt;/h2&gt;
&lt;h3 id=&#34;hyperledger-fabric应用场景实例&#34;&gt;Hyperledger Fabric应用场景实例&lt;/h3&gt;
&lt;h4 id=&#34;业务角色&#34;&gt;业务角色&lt;/h4&gt;
&lt;p&gt;假设有一个采用&lt;code&gt;Fabric&lt;/code&gt;系统的应用场景里。&lt;/p&gt;
&lt;p&gt;有4个组织&lt;code&gt;R1&lt;/code&gt;, &lt;code&gt;R2&lt;/code&gt;, &lt;code&gt;R3&lt;/code&gt;和&lt;code&gt;R4&lt;/code&gt;，&lt;code&gt;R4&lt;/code&gt;是网络启动者，&lt;code&gt;R1&lt;/code&gt;和&lt;code&gt;R4&lt;/code&gt;共同担任网络管理员角色。&lt;/p&gt;
&lt;p&gt;系统设置了2个通道，分别为&lt;code&gt;C1&lt;/code&gt;和&lt;code&gt;C2&lt;/code&gt;。&lt;code&gt;R1&lt;/code&gt;和&lt;code&gt;R2&lt;/code&gt;使用&lt;code&gt;C1&lt;/code&gt;通道，&lt;code&gt;R2&lt;/code&gt;和&lt;code&gt;R3&lt;/code&gt;使用&lt;code&gt;C2&lt;/code&gt;通道。&lt;/p&gt;
&lt;p&gt;应用&lt;code&gt;A1&lt;/code&gt;属于组织&lt;code&gt;R1&lt;/code&gt;，于&lt;code&gt;C1&lt;/code&gt;通道运行；应用&lt;code&gt;A2&lt;/code&gt;属于组织&lt;code&gt;R2&lt;/code&gt;，同时于&lt;code&gt;C1&lt;/code&gt;通道和&lt;code&gt;C2&lt;/code&gt;通道运行；应用&lt;code&gt;A3&lt;/code&gt;属于组织&lt;code&gt;R3&lt;/code&gt;，于&lt;code&gt;C2&lt;/code&gt;通道运行。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;P1&lt;/code&gt;、&lt;code&gt;P2&lt;/code&gt;和&lt;code&gt;P3&lt;/code&gt;分别是组织&lt;code&gt;R1&lt;/code&gt;、&lt;code&gt;R2&lt;/code&gt;和&lt;code&gt;R3&lt;/code&gt;的节点。&lt;/p&gt;
&lt;p&gt;排序节点由&lt;code&gt;O4&lt;/code&gt;提供，属于组织&lt;code&gt;R4&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&#34;搭建过程&#34;&gt;搭建过程&lt;/h4&gt;
&lt;p&gt;与真正的商业应用场景相比，角色和商业和逻辑都很简化，但很适合用来理解不同节点和角色之间的功能和交互。接下来，我将一步一步说明网络的搭建过程。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;创建网络并添加网络管理员&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;每一个组织需要通过&lt;code&gt;MSP&lt;/code&gt;中的CA机构颁发的证书才能加入网络，因此，每个节点都需要有相应的CA。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;R4&lt;/code&gt;作为网络启动者，需要先配置网络并设立&lt;code&gt;O4&lt;/code&gt;排序节点！网络创建后，添加&lt;code&gt;R1&lt;/code&gt;作为网络管理员，因此，&lt;code&gt;R1&lt;/code&gt;和&lt;code&gt;R4&lt;/code&gt;可以对网络进行配置（&lt;code&gt;NC4&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/fabric_network_example_1.png&#34; alt=&#34;fabric_network_example_1&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定义联盟并创建通道&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;R1&lt;/code&gt;和&lt;code&gt;R2&lt;/code&gt;将通过&lt;code&gt;C1&lt;/code&gt;进行业务交互，因此需要在网络中定义联盟，因为现在&lt;code&gt;R1&lt;/code&gt;和&lt;code&gt;R4&lt;/code&gt;都可以对网络进行配置，因此都可以定义联盟。&lt;/p&gt;
&lt;p&gt;接着为这个联盟创建通道&lt;code&gt;C1&lt;/code&gt;（连接至排序服务&lt;code&gt;O4&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/fabric_network_example_2.png&#34; alt=&#34;fabric_network_example_2&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;加入节点、部署智能合约与应用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;P1&lt;/code&gt;节点加入已经建立的通道&lt;code&gt;C1&lt;/code&gt;，维护着一个账本&lt;code&gt;L1&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这时候就可以在节点上安装和实例化智能合约了。&lt;code&gt;Fabric&lt;/code&gt;的智能合约是链码，把链码存储在节点的文件系统上称为安装智能合约，安装后还需要在特定的通道上启动和实例化链码，至此，应用可以发送交易proposal至背书节点了（需要遵守链码设置的背书策略）。&lt;/p&gt;
&lt;p&gt;如下图所示，&lt;code&gt;P1&lt;/code&gt;节点安装链码&lt;code&gt;S5&lt;/code&gt;并在通道&lt;code&gt;C1&lt;/code&gt;实例化后，就可以响应来自应用&lt;code&gt;A1&lt;/code&gt;的链码调用了;&lt;code&gt;P2&lt;/code&gt;节点安装链码&lt;code&gt;S5&lt;/code&gt;并在通道&lt;code&gt;C1&lt;/code&gt;实例化后，就可以响应来自应用&lt;code&gt;A2&lt;/code&gt;的链码调用了。&lt;/p&gt;
&lt;p&gt;通道中的每一个节点都是提交节点，可以接收新区块（来自排序节点）进行验证，并提交至账本；而部署了链码的一些节点则可以成为背书节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/fabric_network_example_4.png&#34; alt=&#34;fabric_network_example_4&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定义新联盟、创建新通道&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在网络中定义新联盟并加入&lt;code&gt;C2&lt;/code&gt;通道。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/fabric_network_example_5.png&#34; alt=&#34;fabric_network_example_5&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;加入新节点并部署智能合约与应用&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;值得注意的是，有些节点会同时加入多个通道，在不同的业务中扮演不同的角色，其他流程同上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/fabric_network_example_6.png&#34; alt=&#34;fabric_network_example_6&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;网络搭建完成&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_network_example.png&#34; alt=&#34;hyperledger_fabric_network_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;采用权限管理、通道等机制，并通过对不同节点功能分工，提升了系统的运行效率，并保障了复杂业务场景中的安全和隐私；强大的链码和可自定义的背书策略等也保障了系统的拓展性，可以处理复杂的业务逻辑。&lt;/p&gt;
&lt;h2 id=&#34;hyperledger-fabric安全分析&#34;&gt;Hyperledger Fabric安全分析&lt;/h2&gt;
&lt;h3 id=&#34;fabric安全机制&#34;&gt;Fabric安全机制&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;设计了很多机制来保障系统的安全性。&lt;/p&gt;
&lt;h4 id=&#34;系统配置与成员管理&#34;&gt;系统配置与成员管理&lt;/h4&gt;
&lt;p&gt;区别于比特币、以太坊等公链，加入&lt;code&gt;Fabric&lt;/code&gt;网络需要进行权限验证，&lt;code&gt;Fabric CA&lt;/code&gt;为成员管理使用&lt;code&gt;X.509&lt;/code&gt;证书机制以保障其权限，避免潜在&lt;code&gt;Spoofing&lt;/code&gt;攻击等。&lt;/p&gt;
&lt;p&gt;现有的系统成员需要制定加入新成员的规则，比如进行多数投票等；现有成员也需要决定网络和智能合约的更新和改变，这样能够很大程度上防止恶意节点破坏系统安全性；现有节点不能自行升级权限；除此之外，还需要决定系统的通用数据模型等设置。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;的网络传输采用&lt;code&gt;TLSv1.2&lt;/code&gt;，可以保障数据的安全性；且系统中的操作，如发起交易、背书等都会通过数字签名技术来记录，很容易追溯一些恶意操作。但值得注意的是，排序节点可以获取系统中所有节点的交易数据，因此，排序服务节点的设定对于整个系统的安全性尤其重要，它的公正性会很大程度影响整个系统的运作，甚至决定了整个系统是否值得信任，因此，需要根据业务和系统结构慎重选择。&lt;/p&gt;
&lt;p&gt;公链系统中，所有节点都有区块链账本的副本，并且执行智能合约；而在&lt;code&gt;Fabric&lt;/code&gt;系统中，业务相关节点会形成节点组，存储与其交易（业务）相关的账本，而通过链码对账本的更新也会被限制在节点组的范围内，从而保障整个系统的稳定性。&lt;/p&gt;
&lt;p&gt;智能合约的执行称为交易，对于&lt;code&gt;Fabric&lt;/code&gt;系统内的交易，也必须要保持其一致性，往往采用密码学技术来防止交易被篡改，如采用&lt;code&gt;SHA256&lt;/code&gt;、&lt;code&gt;ECDSA&lt;/code&gt;等检测修改；&lt;code&gt;Fabric&lt;/code&gt;采取模块化、可插拔的设计，将交易的执行、验证共识进行分离，因此，可以采取不同的共识机制或规则，不仅能够根据需求选择不同的共识机制，更具拓展性，也能提高系统安全性。&lt;/p&gt;
&lt;p&gt;这些配置和规则共同决定了系统的安全性，需要在业务需求、效率和安全性上作权衡。&lt;/p&gt;
&lt;h4 id=&#34;智能合约安全&#34;&gt;智能合约安全&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;的链码需要安装在节点上并且实例化，安装链码需要有CA的验证，因此要注意权限管理；启动后是运行在独立的Docker容器中的，更轻量级，但是因为它能够访问&lt;code&gt;Fabric&lt;/code&gt;网络，如果没经过严格的代码审计以及对网络进行隔离，会造成一些恶意后果。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;的链码可以用多种通用型的编程语言撰写，例如&lt;code&gt;Go&lt;/code&gt;、&lt;code&gt;Java&lt;/code&gt;等，这让系统有了更强的拓展性，也更容易接入现有系统和工具，但因为其执行结果是不缺性的，编程语言的一些特性（如随机数、系统时间戳、指针等）可能会造成不同背书节点执行结果不同，造成系统不一致性；此外，因为链码可以访问一些外部的Web服务、系统命令、文件系统和第三方库等，也会造成一些潜在的风险。因此，用这些通用语言开发的链码需要相对独立且加强代码审计，以避免一些因编程语言带来的安全风险。&lt;/p&gt;
&lt;h4 id=&#34;交易隐私&#34;&gt;交易隐私&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;采用了通道机制来划分整个系统为多个子区块链（账本），只有加入通道的节点才能查看和存储交易信息，但排序节点可以看到。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那有什么办法在通道中保障一些私有数据的隐私呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;提供了一种存储私有数据的方式，使通道中的节点可以选择特定的数据分享对象（节点）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/fabric_security_private_data.png&#34; alt=&#34;fabric_security_private_data&#34;&gt;&lt;/p&gt;
&lt;p&gt;在这种机制下，真实的数据会通过&lt;code&gt;gossip&lt;/code&gt;协议发送到指定的节点，数据存放私有数据库中，只有授权节点可以通过链码进行访问，因为这个过程并没有涉及到排序服务，所以排序节点也无法获取。&lt;/p&gt;
&lt;p&gt;而在系统内传播、排序与写入账本的数据是经过哈希加密的版本，因此交易仍然可以被各个节点验证，但因为哈希的特性，可以有效保护原数据不被泄漏。&lt;/p&gt;
&lt;p&gt;但值得注意的是，如果在背书节点模拟交易过程中需要使用到数据，那需要采取额外的机制来保障数据对于背书节点的可读性和对其他节点的不可见性（如非对称加密等）。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;网络搭建和安全体系分析了，接下来将会开始学习&lt;code&gt;Go&lt;/code&gt;和链码的开发，通过项目实战来对其进行深入了解学习！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.hku.hk/index.php/programmes/course-offered?infile=2019/fite3011.html&#34;&gt;FITE3011 Distributed Ledger and Blockchain&lt;/a&gt;, &lt;em&gt;Allen Au，HKU&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>Hyperledger Fabric系统架构详解</title>
      <link>https://www.pseudoyu.com/zh/2021/03/20/blockchain_hyperledger_fabric_structure/</link>
      <pubDate>Sat, 20 Mar 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/20/blockchain_hyperledger_fabric_structure/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;因为毕业Case Study的项目主要是基于&lt;code&gt;Ethereum&lt;/code&gt;公链，也没有面向企业的应用场景，所以之前对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;的了解大多只是停留在它的权限管理机制、通道、灵活的智能合约编写等几个特色的概念，对它的架构、各个节点的角色、运行机制等都是一知半解。最近在上HKU的&lt;code&gt;&amp;lt;FITE3011 Distributed Ledger and Blockchain&amp;gt;&lt;/code&gt;课程，教授对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;的工作原理、网络搭建及链码相关的知识做了很详细的讲解，受益匪浅，通过本文来梳理一下，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;hyperledger概述&#34;&gt;Hyperledger概述&lt;/h2&gt;
&lt;p&gt;要学习&lt;code&gt;Hyperledger Fabric&lt;/code&gt;，先来看看它的母项目&lt;code&gt;Hyperledger&lt;/code&gt;是什么。&lt;/p&gt;
&lt;p&gt;企业级应用有较复杂的业务逻辑和参与者角色划分，对于业务执行效率、安全性要求很高，并且针对常见的如支付、数据/信息交易等场景，隐私保护也是重中之重，因此，常见的比特币、以太坊等公链并不符合大部分企业应用需求。但是区块链的分布式、不可篡改的历史账本等特性在溯源、跨境电商等场景中又能够避免因各个国家/地区法律法规、货币等造成的复杂操作流程，大大提高效率。因此，针对企业的联盟链也在不断发展。&lt;/p&gt;
&lt;p&gt;联盟链严格意义上并不是真正的“去中心化”，它通过引入了权限管理机制（结合企业在现实业务中的角色）来弱化对节点作恶的预防机制，从而能提高效率、应对复杂的业务逻辑。&lt;/p&gt;
&lt;p&gt;其中，&lt;code&gt;Hyperledger&lt;/code&gt;是由Linux基金会维护的一组专注于跨行业分布式技术的开源项目，旨在创建企业级、开源、分布式的分类框架和代码库来支持业务用例，提供中立、开放和社区驱动的基础设施；建立技术社区并推广，开发区块链和共享账本概念验证、使用案例、试验和部署；建立行业标准，鼓励更多企业参与到分布式账本技术的建设和应用中来，形成一个开放的生态体系；教育公众关于区块链科技的市场机会。&lt;/p&gt;
&lt;h3 id=&#34;设计理念&#34;&gt;设计理念&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_design_philosophy.png&#34; alt=&#34;hyperledger_design_philosophy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Hyperledger&lt;/code&gt;有如下几个核心设计理念：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;它针对企业具体的业务场景提升效率，并且对溯源等场景有着独特优势，每个企业都可以针对自己的场景维护独立的&lt;code&gt;Hyperledger&lt;/code&gt;项目，因此，它不需要像公链一样通过数字货币来激励用户参与区块链系统。&lt;/li&gt;
&lt;li&gt;企业的应用场景较为复杂，往往Hyperledger只是在其中参与了某个或某些环节，因此与其他现有系统的交互必不可少，因此Hyperledger在设计上注重配备完整的API以供其他系统调用与交互。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hyperledger&lt;/code&gt;的框架结构是模块化、可拓展，企业可以根据具体的业务需求选择不同的模块，避免复杂的业务逻辑和臃肿的系统。&lt;/li&gt;
&lt;li&gt;企业应用的安全性是重中之重，尤其是许多应用场景牵扯到高价值交易或敏感数据，因此提供了很多机制来保障安全性（如&lt;code&gt;Fabric&lt;/code&gt;的通道机制等）&lt;/li&gt;
&lt;li&gt;除了与现有的系统交互外，企业未来的区块链应用中还可能会和很多不同的区块链网络进行交互，因此大部分智能合约/应用应该具备跨区块链网络的可移植性，以形成更复杂和强大的网络。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_family.png&#34; alt=&#34;hyperledger_family&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;框架&#34;&gt;框架&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Hyperledger&lt;/code&gt;下有如下几个项目，其中&lt;code&gt;Fabric&lt;/code&gt;目前应用最为广泛，本文也将主要介绍&lt;code&gt;Fabric&lt;/code&gt;区块链网络&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Burrow&lt;/li&gt;
&lt;li&gt;Fabric&lt;/li&gt;
&lt;li&gt;Grid&lt;/li&gt;
&lt;li&gt;Indy&lt;/li&gt;
&lt;li&gt;Iroha&lt;/li&gt;
&lt;li&gt;Sawtooth&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;工具&#34;&gt;工具&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Hyperledger Cello&lt;/code&gt;。主要用于更方便地搭建和管理区块链服务，降低项目框架部署、维护的复杂度；可以用来搭建区块链BaaS平台；可以通过Dashboard来创建和管理区块链，技术人员可以更方便地进行开发和部署；可以将SaaS部署模型引入区块链系统，帮助企业进一步开发框架。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Hyperledger Explorer&lt;/code&gt;。是一个可视化区块链的操作工具，可以用于创建对用户友好的Web应用程序；是首个&lt;code&gt;Hyperledger&lt;/code&gt;的区块链浏览器，用户可以查看/调用/部署/查询交易、网络、智能合约、存储等信息。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hyperledger-fabric&#34;&gt;Hyperledger Fabric&lt;/h2&gt;
&lt;p&gt;我们着重来讲讲其中应用最广泛的&lt;code&gt;Fabric&lt;/code&gt;项目，它是由Linux基金会维护的一个模块化、可拓展的区块链联盟链项目，不依赖任何加密货币，它对有着共同目标（业务需求）但彼此不完全信息的实体之间的业务提供了保护，例如跨境电商、资金交易、溯源等。&lt;/p&gt;
&lt;h3 id=&#34;架构&#34;&gt;架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ethereum_architecture_simple.png&#34; alt=&#34;ethereum_architecture_simple&#34;&gt;&lt;/p&gt;
&lt;p&gt;在大部分公链中，架构为&lt;code&gt;Order - Execute - Validate - Update State&lt;/code&gt;。如比特币区块链中，如果有一个新交易，会先采用PoW机制对Block进行排序，然后比特币网络中的每个节点逐个进行验证，最后更新状态。因为需要依序进行验证，这种方式决定了其执行效率相对较低。&lt;/p&gt;
&lt;p&gt;而&lt;code&gt;Fabric&lt;/code&gt;采用了&lt;code&gt;Execute - Order - Validate - Update State&lt;/code&gt;架构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_architecture.png&#34; alt=&#34;hyperledger_fabric_architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;收到一笔新的交易后，首先提交至背书节点本地模拟交易执行（并背书），再将已背书交易排序并广播，各个节点对交易进行验证后更新状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_architecture_complete.png&#34; alt=&#34;hyperledger_fabric_architecture_complete&#34;&gt;&lt;/p&gt;
&lt;p&gt;正如上述联盟链特性中所述，&lt;code&gt;Fabric&lt;/code&gt;网络的加入需要得到许可（身份验证），&lt;code&gt;Fabric&lt;/code&gt;网路中的每个节点都有自己的身份。&lt;/p&gt;
&lt;p&gt;总的来说，&lt;code&gt;Fabric&lt;/code&gt;通过模块化、可插拔的架构来支持企业的复杂业务场景，通过身份验证（绑定现实身份）来弱化节点作恶，使用通道机制大大提升了系统的安全性和隐私保护。&lt;/p&gt;
&lt;h4 id=&#34;msp成员服务提供商&#34;&gt;MSP成员服务提供商&lt;/h4&gt;
&lt;p&gt;那么，参与&lt;code&gt;Fabric&lt;/code&gt;网络的身份是怎样管理的呢？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;有一个MSP(Membership Service Provider)成员管理提供商，它主要用来管理CA证书来验证哪些成员是可信任的。&lt;code&gt;Fabric CA&lt;/code&gt;模块是独立的，可以管理证书服务，也可以允许第三方CA的接入，大大拓展的系统的应用范围。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_ca_structure.png&#34; alt=&#34;hyperledger_fabric_ca_structure&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，&lt;code&gt;Fabric CA&lt;/code&gt;提供了客户端和SDK两种方式来和CA进行交互，每个&lt;code&gt;Fabric CA&lt;/code&gt;都有一个根CA或中间CA，为了进一步提高CA的安全性，可以采用集群来搭建中间CA。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_ca_hierarchy.png&#34; alt=&#34;hyperledger_fabric_ca_hierarchy&#34;&gt;&lt;/p&gt;
&lt;p&gt;更具体一点看CA的层级体系，一般是采用根CA、业务CA和用户CA三层树结构，所有的下层CA会继承上层CA的信任体系。根CA用来签发业务CA，业务CA用来签发具体的用户CA（身份认证CA、交易签名、安全通讯CA等）&lt;/p&gt;
&lt;h4 id=&#34;通道&#34;&gt;通道&lt;/h4&gt;
&lt;p&gt;上文提到&lt;code&gt;Fabric&lt;/code&gt;用Channel通道机制来保障交易的安全和隐私性，本质上每一个通道就是一个独立的账本，也是一个独立的区块链，有着不同的世界状态，网络中的一个节点可以同时加入多个通道。这种机制可以很好地划分不同的业务场景，也不用担心交易信息泄漏问题。&lt;/p&gt;
&lt;h4 id=&#34;链码&#34;&gt;链码&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;也有类似以太坊的智能合约，称为Chaincode链码，智能合约使外部的应用程序可以和&lt;code&gt;Fabric&lt;/code&gt;网络中的账本进行交互。不同于&lt;code&gt;Ethereum&lt;/code&gt;，&lt;code&gt;Fabric&lt;/code&gt;使用Docker而不是特定的虚拟机来存放链码，提供了一个安全、轻便的语言执行环境。&lt;/p&gt;
&lt;p&gt;链码主要分成系统链码和用户链码两种，系统链码嵌入在系统内，提供对系统进行配置、管理的支持；而用户链码则是运行在单独的Docker容器中，提供对上层应用的支持，用户通过链码相关的API编写用户链码，即可对账本中状态进行更新操作。&lt;/p&gt;
&lt;p&gt;链码经过安装和实例化操作后即可被调用，在安装的时候需要指定具体安装到哪个Peer节点（有的节点可以没有链码），实例化时还需要指定通道及背书策略。&lt;/p&gt;
&lt;p&gt;链码之间也可以相互调用，从而创建更灵活的应用逻辑。&lt;/p&gt;
&lt;h4 id=&#34;共识机制&#34;&gt;共识机制&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;中广义的共识机制包括背书、排序和验证三个环节，狭义的共识是指排序，&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;区块链网络中，不同参与者之间交易必须按照发生的顺序写到分布式账本中，依赖共识机制，主要有三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SOLO（只限于开发）&lt;/li&gt;
&lt;li&gt;Kafka（一种消息平台）&lt;/li&gt;
&lt;li&gt;Raft（相比Kafka更中心化）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;网络协议&#34;&gt;网络协议&lt;/h4&gt;
&lt;p&gt;那&lt;code&gt;Fabric&lt;/code&gt;网络中各个节点的状态分发又是怎么进行的呢？&lt;/p&gt;
&lt;p&gt;外界的客户端是通过&lt;code&gt;gRPC&lt;/code&gt;来对&lt;code&gt;Fabric&lt;/code&gt;网络中的各个节点进行远程调用，而&lt;code&gt;P2P&lt;/code&gt;网络中各个节点之间的同步是通过&lt;code&gt;Gossip&lt;/code&gt;协议来进行的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gossip&lt;/code&gt;协议主要是用于网络中多个节点之间的数据交换，比较容易实现且容错率很高，原理就是数据发送一方从网络中随机选取若干个节点发送过去，等几个节点接收到这些数据后再随机发送给除了发送方外的若干节点，不断重复，最终所有节点达成一致（复杂度为LogN）。&lt;/p&gt;
&lt;h4 id=&#34;分布式账本&#34;&gt;分布式账本&lt;/h4&gt;
&lt;p&gt;最终所有的交易都会记录到分布式账本中，这也是区块链诸多特性的核心。&lt;code&gt;Fabric&lt;/code&gt;中交易可以存储相关业务信息，区块是一组排列后的交易集合，将区块通过密码算法链接起来就是区块链。分布式账本主要记录世界状态（最新的分布式账本状态，一般使用&lt;code&gt;CouchDB&lt;/code&gt;以方便查询）和事务日志（世界状态的更新历史，记录区块链结构，使用&lt;code&gt;LevelDB&lt;/code&gt;），对账本的每个操作都会记录在日志中，不可篡改。&lt;/p&gt;
&lt;h4 id=&#34;应用编程接口&#34;&gt;应用编程接口&lt;/h4&gt;
&lt;p&gt;对于基于&lt;code&gt;Fabric&lt;/code&gt;的应用，则主要提供了SDK开发工具包和CLI命令行两种方式进行交互。&lt;/p&gt;
&lt;h3 id=&#34;fabric区块链核心角色&#34;&gt;Fabric区块链核心角色&lt;/h3&gt;
&lt;p&gt;首先要提的是&lt;code&gt;Fabric&lt;/code&gt;网络中的角色都是逻辑角色，比如Peer节点A可能既是排序节点，也可能在某些业务中是背书节点，而一个角色也不仅仅由单一节点担任。&lt;/p&gt;
&lt;p&gt;接下来介绍一下各个角色的作用和职能。&lt;/p&gt;
&lt;p&gt;Clients客户端主要给交易签名，提交交易Proposal给背书节点，接收已经背书后的交易广播给排序节点；背书节点则是本地模拟执行交易Proposal验证交易（策略由Chaincode制定），签名并返回已背书交易；排序节点则将交易打包为block然后广播至各个节点，不参与交易的执行和验证，多个排序节点可以组成OSN；所有的节点都维护区块链账本。&lt;/p&gt;
&lt;h3 id=&#34;优势总结&#34;&gt;优势总结&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Fabric&lt;/code&gt;通过将企业应用的各个复杂环节分配到各个逻辑角色节点（背书、排序等），不需要所有节点都承担如排序这样资源消耗较大的操作，消除了网络瓶颈；分配了角色后某些交易只在特定的节点部署和执行，且可以并发执行，大大提升效率和安全性，也隐藏了一些商业逻辑；因此，可以根据不同的业务需要来形成多种灵活的分配方案，极大增强了系统的拓展性。&lt;/p&gt;
&lt;p&gt;将共识机制、权限管理、加密机制、账本等模块都设置为可插拔，且不同的链码可以设置不同的背书策略，信任机制更加灵活，这样可以根据业务需要设置自己的高效系统。&lt;/p&gt;
&lt;p&gt;成员身份管理的&lt;code&gt;Fabric CA&lt;/code&gt;作为单独的项目，能够提供更多功能，也能够与很多第三方CA直接进行接入和交互，功能更强大，适合企业复杂的场景。&lt;/p&gt;
&lt;p&gt;多通道的特性是不同通道之间的数据彼此隔离，提高了安全性和隐私保护。&lt;/p&gt;
&lt;p&gt;链码支持如&lt;code&gt;Java&lt;/code&gt;、&lt;code&gt;Go&lt;/code&gt;、&lt;code&gt;Node&lt;/code&gt;等不同的编程语言，更加灵活，也支持更多第三方拓展应用，降低了业务迁移和维护成本。&lt;/p&gt;
&lt;h3 id=&#34;fabric应用开发及交互&#34;&gt;Fabric应用开发及交互&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_application_interact.png&#34; alt=&#34;hyperledger_fabric_application_interact&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图就是作为一个区块链开发者在应用&lt;code&gt;Fabric&lt;/code&gt;区块链中的开发和交互流程。&lt;/p&gt;
&lt;p&gt;开发者主要负责开发应用和智能合约（链码），应用通过SDK与智能合约进行交互，而智能合约的逻辑可以对账本进行&lt;code&gt;get&lt;/code&gt;、&lt;code&gt;put&lt;/code&gt;、&lt;code&gt;delete&lt;/code&gt;等操作。&lt;/p&gt;
&lt;h3 id=&#34;fabric工作流程&#34;&gt;Fabric工作流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_transaction_flow.png&#34; alt=&#34;hyperledger_fabric_transaction_flow&#34;&gt;&lt;/p&gt;
&lt;p&gt;接下来通过一个完整的交易流来梳理一下&lt;code&gt;Fabric&lt;/code&gt;网络的工作原理
0. 在所有操作之前，需要向CA获取合法身份并且指定通道&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，Client提交交易Proposal（含自己的签名）至背书节点&lt;/li&gt;
&lt;li&gt;背书节点接收到交易Proposal后用本地状态模拟执行，对交易进行背书、签名并返回（其中包含Read-Write Set、签名等）&lt;/li&gt;
&lt;li&gt;Client收集到足够的背书后（策略由Chaincode制定，如图中示例为得到2个背书）提交已背书交易至排序节点（OSN）&lt;/li&gt;
&lt;li&gt;排序节点将交易打包成blocks，排序（不执行或验证交易正确性）并广播至所有节点&lt;/li&gt;
&lt;li&gt;所有节点对新blocks进行验证并提交至账本&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hyperledger_fabric_processes.png&#34; alt=&#34;hyperledger_fabric_processes&#34;&gt;&lt;/p&gt;
&lt;p&gt;接下来对每个环节进行一些详细的拆解&lt;/p&gt;
&lt;h4 id=&#34;执行背书环节&#34;&gt;执行/背书环节&lt;/h4&gt;
&lt;p&gt;Client提交交易proposal后，背书节点会首先核对Client的签名，用本地状态模拟执行，对交易进行签名和Read-Write Set回Clients，R-W Sets主要包含&lt;code&gt;key&lt;/code&gt;, &lt;code&gt;version&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt;三个属性，Read-Set包含交易执行中读取的所有变量和其&lt;code&gt;version&lt;/code&gt;，对账本进行write操作的话&lt;code&gt;version&lt;/code&gt;会产生变化，Write-Set包含所有被编辑的变量及其新值。&lt;/p&gt;
&lt;p&gt;背书节点在执行交易时值根据本地区块链的状态检查链码是否正确，执行并返回。&lt;/p&gt;
&lt;p&gt;Fabric支持多种背书策略，Client在提交至排序节点前会验证是否满足背书要求，值得注意的是如果只做了查询账本操作，Client不会提交至OSN。&lt;/p&gt;
&lt;p&gt;上文所提到的交易proposal主要含括链码、链码的输入值、Client的签名，而背书节点返回至Client的的信息则包括返回值、模拟执行结果的R-W Set以及背书节点的签名，组合起来则是已背书节点。&lt;/p&gt;
&lt;p&gt;背书是相关组织对交易的认可，即相关节点对交易进行签名。对于一个链码交易来说，背书策略是在链码实例化的时候指定的，一笔有效交易必须是背书策略相关组织签名才能生效，本质上&lt;code&gt;Fabric&lt;/code&gt;区块链中的交易验证是基于对背书节点的信任，这也是称&lt;code&gt;Fabric&lt;/code&gt;并不是严格意义上的去中心化的原因之一。&lt;/p&gt;
&lt;p&gt;以下是一个简单的链码执行示例&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;SimpleChaincode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;InitLedger&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;contractapi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;TransactionContextInterface&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Test Product&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Just a test product to make sure chaincode is running&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CreatedBy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;admin&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ProductId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

    &lt;span class=&#34;nx&#34;&gt;productAsBytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Marshal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;GetStub&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;PutState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;productAsBytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在这个简单示例中，链码的主要操作就是更新了&lt;code&gt;key-value&lt;/code&gt;值，经过了这个操作后，&lt;code&gt;version&lt;/code&gt;会变化。&lt;/p&gt;
&lt;p&gt;执行后返回的R-W Set为&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Product&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Test Product&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Just a test product to make sure chaincode is running&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CreatedBy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;admin&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ProductId&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;的Json形式&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;排序环节&#34;&gt;排序环节&lt;/h4&gt;
&lt;p&gt;Client提交已背书交易至排序节点（排序节点可通过一些共识策略组成OSN），排序节点接收到交易后，会打包成blocks并按照配置中的规则进行排序，在此过程中，只执行排序操作，而不进行任何执行或验证，排序完成后发送至所有节点。&lt;/p&gt;
&lt;p&gt;排序服务用来对全网交易达成一致，只负责对交易顺序达成一致，避免了整个网络瓶颈，更容易横向拓展以提升网络效率，目前支持&lt;code&gt;Kafka&lt;/code&gt;和&lt;code&gt;Raft&lt;/code&gt;两种，&lt;code&gt;Fabric&lt;/code&gt;区块链网络的统一/完整性依赖于排序节点的一致性。&lt;/p&gt;
&lt;p&gt;Raft共识机制属于非拜占庭共识机制，使用了领导者和跟随者（Leader和Follower）模型，当一个Leader被选出，日志信息会从Leader向Follower单向复制，更容易管理，在设计上允许所有节点都可以称为Orderer节点，相比Kafka更中心化，其实也允许采用PBFT共识机制，但是性能往往很差。&lt;/p&gt;
&lt;h4 id=&#34;验证环节&#34;&gt;验证环节&lt;/h4&gt;
&lt;p&gt;当节点接收到由排序节点发送来的区块时，会对区块中的所有交易进行验证并标记是否可信，主要验证两个方面：1.是否满足背书策略。2.交易结构的合法性，是否有状态冲突，如Read-Set中的&lt;code&gt;version&lt;/code&gt;是否一致等。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;架构的梳理了，虽然取舍了部分去中心化的理念，但是作为一个面向企业应用的开源联盟链，它鼓励了更多企业参与到分布式账本技术的建设和应用中来，现在国内也有很多联盟链的自研平台，如蚂蚁链、趣链等，相信未来会有更多企业参与到这个开放的生态体系！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.hku.hk/index.php/programmes/course-offered?infile=2019/fite3011.html&#34;&gt;FITE3011 Distributed Ledger and Blockchain&lt;/a&gt;, &lt;em&gt;Allen Au，HKU&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yingpingzhang/enterprise_blockchain_tutorial&#34;&gt;企业级区块链实战教程&lt;/a&gt;，&lt;em&gt;张应平&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 3 Clustering</title>
      <link>https://www.pseudoyu.com/zh/2021/03/18/comp7103_topic3/</link>
      <pubDate>Thu, 18 Mar 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/18/comp7103_topic3/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-3-clustering&#34;&gt;Topic 3 Clustering&lt;/h2&gt;
&lt;h3 id=&#34;cluster-analysis&#34;&gt;Cluster Analysis&lt;/h3&gt;
&lt;p&gt;Finding groups of objects such that the objects in a group will be similar (or related) to one another and different from (or unrelated to) the objects in other groups&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/cluster_analysis.png&#34; alt=&#34;cluster_analysis&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;application&#34;&gt;Application&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Understanding
&lt;ul&gt;
&lt;li&gt;Group related documents for browsing, group genes and proteins that have similar functionality, or group stocks with similar price fluctuations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Summarization
&lt;ul&gt;
&lt;li&gt;Reduce size of large data sets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;types-of-clusterings&#34;&gt;Types of Clusterings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partitional Clustering
&lt;ul&gt;
&lt;li&gt;A division data objects into non-overlapping subsets (clusters) such that each data object is in exactly one subset
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/partitional_clustering.png&#34; alt=&#34;partitional_clustering&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hierarchical clustering
&lt;ul&gt;
&lt;li&gt;A set of nested clusters organized as a hierarchical tree
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hierarchical_clustering.png&#34; alt=&#34;hierarchical_clustering&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other Distinctions Between Sets of Clusters
&lt;ul&gt;
&lt;li&gt;Exclusive versus non-exclusive
&lt;ul&gt;
&lt;li&gt;In non-exclusive clusterings, points may belong to multiple clusters&lt;/li&gt;
&lt;li&gt;Can represent multiple classes or &amp;lsquo;border&amp;rsquo; points&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fuzzy versus non-fuzzy
&lt;ul&gt;
&lt;li&gt;In fuzzy clustering, a point belongs to every cluster with some weight between 0 and 1&lt;/li&gt;
&lt;li&gt;Weights must sum to 1&lt;/li&gt;
&lt;li&gt;Probabilistic clustering has similar characteristics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Partial versus complete
&lt;ul&gt;
&lt;li&gt;In some cases, we only want to cluster some of the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Heterogeneous versus homogeneous
&lt;ul&gt;
&lt;li&gt;Cluster of widely different sizes, shapes, and densities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;well-separated-clusters&#34;&gt;Well-separated clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of points such that any point in a cluster is closer (or more similar) to every other point in the cluster than to any point not in the cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/wellseparated_clusters.png&#34; alt=&#34;wellseparated_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;center-based-clusters&#34;&gt;Center-based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of objects such that an object in a cluster is closer (more similar) to the “center” of a cluster, than to the center of any other cluster&lt;/p&gt;
&lt;p&gt;The center of a cluster is often a centroid, the average of all the points in the cluster, or a medoid, the most “representative” point of a cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/center_based_clusters.png&#34; alt=&#34;center_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;contiguity-based-clusters&#34;&gt;Contiguity-Based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a set of points such that a point in a cluster is closer (or more similar) to one or more other points in the cluster than to any point not in the cluster&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/contiguity_based_clusters.png&#34; alt=&#34;contiguity_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;density-based-clusters&#34;&gt;Density-based clusters&lt;/h4&gt;
&lt;p&gt;A cluster is a dense region of points, which is separated by low-density regions, from other regions of high density&lt;/p&gt;
&lt;p&gt;Used when the clusters are irregular or intertwined, and when noise and outliers are present&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/density_based_clusters.png&#34; alt=&#34;density_based_clusters&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;conceptual-clusters&#34;&gt;Conceptual Clusters&lt;/h4&gt;
&lt;p&gt;Finds clusters that share some common property or represent a particular concept&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/conceptual_clusters.png&#34; alt=&#34;conceptual_clusters&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-means&#34;&gt;K-means&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Input
&lt;ul&gt;
&lt;li&gt;integer k&amp;gt;0, set S of points in the euclidean space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Output
&lt;ul&gt;
&lt;li&gt;A (partitional) clustering of S&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Step&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Select k points in S as the initial centroids&lt;/li&gt;
&lt;li&gt;Repeat until the centroids do not change
&lt;ul&gt;
&lt;li&gt;Form k clusters by assigning points to the closest centroids&lt;/li&gt;
&lt;li&gt;For each cluster recompute its centroid&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Feature&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initial centroids are often chosen randomly&lt;/li&gt;
&lt;li&gt;Centroids are often the mean of the points in the cluster&lt;/li&gt;
&lt;li&gt;&amp;lsquo;Closeness&amp;rsquo; is measured by Euclidean distance, cosine similarity, correlation, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;importance-of-choosing-initial-centroids&#34;&gt;Importance of Choosing Initial Centroids&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids.png&#34; alt=&#34;choosing_Initial_centroids&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids_2.png&#34; alt=&#34;choosing_Initial_centroids_2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/choosing_Initial_centroids_3.png&#34; alt=&#34;choosing_Initial_centroids_3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;evaluating-k-means-clusterings&#34;&gt;Evaluating K-means Clusterings&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Most common measure is Sum of Squared Error (SSE)
&lt;ul&gt;
&lt;li&gt;Given two clusterings, we can choose the one with smallest error&lt;/li&gt;
&lt;li&gt;Decreasing K might decrease SSE&lt;/li&gt;
&lt;li&gt;However, good clusterings with small K might have a lower SSE than poor clusterings with higher K&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;k-means-always-terminates&#34;&gt;K-Means Always Terminates&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Theorem
&lt;ul&gt;
&lt;li&gt;K-means with Euclidean distance as distance always terminates&lt;/li&gt;
&lt;li&gt;Proof follows from the following lemmas&lt;/li&gt;
&lt;li&gt;We cannot obtain the same clustering more than once, otherwise we get the same SSE value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 1
&lt;ul&gt;
&lt;li&gt;The point y that minimizes the SSE in a cluster C is the mean of all points in C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 2
&lt;ul&gt;
&lt;li&gt;SSE strictly decreases.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lemma 3&lt;/li&gt;
&lt;li&gt;The total number of possible clusterings is finite (&amp;lt; n^k).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;solutions-to-initial-centroids-problem&#34;&gt;Solutions to Initial Centroids Problem&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Multiple runs (helps but low success probability)&lt;/li&gt;
&lt;li&gt;Sample and use hierarchical clustering to determine initial centroids&lt;/li&gt;
&lt;li&gt;Select more than k initial centroids and then select among these initial centroids&lt;/li&gt;
&lt;li&gt;Postprocessing&lt;/li&gt;
&lt;li&gt;K-Means++&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;handling-empty-clusters&#34;&gt;Handling Empty Clusters&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Basic K-means algorithm can yield less than k clusters (so called empty clusters)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pick the points that contributes most to SSE and move them to empty cluster&lt;/li&gt;
&lt;li&gt;Pick the points from the cluster with the highest SSE&lt;/li&gt;
&lt;li&gt;If there are several empty clusters, the above can be repeated several times&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;updating-centers-incrementally&#34;&gt;Updating Centers Incrementally&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In the basic K-means algorithm, centroids are updated after all points are assigned to a centroid&lt;/li&gt;
&lt;li&gt;An alternative is to update the centroids after each assignment (incremental approach)&lt;/li&gt;
&lt;li&gt;More precisely, let C1 ,C2 ,&amp;hellip;,C k be the current clusters. Reassign all points one by one to the best cluster. Let p in C i be the current point and suppose we re-assign it to Cj . Then, after that, recompute the centroid of C i and Cj
&lt;ul&gt;
&lt;li&gt;Never get an empty cluster&lt;/li&gt;
&lt;li&gt;Introduces an order dependency&lt;/li&gt;
&lt;li&gt;More expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pre-processing-and-post-processing&#34;&gt;Pre-processing and Post-processing&lt;/h4&gt;
&lt;p&gt;Pre-processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalize the data&lt;/li&gt;
&lt;li&gt;Eliminate outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Post-processing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Eliminate small clusters that may represent outliers&lt;/li&gt;
&lt;li&gt;Split &amp;lsquo;loose&amp;rsquo; clusters, i.e., clusters with relatively high SSE&lt;/li&gt;
&lt;li&gt;Merge clusters that are ‘close’ and that have relatively low SSE&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;limitations-of-k-means&#34;&gt;Limitations of K-means&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means has problems when clusters are of differing
&lt;ul&gt;
&lt;li&gt;Sizes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations.png&#34; alt=&#34;kmeans_limitations&#34;&gt;&lt;/li&gt;
&lt;li&gt;Densities
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations_density.png&#34; alt=&#34;kmeans_limitations_density&#34;&gt;&lt;/li&gt;
&lt;li&gt;Non-globular shapes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_limitations_globular.png&#34; alt=&#34;kmeans_limitations_globular&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;K-means has problems when the data contains outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;overcoming-k-means-limitations&#34;&gt;Overcoming K-means Limitations&lt;/h4&gt;
&lt;p&gt;Use many clusters, find parts of clusters, but need to put together&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overcome_kmeans_limitations_1.png&#34; alt=&#34;overcome_kmeans_limitations_1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overcome_kmeans_limitations_2.png&#34; alt=&#34;overcome_kmeans_limitations_2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hierarchical-clustering&#34;&gt;Hierarchical clustering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Produces a set of nested clusters organized as a hierarchical tree&lt;/li&gt;
&lt;li&gt;Can be visualized as a dendrogram
&lt;ul&gt;
&lt;li&gt;A tree like diagram that records the sequences of merges or splits
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/hierarchical_clustering_dendrogram.png&#34; alt=&#34;hierarchical_clustering_dendrogram&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;strengths-of-hierarchical-clustering&#34;&gt;Strengths of Hierarchical Clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Do not have to assume any particular number of clusters
&lt;ul&gt;
&lt;li&gt;Any desired number of clusters can be obtained by ‘cutting’ the dendogram at the proper level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;They may correspond to meaningful taxonomies
&lt;ul&gt;
&lt;li&gt;Example in biological sciences (e.g., animal kingdom, phylogeny reconstruction, …)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;two-main-types-of-hierarchical-clustering&#34;&gt;Two main types of hierarchical clustering&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Agglomerative
&lt;ul&gt;
&lt;li&gt;Start with the points as individual clusters&lt;/li&gt;
&lt;li&gt;At each step, merge the closest pair of clusters until only one cluster (or k clusters) left&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Divisive
&lt;ul&gt;
&lt;li&gt;Start with one, all-inclusive cluster&lt;/li&gt;
&lt;li&gt;At each step, split a cluster until each cluster contains a point (or there are k clusters)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Traditional hierarchical algorithms use a similarity or distance matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Merge or split one cluster at a time&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;agglomerative-clustering-algorithm&#34;&gt;Agglomerative Clustering Algorithm&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Most popular hierarchical clustering technique&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let each data point be a cluster&lt;/li&gt;
&lt;li&gt;Compute the distance matrix n x n&lt;/li&gt;
&lt;li&gt;Repeat
&lt;ul&gt;
&lt;li&gt;Merge the two closest clusters&lt;/li&gt;
&lt;li&gt;Update distance matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Until only a single cluster remains&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Procedure&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Start with clusters of individual points and a distance matrix n x n
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_1.png&#34; alt=&#34;agglomerative_clustering_algorithm_1&#34;&gt;&lt;/li&gt;
&lt;li&gt;After some merging steps, we have some clusters
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_2.png&#34; alt=&#34;agglomerative_clustering_algorithm_2&#34;&gt;&lt;/li&gt;
&lt;li&gt;We want to merge the two closest clusters (C2 and C5) and update the distance matrix
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_3.png&#34; alt=&#34;agglomerative_clustering_algorithm_3&#34;&gt;&lt;/li&gt;
&lt;li&gt;The question is “How do we update the distance matrix
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/agglomerative_clustering_algorithm_4.png&#34; alt=&#34;agglomerative_clustering_algorithm_4&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;how-to-define-inter-cluster-similarity&#34;&gt;How to Define Inter-Cluster Similarity&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;MIN
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_1.png&#34; alt=&#34;inter_cluster_similarity_1&#34;&gt;&lt;/li&gt;
&lt;li&gt;MAX
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_2.png&#34; alt=&#34;inter_cluster_similarity_2&#34;&gt;&lt;/li&gt;
&lt;li&gt;Group Average
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_3.png&#34; alt=&#34;inter_cluster_similarity_3&#34;&gt;&lt;/li&gt;
&lt;li&gt;Distance Between Centroids
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/inter_cluster_similarity_4.png&#34; alt=&#34;inter_cluster_similarity_4&#34;&gt;&lt;/li&gt;
&lt;li&gt;Other methods driven by an objective function
&lt;ul&gt;
&lt;li&gt;Ward’s Method uses squared error&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;problems-and-limitations&#34;&gt;Problems and Limitations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Once a decision is made to combine two clusters, it cannot be undone&lt;/li&gt;
&lt;li&gt;No objective function is directly minimized&lt;/li&gt;
&lt;li&gt;Different schemes have problems with one or more of the following
&lt;ul&gt;
&lt;li&gt;Sensitivity to noise and outliers&lt;/li&gt;
&lt;li&gt;Difficulty handling different sized clusters and convex shapes&lt;/li&gt;
&lt;li&gt;Breaking large clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cluster-validity&#34;&gt;Cluster Validity&lt;/h3&gt;
&lt;p&gt;Numerical measures that are applied to judge various aspects of cluster validity, are classified into the following three types&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;External Index
&lt;ul&gt;
&lt;li&gt;Used to measure the extent to which cluster labels match externally supplied class labels
&lt;ul&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Internal Index
&lt;ul&gt;
&lt;li&gt;Used to measure the goodness of a clustering structure without respect to external information
&lt;ul&gt;
&lt;li&gt;Sum of Squared Error (SSE)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relative Index
&lt;ul&gt;
&lt;li&gt;To compare two different clusterings or clusters
&lt;ul&gt;
&lt;li&gt;An external or internal index is used for this function, e.g., SSE or entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;internal-measures-sse&#34;&gt;Internal Measures: SSE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Clusters in more complicated figures aren’t well separated&lt;/li&gt;
&lt;li&gt;SSE is good for comparing two clusterings or two clusters (average SSE)&lt;/li&gt;
&lt;li&gt;Can also be used to estimate the number of clusters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/internal_measures_SSE.png&#34; alt=&#34;internal_measures_SSE&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;external-measures-of-cluster-validity-entropy&#34;&gt;External Measures of Cluster Validity: Entropy&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Definition: Entropy
&lt;ul&gt;
&lt;li&gt;Entropy measure how uncertain is an event, the larger the entropy the more uncertain is the event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/external_measures_of_cluster_validity_Entropy.png&#34; alt=&#34;external_measures_of_cluster_validity_Entropy&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&amp;ldquo;The validation of clustering structures is the most difficult and frustrating part of cluster analysis. Without a strong effort in this direction, cluster analysis will remain a black art accessible only to those true believers who have experience and great courage.&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;k-means-1&#34;&gt;K-means++&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Initialize the centroids as in Algorithm 1&lt;/li&gt;
&lt;li&gt;Run K-means algorithm to improve the clustering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kmeans_plus_plus_algorithm1.png&#34; alt=&#34;kmeans_plus_plus_algorithm1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-comparison&#34;&gt;Algorithm Comparison&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K-means
&lt;ul&gt;
&lt;li&gt;No guarantees on the quality of the solution&lt;/li&gt;
&lt;li&gt;It always terminates&lt;/li&gt;
&lt;li&gt;Running time could be exponential but it is OK in practice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;K-means++
&lt;ul&gt;
&lt;li&gt;It always terminates&lt;/li&gt;
&lt;li&gt;O(log k)-approximation on the quality of the solution&lt;/li&gt;
&lt;li&gt;In practice the advantage is noticeable for large k&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 4 Top-k</title>
      <link>https://www.pseudoyu.com/zh/2021/03/06/comp7801_topic4/</link>
      <pubDate>Sat, 06 Mar 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/03/06/comp7801_topic4/</guid>
      
        <description>&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;multidimensional-data&#34;&gt;Multidimensional Data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Flat relational tables&lt;/li&gt;
&lt;li&gt;Multimedia feature vectors&lt;/li&gt;
&lt;li&gt;Data warehouse data&lt;/li&gt;
&lt;li&gt;Spatial data&lt;/li&gt;
&lt;li&gt;Text documents&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;attribute-types&#34;&gt;Attribute Types&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Attributes of multidimensional tuples may have variable types
&lt;ul&gt;
&lt;li&gt;Ordinal (e.g., age, salary)&lt;/li&gt;
&lt;li&gt;Nominal categorical values (e.g., color, religion)&lt;/li&gt;
&lt;li&gt;Binary (e.g., gender, owns_property)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Basic queries: range, NN, similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;basic-queries&#34;&gt;Basic Queries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;(Range) selection query
&lt;ul&gt;
&lt;li&gt;Returns the records that qualify a (multidimensional) range predicate&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Return the employees of age between 45 and 50 and salary above $100,000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distance (similarity) query
&lt;ul&gt;
&lt;li&gt;Returns the records that are within a distance from a reference record.&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Find images with feature vectors of Euclidean distance at most ε with the feature vector of a given image&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nearest neighbor (similarity) query
&lt;ul&gt;
&lt;li&gt;Replaces distance bound by ranking predicate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;top-k-search-methods&#34;&gt;Top-k Search Methods&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Rank aggregation&lt;/li&gt;
&lt;li&gt;Index-based methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query&#34;&gt;Top-k Query&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of objects (e.g., relational tuples),&lt;/li&gt;
&lt;li&gt;Returns the k objects with the highest combined score, based on an aggregate function f.&lt;/li&gt;
&lt;li&gt;Example:
&lt;ul&gt;
&lt;li&gt;Relational table containing information about restaurants, with attributes(e.g. price, quality, location)&lt;/li&gt;
&lt;li&gt;f: sum(-price, quality, -dist(location,my_hotel))‏&lt;/li&gt;
&lt;li&gt;attribute value ranges are usually normalized
&lt;ul&gt;
&lt;li&gt;E.g., all values in a (0,1) range&lt;/li&gt;
&lt;li&gt;otherwise some attribute may be favored in f&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query-variants&#34;&gt;Top-k Query Variants&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Apply on single table, or ranked lists of tuples ordered by individual attributes
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_1.jpg&#34; alt=&#34;Top_k_Query_Variants_1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ranked inputs in the same or different servers (centralized or distributed data)
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_2.jpg&#34; alt=&#34;Top_k_Query_Variants_1&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Standalone query or operator in a more complex query plan
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Top_k_Query_Variants_3.jpg&#34; alt=&#34;Top_k_Query_Variants_3&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Incremental retrieval of objects with highest scores (k is not predefined)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Top-k joins&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;House&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;School&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;location&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;location&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;ORDER&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;BY&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;price&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;∗&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tuition&lt;/span&gt; 
&lt;span class=&#34;k&#34;&gt;LIMIT&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Probabilistic/approximate top-k retrieval&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Random and/or sorted accesses at ranked inputs&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;top-k-query-evaluation&#34;&gt;Top-k Query Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Most solutions assume distributive, monotone aggregate functions (e.g. f=sum)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;distributive: f(x,y,z,w)= f(f(x,y),f(z,w))
&lt;ul&gt;
&lt;li&gt;e.g., A+B+C+D = (A+B) + (C+D)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;monotone: if x&amp;lt;y and z&amp;lt;w, then f(x,z)&amp;lt;f(y,w)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions based on 1-D ordering and merging sorted lists (rank aggregation)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions based on multidimensional indexing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;rank-aggregation&#34;&gt;Rank Aggregation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Solutions based on 1-D ordering and merging sorted lists (rank aggregation)&lt;/li&gt;
&lt;li&gt;Assume that there is a total ranking of theobjects for each attributethat can be used in top-kqueries&lt;/li&gt;
&lt;li&gt;These sorted inputs canbe accessed sequentiallyand/or by random accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Rank_Aggregation.jpg&#34; alt=&#34;Rank_Aggregation&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;advantages-and-drawbacks&#34;&gt;Advantages and Drawbacks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Advantages：
&lt;ul&gt;
&lt;li&gt;can be applied on any subset of inputs (arbitrary subspace)&lt;/li&gt;
&lt;li&gt;appropriate for distributed data&lt;/li&gt;
&lt;li&gt;appropriate for top-k joins&lt;/li&gt;
&lt;li&gt;easy to understand and implement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Drawbacks:
&lt;ul&gt;
&lt;li&gt;slower than index-based methods&lt;/li&gt;
&lt;li&gt;require inputs to be sorted&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ta-threshold-algorithm&#34;&gt;TA: Threshold Algorithm&lt;/h3&gt;
&lt;h4 id=&#34;introduction&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Iteratively retrieves objects and their atomic scores from the ranked inputs in a round-robin fashion.&lt;/li&gt;
&lt;li&gt;For each encountered object x, perform random accesses to the inputs where x has not been seen.&lt;/li&gt;
&lt;li&gt;Maintain top-k objects seen so far.&lt;/li&gt;
&lt;li&gt;T = f($l_1$, . . . , $l_m$) is the score derived when applying the aggregation function to the last atomic scores seen at each input. If the score of the k-th object is no smaller than T, terminate.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-of-tak1fsum&#34;&gt;Example of TA(k=1,f=sum)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 1&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is c, with score 2.0&lt;/li&gt;
&lt;li&gt;T=sum(0.9,0.9,0.9)=2.7&lt;/li&gt;
&lt;li&gt;T&amp;gt;top-1, we proceed to another round of accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_1.jpg&#34; alt=&#34;TA_Step_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 2&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is b, with score 2.2&lt;/li&gt;
&lt;li&gt;T=sum(0.8,0.8,0.9)=2.5&lt;/li&gt;
&lt;li&gt;T&amp;gt;top-1, we proceed to another round of accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_2.jpg&#34; alt=&#34;TA_Step_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 3&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;top-1 is b, with score 2.2&lt;/li&gt;
&lt;li&gt;T=sum(0.6,0.6,0.8)=2.0&lt;/li&gt;
&lt;li&gt;T≤top-1, terminate and output (b,2.2)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/TA_Step_3.jpg&#34; alt=&#34;TA_Step_3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;properties-of-ta&#34;&gt;Properties of TA&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Used as a standard module for merging ranked lists in many applications&lt;/li&gt;
&lt;li&gt;Usually finds the result quickly&lt;/li&gt;
&lt;li&gt;Depends on random accesses, which can be expensive&lt;/li&gt;
&lt;li&gt;random accesses are impossible in some cases
&lt;ul&gt;
&lt;li&gt;e.g., an API allows to access objects incrementally by ranking score, but does not provide the score of a given object&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;nra-no-random-accesses&#34;&gt;NRA: No Random Accesses&lt;/h3&gt;
&lt;h4 id=&#34;introduction-1&#34;&gt;Introduction&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Iteratively retrieves objects and their atomic scores from the ranked inputs in a round-robin fashion.&lt;/li&gt;
&lt;li&gt;For each object x seen so far at any input maintain:
&lt;ul&gt;
&lt;li&gt;f_x_ub: upper bound for x’s aggregate score (f_x)&lt;/li&gt;
&lt;li&gt;f_x_lb: lower bound for x’s aggregate score (f_x)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;W_k = k objects with the largest f^lb.&lt;/li&gt;
&lt;li&gt;If the smallest f^lb in W_k is at least the largest f_x_ub of any object x not in W_k, then terminate and report W_k as top-k result.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-of-nrak1fsum&#34;&gt;Example of NRA(k=1,f=sum)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 1&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_1.jpg&#34; alt=&#34;NRA_Step_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_2.jpg&#34; alt=&#34;NRA_Step_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 3&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_3.jpg&#34; alt=&#34;NRA_Step_3&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;STEP 4&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/NRA_Step_4.jpg&#34; alt=&#34;NRA_Step_4&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;nra-properties&#34;&gt;NRA Properties&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;More generic than TA, since it does not depend on random accesses&lt;/li&gt;
&lt;li&gt;Can be cheaper than TA, if random accesses are very expensive&lt;/li&gt;
&lt;li&gt;NRA accesses objects sequentially from all inputs and updates the upper bounds for all objects seen so far unconditionally.
&lt;ul&gt;
&lt;li&gt;Cost: O(n) per access (the expected distinct number of objects accessed so far is O(n))&lt;/li&gt;
&lt;li&gt;No input list is pruned until the algorithm terminates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lara-lattice-based-rank-aggregation&#34;&gt;LARA: LAttice-based Rank Aggregation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LARA: An efficient NRA implementation&lt;/li&gt;
&lt;li&gt;Based on 3 observations about the top-k candidates&lt;/li&gt;
&lt;li&gt;Operates differently in the two (growing, shrinking) phases&lt;/li&gt;
&lt;li&gt;Takes its name from the lattice used in the shrinking phase&lt;/li&gt;
&lt;li&gt;Extendable to various top-k query variants&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 3 Spatial Networks</title>
      <link>https://www.pseudoyu.com/zh/2021/02/27/comp7801_topic3/</link>
      <pubDate>Sat, 27 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/27/comp7801_topic3/</guid>
      
        <description>&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;h4 id=&#34;network-distance&#34;&gt;Network Distance&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In many real applications accessibility of objects is restricted by a spatial network
&lt;ul&gt;
&lt;li&gt;Examples
&lt;ul&gt;
&lt;li&gt;Driver looking for nearest gas station&lt;/li&gt;
&lt;li&gt;Mobile user looking for nearest restaurant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shortest path distance&lt;/strong&gt; used instead of Euclidean distance&lt;/li&gt;
&lt;li&gt;SP(a,b) = path between a and b with the minimum accumulated length&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;challenges&#34;&gt;Challenges&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Euclidean distance is no longer relevant
&lt;ul&gt;
&lt;li&gt;R-tree may not be useful, when search is based on shortest path distance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph cannot be flattened to a one-dimensional space
&lt;ul&gt;
&lt;li&gt;Special storage and indexing techniques for graphs are required&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Graph properties may vary
&lt;ul&gt;
&lt;li&gt;directed vs. undirected&lt;/li&gt;
&lt;li&gt;length, time, etc. as edge weights&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;modeling-and-storing-spatial-networks&#34;&gt;Modeling and Storing Spatial Networks&lt;/h3&gt;
&lt;h4 id=&#34;modeling-spatial-networks&#34;&gt;Modeling Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Adjacency matrix only appropriate for dense graphs&lt;/li&gt;
&lt;li&gt;Spatial networks are sparse: use adjacency lists instead&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Modeling_Spatial_Networks.png&#34; alt=&#34;Modeling_Spatial_Networks&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;storing-large-spatial-networks&#34;&gt;Storing Large Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Problem: adjacency lists representation may not fit in memory if graph is large&lt;/li&gt;
&lt;li&gt;Solution:
&lt;ul&gt;
&lt;li&gt;partition adjacency lists to disk blocks (based on proximity)&lt;/li&gt;
&lt;li&gt;create B+-tree index on top of partitions (based on node-id)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Storing_Large_Spatial_Network.png&#34; alt=&#34;Storing_Large_Spatial_Network&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;shortest-path-search&#34;&gt;Shortest Path Search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Given a graph G(V,E), and two nodes s,t in V, find the shortest path from s to t&lt;/li&gt;
&lt;li&gt;A classic algorithmic problem&lt;/li&gt;
&lt;li&gt;Studied extensively since the 1950’s&lt;/li&gt;
&lt;li&gt;Several methods:
&lt;ul&gt;
&lt;li&gt;Dijkstra’s algorithm&lt;/li&gt;
&lt;li&gt;A*-search&lt;/li&gt;
&lt;li&gt;Bi-directional search&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;dijkstras-shortest-path-search&#34;&gt;Dijkstra’s Shortest Path Search&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;idea: incrementally explore the graph around s, visitingnodes in distance order to suntil t is found (like NN)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_1.png&#34; alt=&#34;Dijkstra_1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_2.png&#34; alt=&#34;Dijkstra_2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_Algorithm.png&#34; alt=&#34;Dijkstra_Algorithm&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;example&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Dijkstra_Example.png&#34; alt=&#34;Dijkstra_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the shortest path between a and b.&lt;/li&gt;
&lt;li&gt;Worst-case performance O(|E| + |V|log|V| )&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;a-search&#34;&gt;A*-search&lt;/h3&gt;
&lt;h4 id=&#34;description&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Dijkstra’s search explores nodes around s without a specific search direction until t is found&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Idea: improve Dijkstra’s algorithm by directing search towards t&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Due to triangular inequality, Euclidean distance is a lower bound of network distance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Euclidean distance to lower bound network distance based on known information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nodes are visited in increasing SPD(s,v)+dist(v,t) order
&lt;ul&gt;
&lt;li&gt;SPD(s,v): shortest path distance from s to v (computed by Dijkstra)&lt;/li&gt;
&lt;li&gt;dist(v,t): Euclidean distance between v and t&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Original Dijkstra visits nodes in increasing SPD(s,v) order&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/A_Star_1.png&#34; alt=&#34;A_Star_1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;example-1&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/A_Star_Example.png&#34; alt=&#34;A_Star_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating-1&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the shortest path between s and t.
&lt;ul&gt;
&lt;li&gt;f(p) = Dijkstra_dist(s, p) + Euclidean_dist(p, t)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bi-directional-search&#34;&gt;Bi-directional search&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra’s search explores nodes around s without a specific search direction until t is found&lt;/li&gt;
&lt;li&gt;Idea: search can be performed concurrently from s and from t (backwards)&lt;/li&gt;
&lt;li&gt;The shortest path tree of s and the (backward) shortest path tree of t are computed in concurrently
&lt;ul&gt;
&lt;li&gt;One queue Q_s for forward and one queue Q_t for backward search&lt;/li&gt;
&lt;li&gt;Node visits are prioritized based on min(SPD(s,v), SPD(v,t))&lt;/li&gt;
&lt;li&gt;If v already visited from s and v is in Qt, then candidate shortest path: p(s,v)+p(v,t)  (if v already visited from t and v in Q_s symmetric)&lt;/li&gt;
&lt;li&gt;If v is visited by both s and t terminate search; report best candidate shortest path&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-2&#34;&gt;Example&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Bi_Directional_Example.png&#34; alt=&#34;Bi_Directional_Example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;discussions&#34;&gt;Discussions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A* and bi-directional search can be combined to powerful search techniques&lt;/li&gt;
&lt;li&gt;A* can only be applied if lower distance bounds are available&lt;/li&gt;
&lt;li&gt;All versions of Dijkstra’s search require non-negative edge weights
&lt;ul&gt;
&lt;li&gt;Bellman-Ford is an algorithm for arbitrary negative edges&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spatial-queries-over-spatial-networks&#34;&gt;Spatial queries over spatial networks&lt;/h2&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;h4 id=&#34;sourcedestination-on-edges&#34;&gt;Source/Destination on Edges&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;We have assumed that points s and t are nodes of the network&lt;/li&gt;
&lt;li&gt;In practice s and t could be arbitrary points on edges
&lt;ul&gt;
&lt;li&gt;Mobile user locations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solve problem by introducing 2 more nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Source_Destination_on_Edges.png&#34; alt=&#34;Source_Destination_on_Edges&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;spatial-queries-over-spatial-networks-1&#34;&gt;Spatial Queries over Spatial Networks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data:
&lt;ul&gt;
&lt;li&gt;A (static) spatial network (e.g., city map)&lt;/li&gt;
&lt;li&gt;A (dynamic) set of spatial objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial queries based on network distance:
&lt;ul&gt;
&lt;li&gt;Selections. Ex: find gas stations within 10km driving distance from here&lt;/li&gt;
&lt;li&gt;Nearest neighbor search. Ex: find k nearest restaurants from present position&lt;/li&gt;
&lt;li&gt;Joins. Ex: find pairs of restaurants and hotels at most 100m from each other&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Spatial_Queries_over_Spatial_Networks.png&#34; alt=&#34;Spatial_Queries_over_Spatial_Networks&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;methodology&#34;&gt;Methodology&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Store (and index) the spatial network
&lt;ul&gt;
&lt;li&gt;Graph component (indexes connectivity information)&lt;/li&gt;
&lt;li&gt;Spatial component (indexes coordinates of nodes, edges, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Store (and index) the sets of spatial objects
&lt;ul&gt;
&lt;li&gt;Ex., one spatial relation for restaurants, one spatial relation for hotels, one relation for mobile users, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Given a spatial location p, use spatial component of network to find the network edge containing p&lt;/li&gt;
&lt;li&gt;Given a network edge, use network component to traverse neighboring edges&lt;/li&gt;
&lt;li&gt;Given a neighboring edge, use spatial indexes to find objects on them&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-of-spatial-selections-1&#34;&gt;Evaluation of Spatial Selections (1)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find all objects in spatial relation R, within network distance ε from location q&lt;/li&gt;
&lt;li&gt;Method:
&lt;ul&gt;
&lt;li&gt;Use spatial index of network (R-tree indexing network edges) to find edge n_1n_2, which includes q&lt;/li&gt;
&lt;li&gt;Use adjacency index of network (graph component) and apply Dijkstra’s algorithm to progressively retrieve edges that are within network distance ε from location q&lt;/li&gt;
&lt;li&gt;For all these edges apply a spatial selection on the R-tree that indexes R to find the results&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-3&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example: Find restaurants at most distance 10 from q&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 1: find network edge which contains q&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_1.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: traverse network to find all edges (or parts of them within distance 10 from q)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_2.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: find restaurants that intersect the subnetwork computed at step 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_3.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_3&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluation-of-spatial-selections-2&#34;&gt;Evaluation of Spatial Selections (2)&lt;/h3&gt;
&lt;h4 id=&#34;description-1&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Query: find all objects in spatial relation R, within network distance ε from location q&lt;/li&gt;
&lt;li&gt;Alternative method based on Euclidean bounds:
&lt;ul&gt;
&lt;li&gt;Assumption: Euclidean distance is a lower-bound of network distance:
&lt;ul&gt;
&lt;li&gt;dist(v,u) ≤ SPD(v,u), for any v,u&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use R-tree on R to find set S of objects such that for each o in S: dist(q,o) ≤ ε&lt;/li&gt;
&lt;li&gt;For each o in S:
&lt;ul&gt;
&lt;li&gt;find where o is located in the network (use Network R-tree)&lt;/li&gt;
&lt;li&gt;compute SPD(q,o) (e.g. use A*)&lt;/li&gt;
&lt;li&gt;If SPD(q,o) ≤ ε then output o&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-4&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Example: Find restaurants at most distance 10 from q&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 1: find restaurants for which the Euclidean distance to q is at most 10: S={r1,r2,r3}&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_Example_1.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_Example_1&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 2: for each restaurant in S, compute SPD to q and verify if it is indeed a correct result&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_Spatial_Selections_Example_2.png&#34; alt=&#34;Evaluation_of_Spatial_Selections_Example_2&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;evaluation-of-nn-search-1&#34;&gt;Evaluation of NN search (1)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find in spatial relation R the nearest object to a given location q&lt;/li&gt;
&lt;li&gt;Method:
&lt;ul&gt;
&lt;li&gt;Use spatial index of network (R-tree indexing network edges) to find edge n_1n_2, which includes q&lt;/li&gt;
&lt;li&gt;Use adjacency index of network (graph component) and apply Dijkstra’s algorithm to progressively retrieve edges in order of their distance to q&lt;/li&gt;
&lt;li&gt;For each edge apply a spatial selection on the R-tree that indexes R to find any objects&lt;/li&gt;
&lt;li&gt;Keep track of nearest object found so far; use its shortest path distance to terminate network browsing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;example-5&#34;&gt;Example&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Example: Find nearest restaurant to q&lt;/li&gt;
&lt;li&gt;Step: in ppt 31&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation-of-nn-search-2&#34;&gt;Evaluation of NN search (2)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Query: find in spatial relation R the nearest object to a given location q&lt;/li&gt;
&lt;li&gt;Alternative method based on Euclidean bounds:
&lt;ul&gt;
&lt;li&gt;Assumption: Euclidean distance lower-bounds network distance:
&lt;ul&gt;
&lt;li&gt;dist(v,u) ≤ SPD(v,u), for any v,u&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Evaluation_of_NN_search.png&#34; alt=&#34;Evaluation_of_NN_search&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;spatial-join-queries&#34;&gt;Spatial Join Queries&lt;/h3&gt;
&lt;h4 id=&#34;description-2&#34;&gt;Description&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Query: find pairs (r,s), such that r in relation R, s in relation S, and SPD(r,s)≤ε&lt;/li&gt;
&lt;li&gt;Methods:
&lt;ul&gt;
&lt;li&gt;For each r in R, do an ε-distance selection queries for objects in S (Index Nested Loops)&lt;/li&gt;
&lt;li&gt;For each pair (r,s), such that Euclidean dist(r,s)≤ε compute SPD(r,s) and verify SPD(r,s)≤ε&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;notes-on-query-evaluation-based-on-network-distance&#34;&gt;Notes on Query Evaluation based on Network Distance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;For each query type, there are methods based on network browsing and methods based on Euclidean bounds&lt;/li&gt;
&lt;li&gt;Network browsing methods are fast if network edges are densely populated with points of interest
&lt;ul&gt;
&lt;li&gt;A limited network traversal can find the result fast&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Methods based on Euclidean bounds are good if the searched POIs are sparsely distributed in the network
&lt;ul&gt;
&lt;li&gt;Few verifications with exact SP searches are required&lt;/li&gt;
&lt;li&gt;Directed SP search (e.g. using A*) avoids visiting empty parts of the network&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;advanced-indexing-techniques-for-spatial-networks&#34;&gt;Advanced indexing techniques for spatial networks&lt;/h2&gt;
&lt;h3 id=&#34;shortest-path-materialization-and-indexing-in-large-graphs&#34;&gt;Shortest Path Materialization and Indexing in Large Graphs&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dijkstra’s algorithm and related methods could be very expensive on very large graphs&lt;/li&gt;
&lt;li&gt;(Partial) materialization of shortest paths in static graphs can accelerate search&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Shortest_Path_Materialization_and_Indexing_in_Large_Graphs.png&#34; alt=&#34;Shortest_Path_Materialization_and_Indexing_in_Large_Graphs.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;hierarchical-path-materialization&#34;&gt;Hierarchical Path Materialization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Idea: Partition graph G into G_1,G_2,G_3,… based on connectivity and proximity of nodes&lt;/li&gt;
&lt;li&gt;Every edge of G goes to exactly one G_i&lt;/li&gt;
&lt;li&gt;Border nodes belong to more than one G_i’s&lt;/li&gt;
&lt;li&gt;For each G_i compute and materialize SPs between every pair of nodes in G_i (matrix M_i)
&lt;ul&gt;
&lt;li&gt;Partitions are small enough for materialization space overhead to be low&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compute and materialize SPs between every pair of border nodes (matrix B)
&lt;ul&gt;
&lt;li&gt;If border nodes too many, hierarchically partition them into 2nd-level partitions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization.png&#34; alt=&#34;Hierarchical_Path_Materialization&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-1&#34;&gt;algorithm&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization_algorithm.png&#34; alt=&#34;Hierarchical_Path_Materialization_algorithm&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;illustrating-2&#34;&gt;Illustrating&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Good partitioning if:
&lt;ul&gt;
&lt;li&gt;small partitions&lt;/li&gt;
&lt;li&gt;few combinations examined for SP search&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Real road networks:
&lt;ul&gt;
&lt;li&gt;Non-highway nodes in local partitions&lt;/li&gt;
&lt;li&gt;Highway nodes become border nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hierarchical_Path_Materialization_Illustration.png&#34; alt=&#34;Hierarchical_Path_Materialization_Illustration&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;compressing-materialized-paths&#34;&gt;Compressing Materialized Paths&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Distance matrix with successors has O(n_2) space cost&lt;/li&gt;
&lt;li&gt;Motivation: reduce space by grouping targets based on common successors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Compressing_Materialized_Paths.png&#34; alt=&#34;Compressing_Materialized_Paths&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;algorithm-2&#34;&gt;algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Create and encode one space partitioning defined by targets of the same successor&lt;/li&gt;
&lt;li&gt;For each node s, index Is a set of &amp;lt;succ,R&amp;gt; pairs:
&lt;ul&gt;
&lt;li&gt;succ: a successor of s&lt;/li&gt;
&lt;li&gt;R: a continuous region, such that for each t in R, the successor of s in SP(s,t) is succ&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Compressing_Materialized_Paths_Algorithm.png&#34; alt=&#34;Compressing_Materialized_Paths_Algorithm&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To compute SP(s,t) for a given s, t:
&lt;ol&gt;
&lt;li&gt;SP=s&lt;/li&gt;
&lt;li&gt;Use spatial index Is to find &amp;lt;succ,R&amp;gt;, such that t in R&lt;/li&gt;
&lt;li&gt;SP = SP + (s,succ)&lt;/li&gt;
&lt;li&gt;If succ = t, report SP and terminate&lt;/li&gt;
&lt;li&gt;Otherwise s=succ; Goto step 2&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Indexing and search of spatial networks is different than spatial indexing
&lt;ul&gt;
&lt;li&gt;Shortest path distance is used instead of Euclidean distance, to define range queries, nearest neighbor search, and spatial joins&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial networks could be too large to fit in memory
&lt;ul&gt;
&lt;li&gt;Disk-based index for adjacency lists is used&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Several shortest path algorithms&lt;/li&gt;
&lt;li&gt;Spatial queries can be evaluated using Euclidean bounds&lt;/li&gt;
&lt;li&gt;Advanced indexing methods for shortest path search on large graphs&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 2 Association Rules</title>
      <link>https://www.pseudoyu.com/zh/2021/02/25/comp7103_topic2/</link>
      <pubDate>Thu, 25 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/25/comp7103_topic2/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-2-association-rules&#34;&gt;Topic 2 Association Rules&lt;/h2&gt;
&lt;h3 id=&#34;market-basket-model&#34;&gt;Market-Basket Model&lt;/h3&gt;
&lt;p&gt;A general many-many mapping (association) between two kinds of things&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A large set of items, e.g., things sold in a supermarket&lt;/li&gt;
&lt;li&gt;A large set of baskets, each of which is a small set of the items, e.g., the things one customer buys on one day&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;frequent-itemsets&#34;&gt;Frequent Itemsets&lt;/h3&gt;
&lt;h4 id=&#34;support&#34;&gt;Support&lt;/h4&gt;
&lt;p&gt;Support for itemset I (s(I)) = the number of baskets containing all items in I&lt;/p&gt;
&lt;p&gt;Given a support threshold s, sets of items that appear in at least s baskets are called frequent itemsets&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/frequent_itemsets.png&#34; alt=&#34;frequent_itemsets&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;monotonicity&#34;&gt;Monotonicity&lt;/h4&gt;
&lt;p&gt;For any sets of items I and any set of items J, it holds that&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_monotonicity.png&#34; alt=&#34;association_rules_monotonicity&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;applications&#34;&gt;Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;given that many people buy beer and diapers together
&lt;ul&gt;
&lt;li&gt;Run a sale on diapers; raise price of beer&lt;/li&gt;
&lt;li&gt;Only useful if many buy diapers &amp;amp; beer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Items that appear together too often could represent plagiarism&lt;/li&gt;
&lt;li&gt;Unusual words appearing together in a large number of documents&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;association-rules&#34;&gt;Association Rules&lt;/h3&gt;
&lt;p&gt;If-then rules I → j about the contents of baskets, I is a set of items and j is an item&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;i → j means
&lt;ul&gt;
&lt;li&gt;if a basket contains all the items in I then it is likely to contain j&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;confidence&#34;&gt;Confidence&lt;/h4&gt;
&lt;p&gt;The probability of j given I&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_confidence.png&#34; alt=&#34;association_rules_confidence&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/association_rules_confidence_example.png&#34; alt=&#34;association_rules_confidence_example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;finding-association-rules&#34;&gt;Finding Association Rules&lt;/h4&gt;
&lt;p&gt;find all association rules with support ≥ s and confidence ≥ c&lt;/p&gt;
&lt;h4 id=&#34;computation-model&#34;&gt;Computation Model&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Data is kept in raw files rather than in a database system
&lt;ul&gt;
&lt;li&gt;Stored on disk&lt;/li&gt;
&lt;li&gt;Stored basket-by-basket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The true cost of mining disk-resident data is usually the number of disk I/O’s&lt;/li&gt;
&lt;li&gt;In practice, association-rule algorithms read data in passes – all baskets read in turn&lt;/li&gt;
&lt;li&gt;we measure the cost by the number of passes an algorithm takes&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;association-rules-algorithms&#34;&gt;Association Rules Algorithms&lt;/h3&gt;
&lt;h4 id=&#34;naïve-algorithm&#34;&gt;Naïve Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Read file once, counting in main memory the occurrences of each pair
&lt;ul&gt;
&lt;li&gt;From each basket of n items, generate its n (n -1)/2 pairs by two nested loops&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fails if (#items)^2 exceeds main memory&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-priori-algorithm&#34;&gt;A-Priori Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A two-pass approach called a-priori limits the need for main memory&lt;/li&gt;
&lt;li&gt;Key idea: monotonicity
&lt;ul&gt;
&lt;li&gt;If a set of items appears at least s times, so does every subset&lt;/li&gt;
&lt;li&gt;For pairs: if item i does not appear in s baskets, then no pair including i can appear in s baskets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Read baskets and count in main memory the occurrences of each item (Requires only memory proportional to #items)
&lt;ul&gt;
&lt;li&gt;Items that appear at least s times are the frequent items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Read baskets again and count in main memory only those pairs both of which were found in pass 1 to be frequent
&lt;ul&gt;
&lt;li&gt;To count number of item pairs use a hash function&lt;/li&gt;
&lt;li&gt;Requires memory proportional to square of frequent items only, plus a list of the frequent items, plus space for hashing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/APriori_Algorithm.png&#34; alt=&#34;APriori_Algorithm&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One pass for each k&lt;/li&gt;
&lt;li&gt;Needs room in main memory to count each candidate k -set&lt;/li&gt;
&lt;li&gt;For typical market-basket data and reasonable support (e.g., 1%), k = 2 requires the most memory&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pcy-algorithm&#34;&gt;PCY Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Main observation: during pass 1 of A-priori, most memory is idle&lt;/li&gt;
&lt;li&gt;Use that memory to keep additional info to improve storage during pass 2 of A-priori&lt;/li&gt;
&lt;li&gt;Passes &amp;gt; 2 are the same as in A-Priori&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Use a hash function which bucketizes item pairs, that is, maps them to integers in [1,k]&lt;/li&gt;
&lt;li&gt;Each bucket i in [1,k] is associated with a counter ci&lt;/li&gt;
&lt;li&gt;During pass 1, as we examine a basket (e.g. {m,b,d,o})
&lt;ul&gt;
&lt;li&gt;update counters of single items&lt;/li&gt;
&lt;li&gt;Generate all item pairs for that basket, hash each of them and add 1 to the corr. counter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Count all pairs {i, j } that meet the conditions for being a candidate pair
&lt;ul&gt;
&lt;li&gt;Both i and j are frequent items&lt;/li&gt;
&lt;li&gt;The pair {i, j }, hashes to a frequent bucket&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ignore all pairs belonging to non-frequent buckets (do not use a counter for them)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;simple-algorithm&#34;&gt;Simple Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Take a random sample of the market baskets
&lt;ul&gt;
&lt;li&gt;give a full pass on the data and keep a basket in main memory with probability p&lt;/li&gt;
&lt;li&gt;A random sample is the best representative of a dataset&lt;/li&gt;
&lt;li&gt;Keeping only the first baskets might not contain iPhones for example&lt;/li&gt;
&lt;li&gt;If we cannot have a sample large enough then
&lt;ul&gt;
&lt;li&gt;Remove false positives with one more pass&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Run A-priori or one of its improvements in main memory, so you don’t pay for disk I/O each time you give a pass on the data
&lt;ul&gt;
&lt;li&gt;Be sure you leave enough space for counts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adjust the support threshold s accordingly&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;son-algorithm&#34;&gt;SON Algorithm&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Two passes&lt;/li&gt;
&lt;li&gt;No false positives or false negatives&lt;/li&gt;
&lt;li&gt;Divide the dataset into chunks, where each chunk contains a subset of baskets&lt;/li&gt;
&lt;li&gt;Process
&lt;ul&gt;
&lt;li&gt;Pass 1
&lt;ul&gt;
&lt;li&gt;Divide the dataset into chunks, where each chunk contains a subset of baskets&lt;/li&gt;
&lt;li&gt;Let pi such that the ith chunk contains a fraction pi of the dataset&lt;/li&gt;
&lt;li&gt;For each chunk i compute all frequent itemsets with support p i x s and store them on disk. This is the set of candidates for next pass&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pass 2
&lt;ul&gt;
&lt;li&gt;Read all frequent itemsets found in the previous pass (candidates)&lt;/li&gt;
&lt;li&gt;For each of them count the number of occurrences and output only those with support at least s&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Ethereum核心技术解读</title>
      <link>https://www.pseudoyu.com/zh/2021/02/20/blockchain_ethereum_basic/</link>
      <pubDate>Sat, 20 Feb 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/20/blockchain_ethereum_basic/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;比特币作为一种去中心化的数字货币，是极其成功的，但受限于比特币脚本（非图灵完备，只能处理一些简单的逻辑），并不能处理很复杂的业务。而&lt;code&gt;Ethereum&lt;/code&gt;引入了智能合约，使去中心化的概念能够应用于更丰富的应用场景，因此也被称为区块链2.0。本文将对以太坊核心技术进行解读，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;ethereum系统&#34;&gt;Ethereum系统&lt;/h2&gt;
&lt;p&gt;2014年1月，俄罗斯开发者Vitalik Buterin发布了以太坊白皮书并成立团队，旨在创造一个集成更通用的脚本语言的区块链平台。其中一位成员Dr. Gavin Wood发布了一份黄皮书，涉及&lt;code&gt;Ethereum Virtual Machin(EVM)&lt;/code&gt;以太坊虚拟的相关技术，这就是&lt;code&gt;Ethereum&lt;/code&gt;的诞生。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ethereum_overview.png&#34; alt=&#34;ethereum_overview&#34;&gt;&lt;/p&gt;
&lt;p&gt;简单来说，&lt;code&gt;Ethereum&lt;/code&gt;是一个开源的去中心化系统，使用区块链来存储系统状态变化，因此也被称为“世界计算机”；它支持开发者在区块链上部署运行不可变的程序，称为智能合约，因此可以支持广泛的应用场景；它使用数字货币&lt;code&gt;Ether&lt;/code&gt;来衡量系统资源消耗，激励更多人参与&lt;code&gt;Ethereum&lt;/code&gt;系统建设。&lt;/p&gt;
&lt;h3 id=&#34;去中心化应用dapp&#34;&gt;去中心化应用DApp&lt;/h3&gt;
&lt;p&gt;狭义来说，DApp其实就是一个集成了用户界面、支持智能合约、运行于以太坊区块链上的应用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ethereum_architecture.png&#34; alt=&#34;ethereum_architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，&lt;code&gt;Ethereum&lt;/code&gt;应用实例部署在区块链网络上（智能合约运行于区块链虚拟机中），而Web程序只需要通过&lt;code&gt;Web3.js&lt;/code&gt;对区块链网络进行&lt;code&gt;RPC&lt;/code&gt;远程调用，这样用户就可以通过浏览器（DApp浏览器或MetaMask等插件工具）访问去中心化服务应用了。&lt;/p&gt;
&lt;h3 id=&#34;账本&#34;&gt;账本&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Ethereum&lt;/code&gt;区块链是一个去中心化的账本（数据库），网络中的所有交易都会存储在区块链中，所有节点都要本地保存一份数据，并且确保每一笔交易的可信度；所有的交易都是公开且不可篡改的，网络中的所有节点都可以查看和验证。&lt;/p&gt;
&lt;h3 id=&#34;账户&#34;&gt;账户&lt;/h3&gt;
&lt;p&gt;当我们需要登录一个网站或系统（比如邮箱）时，往往需要一个帐号和一个密码，密码通过加密算法以暗文的形式存储在中心化的数据库中。然而，以太坊是一个去中心化的系统，那是怎么生成账户的呢？&lt;/p&gt;
&lt;p&gt;和比特币系统原理类似&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先生成一个仅有自己知道的私钥，假设为&lt;code&gt;sk&lt;/code&gt;，采用&lt;code&gt;ECDSA(Elliptic Curve Digital Signature Algorithm)&lt;/code&gt;椭圆曲线算法生成对应的公钥&lt;code&gt;pk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;采用&lt;code&gt;keccak256&lt;/code&gt;算法对公钥&lt;code&gt;pk&lt;/code&gt;求哈希值&lt;/li&gt;
&lt;li&gt;截取后160位作为以太坊的地址&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;用户的私钥和地址一起组成了以太坊的账户，可以存储余额、发起交易等（比特币的余额是通过计算所有的&lt;code&gt;UTXO&lt;/code&gt;得到的，而不是像以太坊一样存储在账户中）。&lt;/p&gt;
&lt;p&gt;其实&lt;code&gt;Ethereum&lt;/code&gt;账户分为两种类型，上述方式生成的叫&lt;code&gt;Externally Owned Accounts(EOA)&lt;/code&gt;，外部账户，也就是常规用户拥有的账户，主要是用来发送/接收&lt;code&gt;Ether&lt;/code&gt;代币或者向智能合约发送交易（即调用智能合约）。&lt;/p&gt;
&lt;p&gt;而另一种则是&lt;code&gt;Contract Accounts&lt;/code&gt;，合约账户，不同于外部账户，这种账户是没有对应的私钥的，而是在部署合约的时候生成的，存储智能合约代码。值得注意的是，合约账户必须要被外部账户或者其他合约调用才能够发送或接收&lt;code&gt;Ether&lt;/code&gt;，而不能自己主动执行交易。&lt;/p&gt;
&lt;h3 id=&#34;钱包&#34;&gt;钱包&lt;/h3&gt;
&lt;p&gt;存储和管理&lt;code&gt;Ethereum&lt;/code&gt;账户的软件/插件称为钱包，提供了诸如交易签名、余额管理等功能。钱包生成主要有两种方式，非确定性随机生成或根据随机种子生成。&lt;/p&gt;
&lt;h3 id=&#34;gas&#34;&gt;Gas&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Ethereum&lt;/code&gt;网络上的操作也需要“手续费”，称为&lt;code&gt;Gas&lt;/code&gt;，在区块链上部署智能合约以及转账都需要消耗一定单位的&lt;code&gt;Gas&lt;/code&gt;，这也是鼓励矿工参与&lt;code&gt;Ethereum&lt;/code&gt;网络建设的激励机制，从而使整个网络更加安全、可靠。&lt;/p&gt;
&lt;p&gt;每个交易都可以设置相应的&lt;code&gt;Gas&lt;/code&gt;量和&lt;code&gt;Gas&lt;/code&gt;的价格，设置较高的&lt;code&gt;Gas&lt;/code&gt;费则往往矿工会更快处理你的交易，但为了预防交易多次执行消耗大量&lt;code&gt;Gas&lt;/code&gt;费，可以通过&lt;code&gt;Gas Limit&lt;/code&gt;来设置限制。&lt;code&gt;Gas&lt;/code&gt;相关信息可以通过 &lt;a href=&#34;https://etherscan.io/gastracker&#34;&gt;Ethereum Gas Tracker&lt;/a&gt; 工具进行查询。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;If START_GAS * GAS_PRICE &amp;gt; caller.balance, halt
Deduct START_GAS * GAS_PRICE from caller.balance
Set GAS = START_GAS
Run code, deducting from GAS
For negative values, add to GAS_REFUND
After termination, add GAS_REFUND to caller.balance
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;智能合约&#34;&gt;智能合约&lt;/h3&gt;
&lt;p&gt;上文提到，&lt;code&gt;Ethereum&lt;/code&gt;区块链不仅仅存储交易信息，还会存储与执行智能合约代码。&lt;/p&gt;
&lt;p&gt;智能合约控制应用和交易逻辑，&lt;code&gt;Ethereum&lt;/code&gt;系统中的智能合约采用专属&lt;code&gt;Solidity&lt;/code&gt;语言，语法类似于&lt;code&gt;JavaScript&lt;/code&gt;，除此之外，还有&lt;code&gt;Vyper&lt;/code&gt;、&lt;code&gt;Bamboo&lt;/code&gt;等编程语言。智能合约代码会被编译为字节码并部署至区块链中，一旦上链则不可以再编辑。&lt;code&gt;EVM&lt;/code&gt;作为一个智能合约执行环境，能够保障执行结果的确定性。&lt;/p&gt;
&lt;h4 id=&#34;智能合约示例众筹&#34;&gt;智能合约示例：众筹&lt;/h4&gt;
&lt;p&gt;让我们想象一个更复杂的场景，假设我要众筹10000元开发一个新产品，通过现有众筹平台需要支付不菲的手续费，而且很难解决信任问题，于是，可以通过一个众筹的DApp来解决这个问题。&lt;/p&gt;
&lt;p&gt;先为众筹设置一些规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个想参与众筹的人可以捐款10-10000元的金额&lt;/li&gt;
&lt;li&gt;如果目标金额达成了，金额会通过智能合约发送给我（即众筹发起人）&lt;/li&gt;
&lt;li&gt;如果目标在一定时间内（如1个月）没有达成，众筹的资金会原路返回至众筹用户&lt;/li&gt;
&lt;li&gt;也可以设置一些规则，比如一周后，如果目标金额没有达成，用户可以申请退款&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因为这些众筹条款是通过智能合约实现并部署在公开的区块链上的，即使是发起者也不能篡改条款，且任何人都可以查看，解决了信任问题。&lt;/p&gt;
&lt;p&gt;完整代码可以点击这里查看：&lt;a href=&#34;https://www.toshblocks.com/solidity/complete-example-crowd-funding-smart-contract/&#34;&gt;Demo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;交易&#34;&gt;交易&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;Ethereum&lt;/code&gt;中，一个典型的交易是怎么样的呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开发者部署智能合约至区块链&lt;/li&gt;
&lt;li&gt;DApp实例化合约、传入相应值以执行合约&lt;/li&gt;
&lt;li&gt;DApp对交易进行数字签名&lt;/li&gt;
&lt;li&gt;本地对交易进行验证&lt;/li&gt;
&lt;li&gt;广播交易至网络中&lt;/li&gt;
&lt;li&gt;矿工节点接收交易并进行验证&lt;/li&gt;
&lt;li&gt;矿工节点确认可信区块后广播至网络中&lt;/li&gt;
&lt;li&gt;本地节点与网络进行同步，接收新区块&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;架构&#34;&gt;架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ethereum_architecture_simple.png&#34; alt=&#34;ethereum_architecture_simple&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ethereum&lt;/code&gt;采用的是一种&lt;code&gt;Order - Execute - Validate - Update State&lt;/code&gt;的系统架构。在这种架构下，当产生一笔新的交易，矿工会进行&lt;code&gt;PoW&lt;/code&gt;工作量证明机制的运算；验证完成后，将区块通过&lt;code&gt;gossip&lt;/code&gt;协议广播至网络中；网络中的其他节点接收到新区块后，也会对区块进行验证；最终，提交至区块链，更新状态。&lt;/p&gt;
&lt;p&gt;具体来看，&lt;code&gt;Ethereum&lt;/code&gt;系统有共识层、数据层、应用层等核心组件，其交互逻辑如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/ethereum_architecture_concrete.png&#34; alt=&#34;ethereum_architecture_concrete&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上图所示，&lt;code&gt;Ethereum&lt;/code&gt;数据由&lt;code&gt;Transaction Root&lt;/code&gt;和&lt;code&gt;State Root&lt;/code&gt;组成。&lt;code&gt;Transaction Root&lt;/code&gt;是所有交易组成的树，包含&lt;code&gt;From&lt;/code&gt;、&lt;code&gt;To&lt;/code&gt;、&lt;code&gt;Data&lt;/code&gt;、&lt;code&gt;Value&lt;/code&gt;、&lt;code&gt;Gas Limit&lt;/code&gt;和&lt;code&gt;Gas Price&lt;/code&gt;；而&lt;code&gt;State Root&lt;/code&gt;则是所有账户组成的树，包含&lt;code&gt;Address&lt;/code&gt;、&lt;code&gt;Code&lt;/code&gt;、&lt;code&gt;Storage&lt;/code&gt;、&lt;code&gt;Balance&lt;/code&gt;和&lt;code&gt;Nonce&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对&lt;code&gt;Ethereum&lt;/code&gt;核心技术的一些解读，智能合约的引入给区块链的应用带来了更多可能性，但仍有很多安全性、隐私性和效率问题需要考虑。针对复杂的企业级应用场景，联盟链是更好的选择，后续将会对&lt;code&gt;Hyperledger Fabric&lt;/code&gt;进行详尽的分析，敬请期待！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://msccs.cs.hku.hk/public/courses/2020/COMP7408A/&#34;&gt;COMP7408 Distributed Ledger and Blockchain Technology&lt;/a&gt;, &lt;em&gt;Professor S.M. Yiu, HKU&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/blockchain-developer-nanodegree--nd1309&#34;&gt;Udacity Blockchain Developer Nanodegree&lt;/a&gt;, &lt;em&gt;Udacity&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Vt411X7JF&#34;&gt;区块链技术与应用&lt;/a&gt;，&lt;em&gt;肖臻，北京大学&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ituring.com.cn/book/2434&#34;&gt;区块链技术进阶与实战&lt;/a&gt;，&lt;em&gt;蔡亮 李启雷 梁秀波，浙江大学 | 趣链科技&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.zastrin.com/courses/ethereum-primer/lessons/1-5&#34;&gt;Ethereum Architecture&lt;/a&gt;, &lt;em&gt;zastrin&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.toshblocks.com/solidity/complete-example-crowd-funding-smart-contract/&#34;&gt;Learn Solidity: Complete Example: Crowd Funding Smart Contract&lt;/a&gt;, &lt;em&gt;TOSHBLOCKS&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>比特币核心技术解读</title>
      <link>https://www.pseudoyu.com/zh/2021/02/17/blockchain_bitcoin_basic/</link>
      <pubDate>Wed, 17 Feb 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/17/blockchain_bitcoin_basic/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;在上一篇文章《&lt;a href=&#34;https://www.pseudoyu.com/zh/2021/02/12/blockchain_basic/&#34;&gt;区块链基础知识与关键技术&lt;/a&gt;》里对区块链的基础知识和关键技术进行了梳理，而比特币是区块链最典型的应用，本文将对比特币核心技术进行解读，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;比特币系统&#34;&gt;比特币系统&lt;/h2&gt;
&lt;p&gt;比特币是在2009年由中本聪发明的一个数字货币，主要是为了反抗中心化的银行体系，因为其精巧的系统设计和安全性，价值也在迅速提升。同时，因为它并不与真实世界的身份绑定，具备强大的匿名性，也被用于非法交易、洗钱、勒索等恶意行为，引起了一些争议。&lt;/p&gt;
&lt;p&gt;作为一个去中心化的区块链系统，所有人都可以访问，也可以在本地维护一个节点参与到比特币网络中，下文也会应用&lt;code&gt;Bitcoin Core&lt;/code&gt;客户端在本地维护一个节点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/bitcoin_network_nodes.png&#34; alt=&#34;bitcoin_network_nodes&#34;&gt;&lt;/p&gt;
&lt;p&gt;节点分为全节点和轻节点两种，早期所有的节点都是全节点，但随着数据量越来越大，运行在手机或平板等设备上的比特币客户端不需要存储整个区块链的信息，称为&lt;code&gt;Simplified Payment Verification(SPV)&lt;/code&gt;节点，也叫轻节点。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Bitcoin Core&lt;/code&gt;客户端就是一个全节点，下文也会具体讲述。全节点一直在线，维护着完整的区块链信息；因为其内存里维护着完整的&lt;code&gt;UTXO&lt;/code&gt;集合，所以通过验证整个区块链的区块和交易信息（从创世区块到最新区块）来验证交易的合法性；也会决定哪些交易会被打包到区块中；验证交易即挖矿，可以决定沿着哪条链继续挖，在出现等长的分叉时，也会选择哪一个分叉；同时监听别的矿工挖出来的区块，验证合法性。&lt;/p&gt;
&lt;p&gt;轻节点不需要一直在线，也不需要保留整个区块链（数据量庞大），只需要保留每个区块的块头；且只需要保存与自己有关的区块，而不需要保存链上全部交易；因为并没有保存全部信息，无法验证大多数交易的合法性和网上发布的新区块的正确性，只能检验与自己有关的区块；可以通过&lt;code&gt;Merkle Proof&lt;/code&gt;验证一笔交易存在，但不能确认一笔交易不存在；可以验证挖矿的难度，因为保存在块头中。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;下面通过一个示例来讲解一下全节点和轻节点的交易验证方式。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假如要验证一个位于block 300,000的交易T，全节点会查验全部300,000个区块（直到创世区块），建立一个完整&lt;code&gt;UTXO&lt;/code&gt;的数据库来确保这个交易没有被花费；而轻节点则会通过&lt;code&gt;Merkle Path&lt;/code&gt;来链接所有和交易T相关的区块，然后等待300,001至300,006个区块来进行确认，从而验证交易的合法性。&lt;/p&gt;
&lt;h3 id=&#34;区块链结构&#34;&gt;区块链结构&lt;/h3&gt;
&lt;p&gt;区块链是由顺序链接起来的区块组成的一种数据结构，可以存于单文件或者数据库中，&lt;code&gt;Bitcoin Client&lt;/code&gt;使用Google的&lt;code&gt;LevelDB&lt;/code&gt;数据库存储数据。每一个区块都指向前一个区块，任何一个区块进行了修改的话，其所有后面的区块都会受到影响，所以想要篡改一个区块的话需要同时篡改之后的所有区块，这需要大量的算力，往往成本大于收益，因此极大地保障了安全性。&lt;/p&gt;
&lt;p&gt;区块链结构包含区块&lt;code&gt;Block Size (4 bytes)&lt;/code&gt;、&lt;code&gt;Block Header&lt;/code&gt;、&lt;code&gt;Transaction Counter(1-9 bytes)&lt;/code&gt;和&lt;code&gt;Transaction&lt;/code&gt;几个核心组成部分。&lt;/p&gt;
&lt;p&gt;区块链的块头大小为80 bytes，存储着&lt;code&gt;Version(4 bytes)&lt;/code&gt;、&lt;code&gt;Previous Block Hash(32 bytes)&lt;/code&gt;、&lt;code&gt;Merkle Tree Root(32 bytes)&lt;/code&gt;、&lt;code&gt;Timestamp(4 bytes)&lt;/code&gt;、&lt;code&gt;Difficulty Target(4 bytes)&lt;/code&gt;和&lt;code&gt;Nonce(4 bytes)&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;每一个区块的哈希值通过对区块头进行两次哈希运算，即&lt;code&gt;SHA256(SHA256(Block Header))&lt;/code&gt;，并不存在区块链结构中，而是由每个节点接收到区块后计算得到，是独一无二的；此外，&lt;code&gt;Block Height&lt;/code&gt;也可以作为区块的标识符。&lt;/p&gt;
&lt;h4 id=&#34;merkle-tree&#34;&gt;Merkle Tree&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Merkle Tree&lt;/code&gt;默克尔树是区块链中很重要的一个数据结构，主要通过哈希算法来验证较大数据集（也是通过双重哈希的方式&lt;code&gt;SHA256(SHA256(Block Header))&lt;/code&gt;），结构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/merkle_tree_example.png&#34; alt=&#34;merkle_tree_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;通过&lt;code&gt;Merkle Tree&lt;/code&gt;的方式可以很快地验证一个交易存在于某个区块中（算法复杂度为&lt;code&gt;LogN&lt;/code&gt;），例如，如果要验证一个交易K存在于区块中，只需要访问很少的节点&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/merkle_proof_example.png&#34; alt=&#34;merkle_proof_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为比特币网络中存在大量交易，这种方式能够极大提高效率，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/merkle_proof_efficiency.png&#34; alt=&#34;merkle_proof_efficiency&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为轻节点（例如手机上的比特币钱包）不保存整个区块链数据，通过&lt;code&gt;Merkle Tree&lt;/code&gt;结构可以很方便地查找交易，轻节点会构造一个&lt;code&gt;Bloom filter&lt;/code&gt;布隆过滤器来得到与自身相关的交易：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，初始化布隆过滤器为空值，获取钱包中的所有地址，创建一个检索模式来匹配与这个交易输出相关的地址，将检索模式加入布隆过滤器；&lt;/li&gt;
&lt;li&gt;然后布隆过滤器被发送至各个节点（通过&lt;code&gt;filterload&lt;/code&gt;消息）；&lt;/li&gt;
&lt;li&gt;节点收到后会发送一个包含符合条件的区块头和符合交易的&lt;code&gt;Merkle Path&lt;/code&gt;的&lt;code&gt;merkleblock&lt;/code&gt;消息和一个包含过滤结果的&lt;code&gt;tx&lt;/code&gt;消息。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;过程中，轻节点会使用&lt;code&gt;Merkle Path&lt;/code&gt;来链接交易与区块，并通过区块头来组成区块链，从而能够验证交易存在于区块链中。&lt;/p&gt;
&lt;p&gt;使用布隆过滤器会返回符合筛选条件的结果，也会存在着一些误报，因此返回了很多不相关的结果，也能够在轻节点向其他节点请求相关地址时保护了隐私性。&lt;/p&gt;
&lt;h3 id=&#34;比特币网络&#34;&gt;比特币网络&lt;/h3&gt;
&lt;p&gt;比特币系统运行在一个P2P点对点网络上，节点之间是平等的，没有身份、权限的区别；没有中心化的服务器，网络也没有层级区分。&lt;/p&gt;
&lt;p&gt;每个节点都要维护一个等待上链的交易的集合，每个区块大小为1M，因此需要几秒才能够穿到大多数的节点。假设一个节点监听到了A-&amp;gt;B的交易，会将其写入集合，如果同时又发现了一个A-&amp;gt;C的双花攻击，则不会再写入，而如果监听到同样一笔A-&amp;gt;B的交易或者同一个币来源的A-&amp;gt;C的交易，则会将该集合中A-&amp;gt;B的交易删除。&lt;/p&gt;
&lt;h3 id=&#34;比特币共识协议&#34;&gt;比特币共识协议&lt;/h3&gt;
&lt;p&gt;比特币作为一个人人都可以参与的开发系统，需要解决恶意节点的威胁，解决思路为工作量证明机制，也就是算力投票机制，当产生一笔新交易，广播新的数据记录，全网执行共识算法，即矿工挖矿来验证记录，即求解随机数，率先解出难题的矿工获得记账权，产生新区块，然后对外广播新区块，其他节点验证通过后加至主链。&lt;/p&gt;
&lt;h3 id=&#34;钱包&#34;&gt;钱包&lt;/h3&gt;
&lt;p&gt;作为一个数字货币系统，比特币有自己的钱包系统，主要由私钥、公钥和钱包地址三个部分组成。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;生成钱包地址的过程如下：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;采用&lt;code&gt;ECDSA(Elliptic Curve Digital Signature Algorithm)&lt;/code&gt;椭圆曲线算法，利用私钥生成对应的公钥&lt;/li&gt;
&lt;li&gt;公钥很长且难以输入和记忆，因此再通过&lt;code&gt;SHA256&lt;/code&gt;和&lt;code&gt;RIPEMD160&lt;/code&gt;算法得到一个公钥哈希值&lt;/li&gt;
&lt;li&gt;最后再用&lt;code&gt;Base58Check&lt;/code&gt;进行处理，得到一个可读性较强的钱包地址&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;交易过程&#34;&gt;交易过程&lt;/h3&gt;
&lt;p&gt;有了钱包（和资产）后，就可以开始交易了。我们来通过一个典型的比特币交易来理解这一流程：&lt;/p&gt;
&lt;p&gt;A和B都拥有一个比特币钱包地址（可以用Bitcoin Client生成，原理如上），假设A要给B转账5个BTC，A需要得到B的钱包地址，然后用自己的私钥对&lt;code&gt;A-&amp;gt;B转账5个BTC&lt;/code&gt;这笔交易签名（因为A的私钥仅有自己知道，所以拥有私钥则是拥有钱包资产的归属权）；然后发布这笔交易，在比特币系统中发起交易需要支付小额矿工费作为交易手续费；矿工会开始验证这笔交易的合法性，得到六个确认后交易就可以被比特币账本所接受，整个验证过程大约10分钟。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;矿工为什么要消耗大量算力来验证交易呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;矿工在验证过程中可以得到出块奖励和矿工费，出块奖励会四年递减，因此，后期主要激励是矿工费。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么验证要10分钟呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比特币其实并不是绝对安全的，新交易容易受到一些恶意攻击，而通过控制挖矿难度把验证过程控制在10分钟左右则可以很大程度上阻止恶意攻击，这只是一种概率上的保证。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;比特币系统中怎么避免双重花费呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比特币采用了一种叫&lt;code&gt;UTXO(Unspent Transaction Outputs)&lt;/code&gt;的概念，当一个用户收到一笔BTC交易时，会计入&lt;code&gt;UTXO&lt;/code&gt;中。&lt;/p&gt;
&lt;p&gt;在这个示例中，A想要给B转账5个BTC，A的这5个BTC可能来自于两个&lt;code&gt;UTXO&lt;/code&gt;(2 BTC + 3 BTC)，因此A在转账给B时，矿工需要检验的是这两笔&lt;code&gt;UTXO&lt;/code&gt;在这笔交易之前有没有被花掉，如果检测已经被花费了，则交易不合法。&lt;/p&gt;
&lt;p&gt;下图很好地阐释了多笔交易的流向和&lt;code&gt;UTXO&lt;/code&gt;的相关概念&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/btc_utxo_example.png&#34; alt=&#34;btc_utxo_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;此外，&lt;code&gt;UTXO&lt;/code&gt;有一个很重要的特性，不可分割，假如A有20个BTC，他想转账5个BTC给B，那交易会先将20个BTC作为输入，然后产生两个输出，一个向B转账5个BTC，一个返还给A剩下的15个BTC，因此，A又拥有了一笔价值为15BTC的&lt;code&gt;UTXO&lt;/code&gt;；如果单个&lt;code&gt;UTXO&lt;/code&gt;不够支付，则可以组合多个形成输入，但总额一定要大于交易额。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;矿工怎么验证交易发起者有足够的余额呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个问题看起来很简单，第一反应是像支付宝这样查询一下余额是否足够就可以。但比特币是一种基于交易的账本模式，并没有帐户概念，因此并不能直接查询余额，要想知道一个帐户的剩余资产，则需要回顾以前所有的交易，并且找到所有&lt;code&gt;UTXO&lt;/code&gt;并相加。&lt;/p&gt;
&lt;h3 id=&#34;交易模型&#34;&gt;交易模型&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;上文讲了一个交易是怎么发生的，那比特币交易由哪些部分组成呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_bitcoin_script_detail.png&#34; alt=&#34;blockchain_bitcoin_script_detail&#34;&gt;&lt;/p&gt;
&lt;p&gt;如图，最开始的部分是&lt;code&gt;Version&lt;/code&gt;，表示版本。&lt;/p&gt;
&lt;p&gt;然后是Input相关的信息：&lt;code&gt;Input Count&lt;/code&gt;表示数量，&lt;code&gt;Input Info&lt;/code&gt;表示输入的内容，也就是&lt;code&gt;Unlocking Script&lt;/code&gt;，主要用于核对输入来源、输入是否可用以及其他输入的细节。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Previous output hash&lt;/code&gt; - 所有输入都能追溯回一个输出，这指向包含将在该输入中花费的UTXO，该UTXO的哈希值在这里以相反的顺序保存&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Previous output index&lt;/code&gt; - 一个交易可以有多个由它们的索引号引用的&lt;code&gt;UTXO&lt;/code&gt;，第一个索引是0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unlocking Script Size&lt;/code&gt; - &lt;code&gt;Unlocking Script&lt;/code&gt;的字节大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Unlocking Script&lt;/code&gt; - 满足&lt;code&gt;UTXO Unlocking Script&lt;/code&gt;的哈希&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Sequence Number&lt;/code&gt; - 默认为&lt;code&gt;ffffffff&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接着是Output相关的信息，&lt;code&gt;Output Count&lt;/code&gt;表示数量，&lt;code&gt;Output Info&lt;/code&gt;表示输出的内容，也就是&lt;code&gt;Locking Script&lt;/code&gt;,主要用于记录输出了多少比特币，未来支出的条件以及输出的细节。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Amount&lt;/code&gt; - 以Satoshis(最小的比特币单位)表示的输出比特币数量，10^8 Satoshis = 1比特币&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Locking Script Size&lt;/code&gt; - 这是Locking Script的字节大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Locking Script&lt;/code&gt; - 这是Locking Script的哈希，它指定了使用此输出必须满足的条件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后是&lt;code&gt;Locktime&lt;/code&gt;，表示一个交易可以被最早添加到区块链的时间/块，如果小于500 million的话直接读取块高度，而如果大于500 million则读取时间戳。&lt;/p&gt;
&lt;h3 id=&#34;比特币脚本&#34;&gt;比特币脚本&lt;/h3&gt;
&lt;p&gt;在交易中有提到&lt;code&gt;Unlocking script&lt;/code&gt;和&lt;code&gt;Locking script&lt;/code&gt;，那什么是比特币脚本呢？&lt;/p&gt;
&lt;p&gt;比特币脚本是记录在每个交易中的指令列表，当脚本被执行时可以检验交易是否有效、比特币是否可以使用等。一个典型的脚本如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&amp;lt;sig&amp;gt; &amp;lt;pubKey&amp;gt; OP_DUP OP_HASH160 &amp;lt;pubKeyHash&amp;gt; OP_EQUALVERIFY OP_CHECKSIG
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;比特币脚本是基于栈从左至右执行的，使用&lt;code&gt;Opcodes&lt;/code&gt;对数据进行操作，在上面这个脚本语言中，&amp;lt;&amp;gt;包含的是要被推入stack的数据，没有&amp;lt;&amp;gt;包括、以OP_为前缀的是操作符（OP可省略），脚本也可以嵌入数据永久记录在链上（不超过40 bytes），所记录的数据不会影响&lt;code&gt;UTXO&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在交易中，&lt;code&gt;&amp;lt;sig&amp;gt; &amp;lt;pubKey&amp;gt;&lt;/code&gt;是&lt;code&gt;Unlocking script&lt;/code&gt;，&lt;code&gt;OP_DUP OP_HASH160 &amp;lt;pubKeyHash&amp;gt; OP_EQUALVERIFY OP_CHECKSIG&lt;/code&gt;部分是&lt;code&gt;Locking script&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;跟大多数编程语言相比，比特币脚本是非图灵完备的，没有循环或复杂的流程控制，执行起来很简单，不论在哪里执行结果都是确定性的，也不会保存状态，且脚本与脚本之间是相互独立的。因为以上特征，虽然比特币脚本相对安全，但没办法处理很复杂的逻辑，因此不适合用来处理一些复杂的业务，&lt;code&gt;Ethereum&lt;/code&gt;所提供的智能合约就在这一点上实现了创新性的突破，因此诞生了很多去中心化应用。&lt;/p&gt;
&lt;h3 id=&#34;挖矿&#34;&gt;挖矿&lt;/h3&gt;
&lt;p&gt;在上文对整个交易过程中提到了挖矿，接下来我们详细讲一下。&lt;/p&gt;
&lt;p&gt;有的节点为了得到出块奖励和矿工费，赚取收益，因此会对交易进行验证，称为矿工挖矿。出块奖励由&lt;code&gt;coinbase&lt;/code&gt;创建，每四年会递减，从2009年的25个，到现在已经减少为6.5个。&lt;/p&gt;
&lt;p&gt;挖矿其实是一个不断尝试随机数以达到某个设定目标值的过程，如小于某个target值，这个难度是人为设置来调整验证时间、提升安全性的，而不是解决数学难题。&lt;/p&gt;
&lt;p&gt;矿工们会不断尝试这个值，成功率很低，但是尝试次数可以很多，因此，算力强的节点有成比例的优势，更容易解出难题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那挖矿难度为什么要进行调整呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因为在比特币系统中，出块时间太短容易出现分叉，如果分叉过多则会影响系统达成共识，危害系统安全性。比特币系统通过难度调整把出块速度稳定在10分钟左右，从而防止交易被算改。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;挖矿难度是如何调整的呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;系统会在每产生2016个区块时（约两周）调整一次目标阈值，存在块头中，全网所有节点需要遵从新的难度进行挖矿，如果恶意节点不调整代码中的target的话，诚实的矿工则不会认可&lt;/p&gt;
&lt;p&gt;目标阈值 = 目标阈值 * (产生2016个区块的实际时间 / 产生2016个区块的预计时间)&lt;/p&gt;
&lt;p&gt;比特币诞生之初，矿工很少，挖矿难度也较低，大多都是用家用电脑（CPU）直接挖矿；随着越来越多的人参与到比特币生态中，挖矿的难度也越来越高，慢慢开始用一些算力较强的GPU进行挖矿，也有一些专用的&lt;code&gt;ASIC(Application Specific Integrated circuit)&lt;/code&gt;专用挖矿芯片以及矿机随着市场需求逐步诞生；而现在也出现了很多大型矿池，集合了全网大量算力进行集中挖矿。&lt;/p&gt;
&lt;p&gt;在这种大型矿池系统中，&lt;code&gt;Pool Manager&lt;/code&gt;担任了全节点的作用，而集合的大量矿工会一起计算哈希值，最后通过工作量证明机制来分配收益。但算力过于集中容易产生一些中心化风险，如某个大型矿池达到了全网51%以上算力的话就可以对交易进行回滚或者对某些交易进行抵制等。&lt;/p&gt;
&lt;h3 id=&#34;分叉&#34;&gt;分叉&lt;/h3&gt;
&lt;p&gt;比特币系统中，也会有未达成一致性意见的情况发生，称为分叉。分叉是主要分为两种类型，一种是状态分叉，往往是一些节点故意进行的；另一种称为协议分叉，也就是说对比特币协议产生了一些分歧。&lt;/p&gt;
&lt;p&gt;协议分叉又可以分为两种类型，一种叫硬分叉，也就是对于协议的部分内容产生了不可兼容的修改，比如将比特币的块大小由1M调整为4M，这种分叉方式是永久的，从某个节点开始形成了两条平行发展的链，比如&lt;code&gt;Bitcoin Classic&lt;/code&gt;，形成了两种币。&lt;/p&gt;
&lt;p&gt;另一种则叫软分叉，比如还是调整比特币的块大小，但是从1M调整为0.5M，这样调整后，就会出现新节点挖小区块，旧的节点挖大的区块的情况，软分叉是非永久性的，比较典型的例子是对coinbase的内容进行修改以及&lt;code&gt;P2SH(Pay to Script Hash)&lt;/code&gt;产生的分叉。&lt;/p&gt;
&lt;h2 id=&#34;bitcoin-core客户端&#34;&gt;Bitcoin Core客户端&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Bitcoin Core&lt;/code&gt;是比特币的实现，又被称为&lt;code&gt;Bitcoin-QT&lt;/code&gt;或&lt;code&gt;Satoshi-client&lt;/code&gt;，可以通过这个客户端连接至比特币网络、验证区块链、发送与接收比特币等。有&lt;code&gt;Mainnet&lt;/code&gt;、&lt;code&gt;Testnet&lt;/code&gt;和&lt;code&gt;Regnet&lt;/code&gt;三个网络，可以进行切换。&lt;/p&gt;
&lt;p&gt;提供了一个&lt;code&gt;Debug Console&lt;/code&gt;来与比特币区块链直接进行交互，常见操作如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Blockchain&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getblockchaininfo: 返回有关区块链处理的各种状态信息&lt;/li&gt;
&lt;li&gt;getblockcount: 返回区块链中的块数&lt;/li&gt;
&lt;li&gt;verifychain: 验证区块链数据库&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Hash&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getblockhash: 返回所提供的区块哈希值&lt;/li&gt;
&lt;li&gt;getnetworkhashps: 基于指定数量的最近块，返回每秒网络哈希数&lt;/li&gt;
&lt;li&gt;getbestblockhash: 返回最佳块的哈希值&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Blocks&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getblock: 返回块信息的详细信息&lt;/li&gt;
&lt;li&gt;getblockheader: 返回有关区块头信息&lt;/li&gt;
&lt;li&gt;generate: 立即将指定数量的块挖矿到钱包中的一个地址&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Wallet&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getwalletinfo: 返回一个对象，该对象包含有关钱包状态的各种信息&lt;/li&gt;
&lt;li&gt;listwallets: 返回当前加载的钱包列表&lt;/li&gt;
&lt;li&gt;walletpassphrasechange: 更改钱包密码&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Mempool&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getmempoolinfo: 返回内存池活动状态的详细信息&lt;/li&gt;
&lt;li&gt;getrawmempool: 返回内存池中的所有交易详细信息&lt;/li&gt;
&lt;li&gt;getmempoolentry: 返回给定交易的内存池数据&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Transaction&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getchaintxstats: 计算关于链中交易总数和速率的统计数据&lt;/li&gt;
&lt;li&gt;getrawtransaction: 返回原始交易数据&lt;/li&gt;
&lt;li&gt;listtransactions: 返回给定帐户的交易列表&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Signature&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;signrawtransaction: 签署原始交易的输入&lt;/li&gt;
&lt;li&gt;signmessage: 使用地址的私钥对信息进行签名&lt;/li&gt;
&lt;li&gt;dumpprivkey: 获取私钥&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Network&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getnetworkinfo: 返回P2P网络的状态信息&lt;/li&gt;
&lt;li&gt;getpeerinfo: 返回每个连接网络节点的数据&lt;/li&gt;
&lt;li&gt;getconnectioncount: 返回节点的连接数&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Mining&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;getmininginfo: 返回包含挖掘相关信息的对象&lt;/li&gt;
&lt;li&gt;getblocktemplate: 返回构造块所需的数据&lt;/li&gt;
&lt;li&gt;prioritisetransaction: 以较高或较低的优先级接受交易进入挖掘的块&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对比特币核心技术的一些解读，主要从它的基础原理和数据模型层面进行了一些深入了解，通过对比特币的学习，能够很好地理解区块链的设计理念和运行机制，接下来将会对被称为区块链2.0的以太坊进行学习和分析，敬请期待！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://msccs.cs.hku.hk/public/courses/2020/COMP7408A/&#34;&gt;COMP7408 Distributed Ledger and Blockchain Technology&lt;/a&gt;, &lt;em&gt;Professor S.M. Yiu, HKU&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/blockchain-developer-nanodegree--nd1309&#34;&gt;Udacity Blockchain Developer Nanodegree&lt;/a&gt;, &lt;em&gt;Udacity&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Vt411X7JF&#34;&gt;区块链技术与应用&lt;/a&gt;，&lt;em&gt;肖臻，北京大学&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ituring.com.cn/book/2434&#34;&gt;区块链技术进阶与实战&lt;/a&gt;，&lt;em&gt;蔡亮 李启雷 梁秀波，浙江大学 | 趣链科技&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>区块链基础知识与关键技术</title>
      <link>https://www.pseudoyu.com/zh/2021/02/12/blockchain_basic/</link>
      <pubDate>Fri, 12 Feb 2021 12:12:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/12/blockchain_basic/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;最近对在上HKU的&lt;code&gt;&amp;lt;COMP7408 Distributed Ledger and Blockchain Technology&amp;gt;&lt;/code&gt;课程，对区块链的基础概念有了更系统的认知，结合之前上过的北京大学肖臻老师《&lt;a href=&#34;https://www.bilibili.com/video/BV1Vt411X7JF&#34;&gt;区块链技术与应用&lt;/a&gt;》公开课，深知区块链知识体系之庞大，打算更新系列文章对区块链、比特币、以太坊等进行系统的知识梳理，如有错漏，欢迎交流指正。&lt;/p&gt;
&lt;h2 id=&#34;区块链中的密码学原理&#34;&gt;区块链中的密码学原理&lt;/h2&gt;
&lt;p&gt;区块链和密码学紧密相关，如比特币采用的核心的公私钥加密技术、数字签名、哈希等，包括很多共识算法也是基于复杂的密码学概念，因此，在开始学习区块链之前，要先了解几个核心的密码学概念，从而能够更深入理解其在区块链体系中的应用。&lt;/p&gt;
&lt;h3 id=&#34;哈希函数&#34;&gt;哈希函数&lt;/h3&gt;
&lt;p&gt;哈希函数是把一个任意长度的源数据经过一系列算法变成一个固定长度输出值的方法，概念很简单，但其具备的几个特性使它被各个领域广泛应用。&lt;/p&gt;
&lt;p&gt;可以访问这个 &lt;a href=&#34;https://andersbrownworth.com/blockchain/hash&#34;&gt;Demo&lt;/a&gt; 体验一下哈希函数的工作原理（以&lt;code&gt;SHA256&lt;/code&gt;为例）！&lt;/p&gt;
&lt;p&gt;第一个特性是单向不可逆性。将一个输入x进行哈希运算得到值H(x)，这一过程很容易，但是如果给定一个值H(x)，几乎不可能逆推得到x的取值，这一特性很好地保护了源数据。&lt;/p&gt;
&lt;p&gt;第二个特性是抗碰撞性。给定一个值x和另一个值y，如果x不等于y，那H(x)几乎不可能等于H(y)，并非完全不可能，但是几率非常低，因此，一个数据的Hash值几乎是唯一的，这可以很好地用于身份验证等场景。&lt;/p&gt;
&lt;p&gt;第三个特性是哈希计算不可预测。很难根据现有条件推导出哈希值，但是很容易检验是否正确，这一机制主要应用于&lt;code&gt;PoW&lt;/code&gt;挖矿机制中。&lt;/p&gt;
&lt;h3 id=&#34;加密解密&#34;&gt;加密/解密&lt;/h3&gt;
&lt;p&gt;加密机制主要分为对称加密和非对称加密两类。&lt;/p&gt;
&lt;p&gt;对称加密机制是两方用同一个密钥来进行信息的加密和解密，很方便，效率也很高，但是密钥的分发存在很大的风险，如果通过网络等方式进行分发，很容易会出现密钥泄漏，从而导致信息泄漏。&lt;/p&gt;
&lt;p&gt;非对称加密机制主要指的是公私钥加密机制，每个人通过算法生成一对密钥，称为公钥和私钥，如果A想发送一个信息给B，可以用B的公钥对文件进行加密，将加密后的信息发给B，这个过程中，即使信息被截获或出现泄漏，也不会暴露源文件，所以可以用任何方式进行传播，当B收到加密文件后，用自己的私钥进行解密，从而获取文件内容。B的私钥没有经过任何渠道进行传播，仅自己知道，所以具备极高的安全性。&lt;/p&gt;
&lt;p&gt;在现实应用中，对很大的文件进行非对称加密效率较低，所以一般采用一种组合机制：假设A想发送一个大文件D给B，则先将文件D用一个密钥K进行对称加密，再用B的公钥对密钥K进行非对称加密。A将加密后的密钥K和文件D发送给B，期间即使被截获或泄漏，因为没有B的私钥，所以无法得到密钥K，也就无法访问文件D。B收到加密后的文件和密钥后，则先用自己的私钥解密得到密钥K，再用密钥K对文件D进行解密，从而获取文件内容。&lt;/p&gt;
&lt;h3 id=&#34;数字签名&#34;&gt;数字签名&lt;/h3&gt;
&lt;p&gt;数字签名是非对称加密机制的另一种用法，上文讲到每个人拥有一对生成的公钥和私钥，在加密/解密应用中，是用公钥进行加密，用私钥进行解密，而数字签名机制刚好相反，假设一个文件持有者用自己的私钥对文件进行加密，其他人可以用他的公钥进行解密，如果得到结果则可以证明文件的归属权。&lt;/p&gt;
&lt;p&gt;数字签名机制最典型的应用就是比特币区块链网络中，用私钥证明自己对比特币的归属权，对交易进行签名，其他人则可以用公钥来验证交易是否合法，整个过程无需暴露自己的私钥，保障了资产的安全。&lt;/p&gt;
&lt;h2 id=&#34;区块链基本概念&#34;&gt;区块链基本概念&lt;/h2&gt;
&lt;p&gt;随着历史的发展，人们的记账方式从单式记账，发展到复式记账、数字记账，最后到分布式记账，因为传统的中心化数字记账则往往依赖于某个或某些组织的可信度，存在一些信任风险，而区块链技术本质上就是一种分布式账本技术，一群人共同维护着一个去中心化的数据库，通过共识机制来共同记账。区块链很容易追溯历史记录，而因为去中心化信任机制的存在，也几乎不可篡改（或者是篡改的成本远远大于收益）。&lt;/p&gt;
&lt;p&gt;相比于传统的数据库，区块链只有增加和查询两种操作，所有的操作历史记录都会准确地保存在账本中且不可变，具备很高的透明度和安全性，当然，代价就是所有节点必须通过一些机制达成共识（因此效率较低，不适合实时性的操作），而且因为每个节点都要永久保存历史记录，会占据很大的存储空间。&lt;/p&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;那怎么判断一个公司/业务是否适合采用区块链作为解决方案呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;是否需要数据库？&lt;/li&gt;
&lt;li&gt;是否需要共享写入&lt;/li&gt;
&lt;li&gt;是否需要多方达成信任？&lt;/li&gt;
&lt;li&gt;是否能够脱离第三方机构运作？&lt;/li&gt;
&lt;li&gt;是否能够脱离权限机制运作？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;区块链作为一个分布式数据库，主要做的还是信息存储的工作，只是通过其各类机制，在不需要第三方机构介入的前提下让有共同需求但并不互相信任的实体之间也能以相对较低的代价达成一致，从而满足需求，除此之外，系统还有加密认证、高透明度等特性，能够满足一些业务需求。而如果所涉及到的数据不能公开/数据量非常大/需要外部服务来存储数据，或者是业务规则经常发生变化，那区块链就并不适合作为其解决方案。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;因此，在以上的标准下，有如下一些需求很适合区块链作为其解决方案：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;需要建立一个共享的数据库，且有多方参与&lt;/li&gt;
&lt;li&gt;参与业务的各方没有建立信任&lt;/li&gt;
&lt;li&gt;现有业务信任一个或者多个信任机构&lt;/li&gt;
&lt;li&gt;现有业务有加密认证的业务需求&lt;/li&gt;
&lt;li&gt;数据需要集成到不同的数据库且业务数字化和一致性的需求迫切&lt;/li&gt;
&lt;li&gt;对于系统参与者有统一的规则&lt;/li&gt;
&lt;li&gt;多方决策是透明的&lt;/li&gt;
&lt;li&gt;需要客观的、不可改变的记录&lt;/li&gt;
&lt;li&gt;非实时性处理业务&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;但其实在很多应用场景里，企业需要在去中心化和效率之间做一些权衡，且有时候很多复杂的业务对透明度、规则都有不同的需求，因此，基于复杂的商业化需求，也有“联盟链”这样的解决方案，能够更好地与现有的系统结合，以满足业务需求。&lt;/p&gt;
&lt;h2 id=&#34;区块链类型&#34;&gt;区块链类型&lt;/h2&gt;
&lt;p&gt;区块链也有不同的类型，主要有私有链、公有链、联盟链三种。&lt;/p&gt;
&lt;p&gt;私有链主要是应用于某一个特定领域或者只是在某一个企业运行的区块链，主要是用于解决信任问题，如跨部门协作等场景，一般不需要外部机构来访问数据。&lt;/p&gt;
&lt;p&gt;公有链则是公开的交易，往往用于一些需要交易/数据公开的业务，如认证、溯源、金融等场景，比如比特币、以太坊和&lt;code&gt;EOS&lt;/code&gt;等。&lt;/p&gt;
&lt;p&gt;联盟链最大的特征是节点需要验证权限才能参与到区块链网络中，而认证一般都是与其现实角色所关联的，因此，联盟链也具有中心化的属性，但效率、拓展性和交易隐私则大大提升了，满足了企业级应用的需求，其中最广泛使用的就是&lt;code&gt;Hyperledger Fabric&lt;/code&gt;了。值得一提的是，联盟链往往不需要代币来作为激励，而是将参与的各个节点作为记账节点，通过区块链机制实现跨部门之间的业务协同所带来的经济效益作为内部激励，是一种更健康、更符合企业应用的方式。&lt;/p&gt;
&lt;p&gt;长期来看的话，公有链和联盟链在技术上也会逐渐趋于融合，即使是同一个业务，可以将需要信任的数据放在共有链上，而一些行业数据和私有的数据则可以放在联盟链上，通过权限管理来保障交易隐私。&lt;/p&gt;
&lt;h2 id=&#34;区块链基本框架&#34;&gt;区块链基本框架&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;那一个区块链究竟由哪些部分组成呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;区块&lt;/li&gt;
&lt;li&gt;区块链&lt;/li&gt;
&lt;li&gt;P2P网络&lt;/li&gt;
&lt;li&gt;共识机制&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;区块&#34;&gt;区块&lt;/h3&gt;
&lt;p&gt;区块链就是由一个个区块组成的生态系统，每一个区块中包含了前一个区块链的哈希值、时间戳、&lt;code&gt;Merkle Root&lt;/code&gt;、&lt;code&gt;Nonce&lt;/code&gt;以及区块数据几个部分，比特币的区块大小为1MB。可以访问这个 &lt;a href=&#34;https://andersbrownworth.com/blockchain/block&#34;&gt;Demo&lt;/a&gt; 来体验一下一个区块的生成过程。&lt;/p&gt;
&lt;p&gt;因为每个区块都包含前一个区块的哈希值，根据前文所述的哈希性质，哪怕是极其微小的改变哈希值也会截然不同，因此很容易检测某个区块是否被篡改；Nonce值则主要是用于调整挖矿难度，可以把时间控制在10分钟左右，以保障安全性。&lt;/p&gt;
&lt;h3 id=&#34;区块链&#34;&gt;区块链&lt;/h3&gt;
&lt;p&gt;所有的区块串联起来就形成了区块链，是一个存储着网络中所有交易历史记录的账本，因为每一个区块都包含着上一个区块的哈希信息（比如比特币系统是将上一个区块的块头取两次哈希），因此如果有交易发生变化则会造成区块链断裂，有一个小 &lt;a href=&#34;https://andersbrownworth.com/blockchain/blockchain&#34;&gt;Demo&lt;/a&gt; 很好地演示了这一过程，大家可以体验一下！&lt;/p&gt;
&lt;h3 id=&#34;p2p网络&#34;&gt;P2P网络&lt;/h3&gt;
&lt;p&gt;P2P网络是用于不同用户之间共享信息和资源的一种分布式网络，是一种分布式网络，网络中的每个人都能够得到一份信息备份，而且都有访问权限；而中心化网络是所有人都连接至一个（或一组）中心化网络；去中心化网络是有多个这样的中心网络，但没有一个单点网络可以拥有所有的信息。下图很好地解释了它们之间的区别：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/blockchain_network.png&#34; alt=&#34;blockchain_network&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;共识机制&#34;&gt;共识机制&lt;/h3&gt;
&lt;p&gt;区块链网络是由多个网络节点组成的，其中每个节点都存有一份信息备份，那它们是如何对交易达成一致的呢？也就是说，它们作为独立的节点，需要有一种机制来保障互相信任，这就是共识机制。&lt;/p&gt;
&lt;p&gt;常用的共识机制有&lt;code&gt;PoW(Proof of Work)&lt;/code&gt;工作量证明，&lt;code&gt;PoS(Proof of Stake)&lt;/code&gt;权益证明，&lt;code&gt;DPoS(Delegated Proof of Stake&lt;/code&gt;委任权益证明，&lt;code&gt;DBFT(Delegated Byzantine Fault Tolerance)&lt;/code&gt;等。&lt;/p&gt;
&lt;p&gt;比特币/以太坊主要采用的是工作量证明机制，通过算力比拼来增加恶意节点的作恶成本。通过动态调整挖矿的难度来让一笔交易时间控制在10分钟左右（6个确认），但随着比特币挖矿越来越火热，消耗资源越来越多，对环境造成破坏；有些矿池拥有大量资源，也会造成一些中心化的风险。&lt;/p&gt;
&lt;p&gt;权益证明机制则是通过权益（一般是代币）持有者进行投票来达成共识。这种机制不需要像工作量证明一样进行大量的算力比拼，但是也有一些风险，称为&lt;code&gt;Nothing at Stake&lt;/code&gt;问题，很多权益持有者会在所有区块都投注并从中获利。为了解决这个问题，系统设置了一些规则，如对同时在多个链创建区块的用户/在错误链上创建区块的用户设置一些惩罚机制。目前以太坊正在向这种共识机制转变。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EOS&lt;/code&gt;则采用了委任权益证明，选出一些代表性的节点来进行投票，这种方式目的是优化社区投票的效率和结果，但带来了一些中心化的风险。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DBFT&lt;/code&gt;共识机制则是通过对节点分配不同的角色来达成共识，这样可以很大程度降低开销和避免分叉，但是也有核心角色作恶的风险。&lt;/p&gt;
&lt;h2 id=&#34;区块链安全与隐私&#34;&gt;区块链安全与隐私&lt;/h2&gt;
&lt;h3 id=&#34;安全&#34;&gt;安全&lt;/h3&gt;
&lt;p&gt;区块链作为一个较新的技术，也存在很多安全隐患，如对数字货币交易所的攻击、智能合约漏洞、对共识协议的攻击、对网络流量（互联网ISP）的攻击以及上传恶意数据等。比较著名的案例有Mt.Gox事件、以太坊DAO事件等，因此，对区块链的安全风险也是区块链的重要研究方向。&lt;/p&gt;
&lt;p&gt;可以从协议、加密方案、应用、程序开发和系统等角度进行风险分析，提高区块链应用的安全性。例如在以太坊区块链中，可以对&lt;code&gt;Solidity&lt;/code&gt;编程语言、&lt;code&gt;EVM&lt;/code&gt;和区块链本身进行一些分析。&lt;/p&gt;
&lt;p&gt;如智能合约中的一种叫低成本攻击的方式，就是通过识别以太坊网络中较低&lt;code&gt;Gas&lt;/code&gt;费用的操作，重复执行以破坏整个网络。&lt;/p&gt;
&lt;p&gt;对于安全问题，构建一个通用的代码检测器来检查恶意代码将会是一个更通用的解决方案。&lt;/p&gt;
&lt;h3 id=&#34;隐私&#34;&gt;隐私&lt;/h3&gt;
&lt;p&gt;在讲区块链概念的时候，提到了它很重要的一个特征，隐私性。也就是说，所有人都能看到链上的交易细节和历史记录，这一特性主要应用在食品、药物等供应链环节，但是对于一些金融场景，如个人账户余额、交易信息，则容易造成一些隐私风险。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那有哪些技术能够应用于这些存在高价值、敏感信息的隐私保护呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;硬件层面，可以采用可信的执行环境，采用一些安全硬件，如&lt;code&gt;Intel SGX&lt;/code&gt;，很大程度保障了隐私；网络可以采用多路径转发以避免从节点的ip地址推算出真实身份。&lt;/p&gt;
&lt;p&gt;在技术层面，混币技术可以把很多交易进行一些混合，这样不容易找出对应的交易发送方和接收方；盲签技术可以保障第三方机构不能将参与交易的双方联系起来；环签用于保障交易签名的匿名性；零知识证明则可以应用于一方（证明者）向另一方（验证者）证明一个陈述是正确的，而无需透露除该陈述是正确的以外的人和信息；同态加密可以保护原数据，给定E(x)和E(y)，可以很容易计算出某些关于x,y的加密函数值（同态运算）；基于属性的加密（&lt;code&gt;Attribute-based Encryption, ABE&lt;/code&gt;）则为各个节点添加一些属性/角色，实现权限控制，从而保护隐私。&lt;/p&gt;
&lt;p&gt;值得注意的是，即使一笔交易生成多个inputs和outputs，这些inputs和outputs的地址也可能被人关联；除此之外，地址账户和现实世界中的真实身份也可能产生关联。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;以上就是对区块链基础知识的一些梳理，主要从概念和原理层面进行了一些学习，后续还会更新对比特币、以太坊、&lt;code&gt;Hyperledger Fabric&lt;/code&gt;等典型应用的分析与思考，并对IPFS、跨链、NFT等热门技术进行一些探究，敬请期待！&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://msccs.cs.hku.hk/public/courses/2020/COMP7408A/&#34;&gt;COMP7408 Distributed Ledger and Blockchain Technology&lt;/a&gt;, &lt;em&gt;Professor S.M. Yiu, HKU&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/blockchain-developer-nanodegree--nd1309&#34;&gt;Udacity Blockchain Developer Nanodegree&lt;/a&gt;, &lt;em&gt;Udacity&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Vt411X7JF&#34;&gt;区块链技术与应用&lt;/a&gt;，&lt;em&gt;肖臻，北京大学&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ituring.com.cn/book/2434&#34;&gt;区块链技术进阶与实战&lt;/a&gt;，&lt;em&gt;蔡亮 李启雷 梁秀波，浙江大学 | 趣链科技&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>用OKR的方式梳理自己的学习计划</title>
      <link>https://www.pseudoyu.com/zh/2021/02/11/learning_plan_okr/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/11/learning_plan_okr/</guid>
      
        <description>&lt;h2 id=&#34;用一句话形容理想情况下自己想要达到的状态&#34;&gt;用一句话形容理想情况下，自己想要达到的状态&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;具体目标范围&lt;/strong&gt;：提升编程技术能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;时间周期&lt;/strong&gt;：2个月&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;描述&lt;/strong&gt;：我想要成为一名具备过硬的编程能力的开发者，并对技术有持续学习的开放心态 &lt;em&gt;&lt;strong&gt;— 目标O&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;寻找关键词拆解状态为目标&#34;&gt;寻找关键词，拆解状态为目标&lt;/h2&gt;
&lt;h3 id=&#34;我需要提升解决的部分&#34;&gt;我需要提升解决的部分&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;过硬的编程能力&lt;/li&gt;
&lt;li&gt;持续学习的开放心态&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;想要达到的程度&#34;&gt;想要达到的程度&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;能够通过技术创造价值&lt;/li&gt;
&lt;li&gt;对技术有热爱和追求&lt;/li&gt;
&lt;li&gt;B站Up主“是落拓呀”的持续学习状态&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;制定每一个关键词目标的指标&#34;&gt;制定每一个关键词/目标的指标&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;过硬的编程能力&lt;/strong&gt;：能够满足目前香港/内地区块链公司，如蚂蚁链、腾讯区块链、杭州趣链科技等目标公司的技术面试要求，并主导完成1-2个完整的项目，深入技术细节 &lt;strong&gt;— KR1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持续学习的开放心态&lt;/strong&gt;：提升对于热门区块链技术平台（Ethereum、Hyperledger）与Java后端技术的理解与学习，并完成多篇原创技术博客 &lt;strong&gt;— KR2&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;填充每一个关键指标的todo-list&#34;&gt;填充每一个关键指标的todo list&lt;/h2&gt;
&lt;h3 id=&#34;过硬的编程能力&#34;&gt;过硬的编程能力&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;每天按照分类与难度刷LeetCode算法题
&lt;ol&gt;
&lt;li&gt;白天刷5-10题&lt;/li&gt;
&lt;li&gt;晚上按照节奏复习之前刷过的题的思路&lt;/li&gt;
&lt;li&gt;看关于算法框架思路的书籍，完善&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;完成区块链音乐版权项目毕业设计
&lt;ol&gt;
&lt;li&gt;每天至少2小时学习Ethereum智能合约编写相关&lt;/li&gt;
&lt;li&gt;按照项目进度进行开发&lt;/li&gt;
&lt;li&gt;与导师和同学定期交流，优化项目&lt;/li&gt;
&lt;li&gt;调研市场上区块链产品，思考运营与商业化相关&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;完成开源项目RPC框架的学习
&lt;ol&gt;
&lt;li&gt;每天至少1小时学习课程并实践代码&lt;/li&gt;
&lt;li&gt;撰写关于RPC框架原理和核心知识点的技术博文&lt;/li&gt;
&lt;li&gt;将此作为亮点项目，添加至简历并与同学进行模拟面试&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;针对GitHub与一些书籍的面试经验，学习掌握计算机基础面试知识，和同学每周模拟面试，现场写算法题并讲解，找到问题并提出建议&lt;/li&gt;
&lt;li&gt;参加春招面试，积攒面试经验查漏补缺，总结心得&lt;/li&gt;
&lt;li&gt;和落拓学长交流区块链学习心得和路径，寻求建议&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;持续学习的开放心态&#34;&gt;持续学习的开放心态&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;完成学校COMP7408区块链与分布式账本课程（共计30学时，每周一节3小时的课程）
&lt;ol&gt;
&lt;li&gt;每周一晚上参加线下课程&lt;/li&gt;
&lt;li&gt;课程第二天花3-6小时整理当周课程的知识点与拓展部分&lt;/li&gt;
&lt;li&gt;每周2-3小时将课程中的理论部分通过代码实践&lt;/li&gt;
&lt;li&gt;每天至少3天对之前所有知识点进行复习和查漏补缺（每次30分钟左右）&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Udacity 区块链开发课程并整理笔记（共计约40学时）
&lt;ol&gt;
&lt;li&gt;每天至少2小时学习课程并实践代码&lt;/li&gt;
&lt;li&gt;每天至少3天对之前所有知识点进行复习和查漏补缺（每次30分钟左右）&lt;/li&gt;
&lt;li&gt;阶段性对课程里的项目进行详细整理，添加至简历并针对面试进行准备&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;每天学习间隙整理基础理论知识，并了解一些前沿技术和产品&lt;/li&gt;
&lt;li&gt;完成CSDN关于Spring Boot和其他框架的入门视频并整理&lt;/li&gt;
&lt;li&gt;完成Udacity关于Java开发相关框架的介绍并进行项目实践&lt;/li&gt;
&lt;li&gt;结合自己的理解与学习笔记，撰写针对特定技术的原创博客&lt;/li&gt;
&lt;li&gt;定期和目前从事区块链的同学进行交流讨论，补充项目经验至简历与面试准备&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 2 Spatial Data Management</title>
      <link>https://www.pseudoyu.com/zh/2021/02/06/comp7801_topic2/</link>
      <pubDate>Sat, 06 Feb 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/02/06/comp7801_topic2/</guid>
      
        <description>&lt;h2 id=&#34;spatial-data-management&#34;&gt;Spatial Data Management&lt;/h2&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Spatial Data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Location data
&lt;ul&gt;
&lt;li&gt;Check-in service&lt;/li&gt;
&lt;li&gt;Online Maps&lt;/li&gt;
&lt;li&gt;Location-based services&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Location tracking&lt;/li&gt;
&lt;li&gt;Traffic Data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spatial Databases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PostgreSQL with PostGIS&lt;/li&gt;
&lt;li&gt;Neo4J-spatial&lt;/li&gt;
&lt;li&gt;HadoopGIS&lt;/li&gt;
&lt;li&gt;Ingres&lt;/li&gt;
&lt;li&gt;GeoMesa&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Spatial Data Management&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spatial Database Systems
&lt;ul&gt;
&lt;li&gt;Manage large collections of multidimensional objects (2D/3D)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A spatial object
&lt;ul&gt;
&lt;li&gt;Contains (at least) one spatial attributes that describes its location and/or geometry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A spatial relation
&lt;ul&gt;
&lt;li&gt;Is an organized collection of spatial objects of the same entity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-data&#34;&gt;Spatial Data&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Representation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Points (Cities in large-scale map)&lt;/li&gt;
&lt;li&gt;Extent (rivers, forest, etc.)
&lt;ul&gt;
&lt;li&gt;Vector (approximation by geometric objects)&lt;/li&gt;
&lt;li&gt;Raster (A set of pixels in the grid)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Application&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spatial data
&lt;ul&gt;
&lt;li&gt;GIS&lt;/li&gt;
&lt;li&gt;Segemented images&lt;/li&gt;
&lt;li&gt;Components of CAD constructs or VLSI circuit&lt;/li&gt;
&lt;li&gt;Stars on the sky&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spatial database
&lt;ul&gt;
&lt;li&gt;Users of mobile devices&lt;/li&gt;
&lt;li&gt;Geographers, life scientists&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;features-of-spatial&#34;&gt;Features of spatial&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Dimensionality
&lt;ul&gt;
&lt;li&gt;There is no total ordering of objects in the multidimensional space that preserves spatial proximity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Complex spatial extent&lt;/li&gt;
&lt;li&gt;No standard definitions of spatial operations and algebra&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Relationa indexes (like B+ trees) and query processing methods (sort-merge join, hash-join) are not applicable&lt;/p&gt;
&lt;p&gt;Spatial access methods (SAMs) for spatial data have to be defined&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Index spatial objects&lt;/li&gt;
&lt;li&gt;Facilitate efficient processing of simple spatial query types (e.g. range queries)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-relationships&#34;&gt;Spatial Relationships&lt;/h3&gt;
&lt;p&gt;A spatial relationship associates two objects according to their relative location and extent in space. Sometimes also called &amp;ldquo;spatial relations&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Can refer to a database relation which stores spatial objects.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Topological relationships&lt;/li&gt;
&lt;li&gt;Distance relationships&lt;/li&gt;
&lt;li&gt;Directional relationships&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;topological-relationships&#34;&gt;Topological relationships&lt;/h4&gt;
&lt;p&gt;Each object is characterized by the space it occupies in the universe (A set of pixels).&lt;/p&gt;
&lt;p&gt;A set of relationsips between their boundaries and interiors&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boundary&lt;/li&gt;
&lt;li&gt;Interior (some may not have, points, line segments, etc.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;A hierarchy of relations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intersect (or overlaps)
&lt;ul&gt;
&lt;li&gt;equals&lt;/li&gt;
&lt;li&gt;inside&lt;/li&gt;
&lt;li&gt;contains&lt;/li&gt;
&lt;li&gt;adjacent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;disjoint&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;distance-relationships&#34;&gt;Distance relationships&lt;/h4&gt;
&lt;p&gt;Associate two objects based on their geometric (Euclidean distance), and it&amp;rsquo;s usually abstracted into human mind.&lt;/p&gt;
&lt;p&gt;Distance relationships are expressed either explicitly or by some abstract distance class.&lt;/p&gt;
&lt;h4 id=&#34;directional-relationships&#34;&gt;Directional relationships&lt;/h4&gt;
&lt;p&gt;Associates two object based on their relative orientation according to a global reference system.&lt;/p&gt;
&lt;h3 id=&#34;spatial-queries&#34;&gt;Spatial Queries&lt;/h3&gt;
&lt;p&gt;Applied on one (or more) spatial relations to retrieve objects staisfying some spatial relationships&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nearest neighbor query&lt;/li&gt;
&lt;li&gt;Spatial join&lt;/li&gt;
&lt;li&gt;Range query
&lt;ul&gt;
&lt;li&gt;Spatial selction&lt;/li&gt;
&lt;li&gt;window query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-query-processing&#34;&gt;Spatial Query Processing&lt;/h3&gt;
&lt;p&gt;Evaluating spatial relationships on geometric data is slow.&lt;/p&gt;
&lt;p&gt;A spatial object is approximated by its minimum bounding rectangle (MBR)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Process&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Filter: The MBR is tested against the query predicate&lt;/li&gt;
&lt;li&gt;Refinement: The exact geometry of objects that pass the filter step is tested for qualification&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;spatial-access-methods-sams&#34;&gt;Spatial Access Methods (SAMs)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;The problem of indexing spatial data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No dynamic access method with good theoretical worst-case guarantees for range queries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SAMs aim at the minimization of the expected cost.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Indexing of multidimensional points&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;point-access-methods&#34;&gt;Point access methods&lt;/h4&gt;
&lt;p&gt;Divide the apce into disjoint partitions and group the points according to the regions they belong&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/point_access_methods.png&#34; alt=&#34;point_access_methods&#34;&gt;&lt;/p&gt;
&lt;p&gt;Not effective for extended objects (may need to be clipped into several parts which leads to data redundancy and affects performance negatively).&lt;/p&gt;
&lt;p&gt;Object clipping can be avoided if we allow the regions of object to overlap.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/object_clipping.png&#34; alt=&#34;object_clipping&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Optimization&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group the objects below into 3 groups of 4 objects each such that the MBRs of the groups have the minimum overlap&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/overlap_region.png&#34; alt=&#34;overlap_region&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hard optimization problem&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;the-r-tree&#34;&gt;The R-tree&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Concept&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group object MBRs to disk blocks hierarchically&lt;/li&gt;
&lt;li&gt;Each group of object is a leaf of the tree&lt;/li&gt;
&lt;li&gt;The MBRs of the leaf nodes are grouped to form nodes at the next level&lt;/li&gt;
&lt;li&gt;Grouping is recursively applied at each level until a single group (the root) is formed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_Tree_example.png&#34; alt=&#34;R_Tree_example&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Elements&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Leaf node entries: &amp;lt;MBR, object-id&amp;gt;, all leaves are in same level&lt;/li&gt;
&lt;li&gt;Non-leaf node entries: &amp;lt;MBR, ptr&amp;gt;, pointing to entries&lt;/li&gt;
&lt;li&gt;Root: have at least two children&lt;/li&gt;
&lt;li&gt;Non-root node parameters
&lt;ul&gt;
&lt;li&gt;M&lt;/li&gt;
&lt;li&gt;m&lt;/li&gt;
&lt;li&gt;m &amp;lt;= M/2&lt;/li&gt;
&lt;li&gt;Usually m = 0.4 M&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;range-searching-using-an-r-tree&#34;&gt;Range searching using an R-tree&lt;/h4&gt;
&lt;p&gt;Range_query (query W, R-tree node n)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If n is not a leaf node
&lt;ul&gt;
&lt;li&gt;For each index entry e in n such that e.MBR intersects W
&lt;ul&gt;
&lt;li&gt;Visit node n&#39; pointed  by e.ptr&lt;/li&gt;
&lt;li&gt;Range_query (W, n&#39;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If n is a leaf
&lt;ul&gt;
&lt;li&gt;For each index entry e in n such that e.MBR intersects W
&lt;ul&gt;
&lt;li&gt;Visit object o pointed by e.object-id&lt;/li&gt;
&lt;li&gt;Test range query against exact geometry of o; If o intersects W, report o&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;May follow multiple paths during search&lt;/li&gt;
&lt;li&gt;Different search predicates are used for different realtionships with W&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/range_search.png&#34; alt=&#34;range_search&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;construction-of-the-r-tree&#34;&gt;Construction of the R-tree&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Dynamically constructed/maintained&lt;/li&gt;
&lt;li&gt;Insertions/deletions interleave with search operations
&lt;ul&gt;
&lt;li&gt;Insertion similiar to B+ Tree, but with special optimization algorithms
&lt;ul&gt;
&lt;li&gt;Choose the path where a new MBR is inserted&lt;/li&gt;
&lt;li&gt;Split overflow nodes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Underflows in deletions
&lt;ul&gt;
&lt;li&gt;Deleting the underflow leaf node&lt;/li&gt;
&lt;li&gt;Re-insert the remaining entries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;r-tree&#34;&gt;R*-tree&lt;/h3&gt;
&lt;p&gt;Only different in the insertion algorithm (compared to R-tree), aiming at constructing a tree of high quality&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A good tree&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nodes with small MBRs&lt;/li&gt;
&lt;li&gt;nodes with small overlap&lt;/li&gt;
&lt;li&gt;nodes that look like squares&lt;/li&gt;
&lt;li&gt;nodes as full as possible&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;optimization&#34;&gt;Optimization&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Minimize the area covered by an index rectangle (small area means small dead space)&lt;/li&gt;
&lt;li&gt;Minimize overlap between node MBRs (Minimizes the number of traversed paths)&lt;/li&gt;
&lt;li&gt;Minimize the margins of node MBRs (Square-like nodes, smaller number of intersections for a random query, better structure)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/margin_minimization.png&#34; alt=&#34;margin_minimization&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimize the storage utilization
&lt;ul&gt;
&lt;li&gt;Nodes in tree should be filled as much as possible&lt;/li&gt;
&lt;li&gt;Minimizes tree height and potentially decreases dead space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Insertion heuristics (Select the path)
&lt;ul&gt;
&lt;li&gt;Least MBR enlargement after insertion
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/MBR_enlargement.png&#34; alt=&#34;MBR_enlargement&#34;&gt;&lt;/li&gt;
&lt;li&gt;Least MBR overlap after insertion
&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/MBR_overlap.png&#34; alt=&#34;MBR_overlap&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node-spliting&#34;&gt;Node Spliting&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Determine the split axis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For each axis (i.e. x and y axis)
&lt;ul&gt;
&lt;li&gt;Sum=0;&lt;/li&gt;
&lt;li&gt;sort entries by the lower value, then by upper value&lt;/li&gt;
&lt;li&gt;for each sorting (e.g. lower value)
&lt;ul&gt;
&lt;li&gt;for k=m to M+1-m&lt;/li&gt;
&lt;li&gt;place first k entries in group A, and the remaining ones in group B&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Sum = Sum + margin(A) + margin(B)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Choose axis with the minimum Sum&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Distribute entries along axis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Along the split axis, choose the distribution with minimum overlap&lt;/li&gt;
&lt;li&gt;If there are multiple groupings with minimal overlap choose &amp;lt;A,B&amp;gt; such that area(A)+area(B) is minimized&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;insertion-heuristics-forced-reinsert&#34;&gt;Insertion heuristics: Forced Reinsert&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/forced_reinsert.png&#34; alt=&#34;forced_reinsert&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forced Reinsert
&lt;ul&gt;
&lt;li&gt;When R*-tree node n overflows, instead of splitting n immediately, try to see if some entries in n could possibly fit better in another node&lt;/li&gt;
&lt;li&gt;Find the 30% furthest entries from the center of the group&lt;/li&gt;
&lt;li&gt;Re-insert them to the tree (not to be repeated if another overflow occurs)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Slightly more expensive, but better tree structure:
&lt;ul&gt;
&lt;li&gt;less overlap&lt;/li&gt;
&lt;li&gt;more space is utilized (more full nodes)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bulk-loading-r-trees&#34;&gt;Bulk-loading R-trees&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/bulk_loading_R_tree.png&#34; alt=&#34;bulk_loading_R_tree&#34;&gt;&lt;/p&gt;
&lt;p&gt;Given a static set S of rectangles, build an R-tree that indexes S.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Method 1: iteratively insert rectangles into an initially empty tree
&lt;ul&gt;
&lt;li&gt;Feature
&lt;ul&gt;
&lt;li&gt;tree reorganization is slow&lt;/li&gt;
&lt;li&gt;tree nodes are not as full as possible: more space occupied for the tree&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 2 (x-sorting): bulk-load the rectangles into the tree using some fast (sort or hash-based) process
&lt;ul&gt;
&lt;li&gt;sort rectangles using the x-coordinate of their center&lt;/li&gt;
&lt;li&gt;pack M consecutive rectangles in leaf nodes&lt;/li&gt;
&lt;li&gt;build tree bottom-up&lt;/li&gt;
&lt;li&gt;Feature
&lt;ul&gt;
&lt;li&gt;R-tree is built fast&lt;/li&gt;
&lt;li&gt;good space utilization&lt;/li&gt;
&lt;li&gt;results in leaf nodes that are have long stripes as MBRs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 3 (Hilbert sorting): use a space-filling curve to order the rectangles
&lt;ul&gt;
&lt;li&gt;much better structure, but still the nodes have large overlap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Method 4 (sort-tile-recursive): Sort using one axis first and then groups of sqrt(n) rectangles using the other axis
&lt;ul&gt;
&lt;li&gt;Usually the best structure compared to other bulk-loading methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;k-nearest-neighbor-search&#34;&gt;K Nearest Neighbor Search&lt;/h3&gt;
&lt;p&gt;Given a spatial relation R, a query object q, and a number k &amp;lt;|R|, find the k-nearest neighbors of q in R.&lt;/p&gt;
&lt;p&gt;We can have more than one k-NN sets (with multiple possible equidistant furthest points in them).&lt;/p&gt;
&lt;h4 id=&#34;distance-measures-and-mbrs&#34;&gt;Distance measures and MBRs&lt;/h4&gt;
&lt;p&gt;Distances between MBRs lower-bound the distances between the corresponding objects&lt;/p&gt;
&lt;p&gt;dist(MBR(oi),MBR(oj)) ≤ dist(oi, oj)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/distance_mbr.png&#34; alt=&#34;distance_mbr&#34;&gt;&lt;/p&gt;
&lt;p&gt;Distances between R-tree node MBRs lower-bound the distances between the entries in them&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/min_distance_mbr.png&#34; alt=&#34;min_distance_mbr&#34;&gt;&lt;/p&gt;
&lt;p&gt;The distance between a query object q and an R-tree node MBR lower-bounds the distances between q and the objects indexed under this node&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/q_distance_mbr.png&#34; alt=&#34;q_distance_mbr&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;depth-first-nn-search-using-an-r-tree&#34;&gt;Depth-first NN search using an R-tree&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Start from the root and visit the node nearest to q&lt;/li&gt;
&lt;li&gt;Continue recursively, until a leaf node nl is visited.&lt;/li&gt;
&lt;li&gt;Find the NN of q in nl.&lt;/li&gt;
&lt;li&gt;Continue visiting other nodes after backtracking as long there are nodes closer to q than the current NN.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/DFNNS_code.png&#34; alt=&#34;DFNNS_code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Large space can be pruned by avoiding visiting R-tree nodes and their sub-trees&lt;/li&gt;
&lt;li&gt;Should order the entries of a node in increasing distance from q to maximize potential for a good NN found fast&lt;/li&gt;
&lt;li&gt;Can be easily adapted for k-NN search&lt;/li&gt;
&lt;li&gt;Requires at most one tree path to be currently in memory – good for small memory buffers
&lt;ul&gt;
&lt;li&gt;Characteristic of all depth-first search algorithms&lt;/li&gt;
&lt;li&gt;Recall that the range search algorithm is also DF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;However, does not visit the least possible number of nodes&lt;/li&gt;
&lt;li&gt;Also, not incremental – more on this later…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/DFNNS_example.png&#34; alt=&#34;DFNNS_example&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. visit root
dist(q,M1)&amp;lt;dist(q,oNN)
must visit node M1

2. visit M1
dist(q,m1)&amp;lt;dist(q,oNN)
must visit node m1

3. visit m1
check a,b,c
found new NN:
oNN = a, dist(q,oNN) = sqrt(5)

4. backtrack to M1
check m2dist(q,m2) = 3 &amp;gt;= sqrt(5):
No need to visit node m2
check m3dist(q,m3) = sqrt(5) &amp;gt;= sqrt(5):
No need to visit node m3

5. backtrack to root
check M2dist(q,M2) = sqrt(2) &amp;lt; sqrt(5):
must visit node M2

6. visit M2
check m4dist(q,m4) = sqrt(2) &amp;lt; sqrt(5):
must visit node m4

7. visit m4
check i,j,k
found new NN:
oNN = k, dist(q,oNN) = sqrt(2)

8. backtrack to M2
check m5dist(q,m5) &amp;gt;= sqrt(2):
No need to visit node m5
check m6dist(q,m6) &amp;gt;= sqrt(2):
No need to visit node m6

9. backtrack to root
check M3dist(q,M3) &amp;gt;= sqrt(2):
No need to visit node M3

10. backtrack from root
Algorithm terminates
oNN =k with dist(q,oNN)= sqrt(2) found
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;best-first-nn-search&#34;&gt;Best-first NN search&lt;/h4&gt;
&lt;p&gt;Put all entries in a priority queue and always “open” the closest one, independently of the node that contains it.&lt;/p&gt;
&lt;p&gt;Thus the best (i.e., closest) entry is always visited first.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A more efficient algorithm (given large enough memory)&lt;/li&gt;
&lt;li&gt;Optimal in the number of R-tree nodes visited for a given query q&lt;/li&gt;
&lt;li&gt;Uses a priority queue to organize seen entries and prioritize the next node to be visited&lt;/li&gt;
&lt;li&gt;Adaptable for k-NN search and incremental NN search&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/BFNNS_code.png&#34; alt=&#34;BFNNS_code&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the previous example, we have visited fewer nodes compared to DF-NN algorithm
&lt;ul&gt;
&lt;li&gt;Only nodes whose MBR intersect the disk centered at q with radius the real NN distance are visited (see if you can you prove this)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The algorithm can be adapted for incremental NN search
&lt;ul&gt;
&lt;li&gt;After having found the NN can we easily (incrementally) find the next NN without starting search from the beginning?
&lt;ul&gt;
&lt;li&gt;put objects on the heap&lt;/li&gt;
&lt;li&gt;never prune, but wait until an object comes out&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The algorithm can be used for k-NN search
&lt;ul&gt;
&lt;li&gt;use a second heap to organize the NN found so far (same can be done for DF-NN)&lt;/li&gt;
&lt;li&gt;no need if we just use the inc. version of the algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;… but: The heap can grow very large until the algorithm terminates&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/BFNNS_example.png&#34; alt=&#34;BFNNS_example&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Step 1: put all entries of root on heap Q
Q = M1(1), M2(sqrt(2)), M3(sqrt(8))

Step 2: get closest entry (top element of Q):
M1(1). Visit node M1. Put all entries of 
visited node on heap Q
Q = M2(sqrt(2)), m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3)

Step 3: get closest entry (top element of Q):
M2(sqrt(2)). Visit node M2. Put all entries of 
visited node on heap Q
Q =m4(sqrt(2)), m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3), 	m5(sqrt(13)), m5(sqrt(17))

Step 4: get closest entry (top element of Q):
m4(sqrt(2)). Visit node m4. m4 is a leaf node, so update NN if some object in m4 is closer than the current NN:
oNN = k, dist(q,oNN)= sqrt(2)
Q =m1(sqrt(5)), M3(sqrt(5)), M3(sqrt(8)), m2(3), 	m5(sqrt(13)), m5(sqrt(17))

Step 5: get closest entry (top element of Q):
m1(sqrt(5)). Since sqrt(5) &amp;gt;= dist(q,oNN)= sqrt(2), search stops and oNN is returned as the NN of q
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;incremental NN search&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Example 1: find the nearest large city (&amp;gt;10,000 residents) to my current position
&lt;ul&gt;
&lt;li&gt;Solution 1:
&lt;ul&gt;
&lt;li&gt;find all large cities&lt;/li&gt;
&lt;li&gt;apply NN search on the result&lt;/li&gt;
&lt;li&gt;could be slow if many such cities&lt;/li&gt;
&lt;li&gt;also R-tree may not be available for large cities only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Solution 2:
&lt;ul&gt;
&lt;li&gt;incrementally find NN and check if the large city requirement is satisfied; if not get the next NN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Example 2: find the nearest hotel; see if you like it; if not get the next one; see if you like it; …&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;spatial-joins&#34;&gt;Spatial Joins&lt;/h3&gt;
&lt;p&gt;Most algorithms focus on the efficient processing of the filter step.&lt;/p&gt;
&lt;p&gt;Most spatial predicates on actual objects reduce to intersection of MBRs in the filter step. Thus all algorithms consider mainly the intersect predicate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Types&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intersection joins&lt;/li&gt;
&lt;li&gt;Semi-join: Find the cities that intersect a river&lt;/li&gt;
&lt;li&gt;Similarity join: Find pairs of hotels, restaurants close to each other (with distance smaller than 100m)&lt;/li&gt;
&lt;li&gt;Closest pairs: Find the closest pair of hotels, restaurants&lt;/li&gt;
&lt;li&gt;All-NN: For each hotel find the nearest restaurant&lt;/li&gt;
&lt;li&gt;Iceberg distance join: Find hotels close to at least 10 restaurants&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Three categories of spatial join algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Both inputs are indexed (e.g., synchronized tree traversal)&lt;/li&gt;
&lt;li&gt;One input is indexed (e.g., indexed nested loops)&lt;/li&gt;
&lt;li&gt;Neither input is indexed (e.g., spatial hash join)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;r-tree-intersection-join&#34;&gt;R-tree (Intersection) Join&lt;/h4&gt;
&lt;p&gt;Applies on two R-trees of spatial relations R and S&lt;/p&gt;
&lt;p&gt;Node MBRs at the high level of the trees can prune object combinations to be checked&lt;/p&gt;
&lt;p&gt;This pseudo-code version assumes that the trees have same height&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_code.png&#34; alt=&#34;R_tree_join_code&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;run for root(RA), root(RB)&lt;/li&gt;
&lt;li&gt;for every intersecting pair there (e.g., A1, B1) run recursively for pointed nodes&lt;/li&gt;
&lt;li&gt;intersecting pairs of leaf nodes are qualifying object MBR pairs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_example.png&#34; alt=&#34;R_tree_join_example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;optimization-1&#34;&gt;Optimization&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;space restriction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If an entry in n1 does not intersect the MBR of n2 it may not intersect any entry in n2.&lt;/li&gt;
&lt;li&gt;Perform two scans in n1 and n2 to prune such entries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_optimization.png&#34; alt=&#34;R_tree_join_optimization&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;plane sweep&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sort entries in both nodes on their lower-x value (lower bound of x-projection)&lt;/li&gt;
&lt;li&gt;Sweep a line to find fast all entry pairs that qualify x-intersection
&lt;ul&gt;
&lt;li&gt;for each of them check y-intersection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/R_tree_join_optimization2.png&#34; alt=&#34;R_tree_join_optimization2&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Worst-case sub-optimal. But very effective on the average&lt;/li&gt;
&lt;li&gt;Worst-case optimal algorithms require advanced data structures for y-intersection. Large hidden constants, thus high cost for this problem size&lt;/li&gt;
&lt;li&gt;Can be used with other spatial join algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;R-tree join&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The most efficient algorithm (assuming that the relations are indexed)&lt;/li&gt;
&lt;li&gt;Cannot be used for non-indexed inputs&lt;/li&gt;
&lt;li&gt;unless we build on-the-fly R-trees&lt;/li&gt;
&lt;li&gt;Comes with some I/O scheduling techniques for minimizing the page accesses&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;joining-non-indexed-inputs&#34;&gt;Joining non-indexed inputs&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Spatial hash join&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/spatial_hash_join.png&#34; alt=&#34;spatial_hash_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Partition based spatial merge join&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/spatial_merge_join.png&#34; alt=&#34;spatial_merge_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Indexed Nested Loops&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexed_nest_loops.png&#34; alt=&#34;indexed_nest_loops&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Seeded tree join and Bulk-load and Match build an on-the-fly R-tree&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/seeded_tree_join.png&#34; alt=&#34;seeded_tree_join&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Slot-index spatial join applies hash-join using the entries of a high R-tree level&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/slot_index_spatial_join.png&#34; alt=&#34;slot_index_spatial_join&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;the-refinement-step&#34;&gt;The refinement step&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_step.png&#34; alt=&#34;refinement_step&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: find MBR pairs that intersect&lt;/li&gt;
&lt;li&gt;Step 2: compare some more detailed approximations to make conclusions (a.k.a. geometric filter)
&lt;ul&gt;
&lt;li&gt;conservative approximations
&lt;ul&gt;
&lt;li&gt;e.g., convex hull&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;progressive approximation
&lt;ul&gt;
&lt;li&gt;e.g., maximum enclosed rectangle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_detailed_approximations.png&#34; alt=&#34;refinement_detailed_approximations&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 3: if still join predicate inconclusive, perform expensive refinement step
&lt;ul&gt;
&lt;li&gt;can be processed by computational geometry algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-step processing (R-tree join as example)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/refinement_multi_step.png&#34; alt=&#34;refinement_multi_step&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 1b Database Indexing</title>
      <link>https://www.pseudoyu.com/zh/2021/01/30/comp7801_topic1b/</link>
      <pubDate>Sat, 30 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/30/comp7801_topic1b/</guid>
      
        <description>&lt;h2 id=&#34;database-indexing&#34;&gt;Database Indexing&lt;/h2&gt;
&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Indexing mechanisms used to speed up access to desired data&lt;/li&gt;
&lt;li&gt;Search Key
&lt;ul&gt;
&lt;li&gt;An attribute or a set of attributes used to look up records in a file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;An index file consists of records (called index entries) of the form &lt;code&gt;search key - pointer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Index files are typically much smaller than the original file&lt;/li&gt;
&lt;li&gt;Two basic kinds of indices
&lt;ul&gt;
&lt;li&gt;Ordered indices:  search keys are stored in sorted order&lt;/li&gt;
&lt;li&gt;Hash indices:  search keys are distributed across &amp;ldquo;buckets&amp;rdquo; using a &amp;ldquo;hash function&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexing_example.png&#34; alt=&#34;indexing_example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;good-index&#34;&gt;Good Index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Index quality is evaluated by several factors
&lt;ul&gt;
&lt;li&gt;Access types supported by the index efficiently
&lt;ul&gt;
&lt;li&gt;records with a specified value in the attribute (equality query)&lt;/li&gt;
&lt;li&gt;or records with an attribute value falling in a specified range of values (range query)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Access time – query response time&lt;/li&gt;
&lt;li&gt;Insertion time – data record insertion time&lt;/li&gt;
&lt;li&gt;Deletion time – data record deletion time&lt;/li&gt;
&lt;li&gt;Space overhead – size of the index file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;classification-of-indexes&#34;&gt;Classification of Indexes&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Primary index
&lt;ul&gt;
&lt;li&gt;In a sequentially ordered file, the index whose search key specifies the sequential order of the file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary index
&lt;ul&gt;
&lt;li&gt;an index whose search key specifies an order different from the sequential order of the file&lt;/li&gt;
&lt;li&gt;Also called non-clustered index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/classification_of_indexing.png&#34; alt=&#34;classification_of_indexing&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dense index
&lt;ul&gt;
&lt;li&gt;Index record appears for every search-key value in the file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sparse Index
&lt;ul&gt;
&lt;li&gt;Contains index records for only some search-key values&lt;/li&gt;
&lt;li&gt;Applicable when records are sequentially ordered on search-key&lt;/li&gt;
&lt;li&gt;Less space and less maintenance overhead for insertions and deletions&lt;/li&gt;
&lt;li&gt;Generally slower than dense index for locating records&lt;/li&gt;
&lt;li&gt;Good tradeoff: sparse index with an index entry for every block in file, corresponding to least search-key value in the block&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/classification_of_indexing_2.png&#34; alt=&#34;classification_of_indexing_2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;primary-and-secondary-indices&#34;&gt;Primary and Secondary Indices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Secondary indices have to be dense&lt;/li&gt;
&lt;li&gt;Indices offer substantial benefits when searching for records
&lt;ul&gt;
&lt;li&gt;Index is much smaller than relation file (cheap scan)&lt;/li&gt;
&lt;li&gt;Index can be ordered (fast search)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;When a file is modified, every index on the file must be updated
&lt;ul&gt;
&lt;li&gt;Updating indices imposes overhead on database modification&lt;/li&gt;
&lt;li&gt;Indexes should be used with care&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential scan using primary index is efficient, but a sequential scan using a secondary index is expensive
&lt;ul&gt;
&lt;li&gt;Each record access may fetch a new block from disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multilevel-index&#34;&gt;Multilevel Index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If index does not fit in memory, access becomes expensive&lt;/li&gt;
&lt;li&gt;To reduce number of disk accesses to index records, treat 1st level of index kept on disk as a sequential file and construct a sparse index on it
&lt;ul&gt;
&lt;li&gt;outer index – a sparse index on 1st-level index file&lt;/li&gt;
&lt;li&gt;inner index – the 1st-level index file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If even outer index is too large to fit in main memory, yet another level of index can be created, and so on&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/multilevel_index_example.png&#34; alt=&#34;multilevel_index_example&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;b-tree-index-files&#34;&gt;B+-Tree Index Files&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A dynamic, multi-level index&lt;/li&gt;
&lt;li&gt;Advantage
&lt;ul&gt;
&lt;li&gt;automatically reorganizes itself with small local changes, in the face of insertions and deletions&lt;/li&gt;
&lt;li&gt;Reorganization of entire file is not required to maintain performance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disadvantage of B+-trees
&lt;ul&gt;
&lt;li&gt;Extra insertion and deletion overhead, space overhead&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Advantages of B+-trees outweigh disadvantages, and they are used extensively&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;basic-properties&#34;&gt;Basic Properties&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Disk-based tree structure
&lt;ul&gt;
&lt;li&gt;every node of the tree is a block and has an address (block-id) on the disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiway tree
&lt;ul&gt;
&lt;li&gt;each node has multiple children (between n/2 and n, where n/2 is the order or degree of the tree)&lt;/li&gt;
&lt;li&gt;Therefore, at least 50% of the space in a node is guaranteed to be occupied (this rule may not apply to tree root)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Balanced tree
&lt;ul&gt;
&lt;li&gt;all paths from the root to a leaf have the same length&lt;/li&gt;
&lt;li&gt;guarantees good search performance (to be seen later)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disjoint partition of attribute domain into ranges
&lt;ul&gt;
&lt;li&gt;each sub-tree indexes a range in the attribute domain&lt;/li&gt;
&lt;li&gt;the entries of a directory node define the separators between domain intervals&lt;/li&gt;
&lt;li&gt;leaf nodes store index entries and pointers to the relation file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Example.png&#34; alt=&#34;B_Plus_Tree_Example&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;non-leaf-nodes-in-b-trees&#34;&gt;Non-Leaf Nodes in B+-Trees&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Each non-leaf node contains up to n-1 search key values and up to n pointers&lt;/li&gt;
&lt;li&gt;All non-leaf nodes (except root) contain at least n/2 pointers (n/2 is sometimes called the minimum fan-out or degree)&lt;/li&gt;
&lt;li&gt;Non leaf nodes form a multi-level sparse index on the leaf nodes.  For a non-leaf node with m pointers
&lt;ul&gt;
&lt;li&gt;All the search-keys in the subtree to which P1 points are less than K1&lt;/li&gt;
&lt;li&gt;For 2 &amp;lt;= i &amp;lt;= n – 1, all the search-keys in the subtree to which Pi points have values greater than or equal to Ki–1 and smaller than Km–1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Non_Leaf_Node.png&#34; alt=&#34;B_Plus_Tree_Non_Leaf_Node&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;leaf-node-in-a-b-tree&#34;&gt;Leaf Node in a B+-Tree&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Contains between (n-1)/2 and n-1 entries&lt;/li&gt;
&lt;li&gt;Each index entry is a search key value + a record-id&lt;/li&gt;
&lt;li&gt;If Li, Lj are leaf nodes and i &amp;lt; j, Li’s search-key values are all smaller than Lj’s search-key values&lt;/li&gt;
&lt;li&gt;Each leaf node is linked with a pointer to the next node&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;observations&#34;&gt;Observations&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Since the inter-node connections are done by pointers, &amp;ldquo;logically&amp;rdquo; close blocks need not be “physically” close
&lt;ul&gt;
&lt;li&gt;Nodes of the tree are dynamically created/deleted, so we cannot guarantee physical closeness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The non-leaf levels of the B+-tree form a hierarchy of sparse indices&lt;/li&gt;
&lt;li&gt;The B+-tree contains a relatively small number of levels (logarithmic in the size of the main file), thus searches can be conducted efficiently&lt;/li&gt;
&lt;li&gt;Insertions and deletions to the main file can be handled efficiently (in logarithmic time)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;queries&#34;&gt;Queries&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Find all records with a search-key value of k&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start with the root node
&lt;ul&gt;
&lt;li&gt;Examine the node for the smallest search-key value &amp;gt; k&lt;/li&gt;
&lt;li&gt;If such a value exists, assume it is Ki.  Then follow Pi to the child node. (E.g. P2 is for keys in  K1 &amp;lt;= Keys &amp;lt; K2 )&lt;/li&gt;
&lt;li&gt;Otherwise k &amp;gt;= Kn–1, where there are n pointers in the node.  Then follow Pn to the child node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the node reached by following the pointer above is not a leaf node, repeat the above procedure on the node, and follow the corresponding pointer&lt;/li&gt;
&lt;li&gt;Eventually reach a leaf node.  If for some i, key Ki = k  follow pointer Pi  to the desired record.  Else no record with search-key value k exists&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In processing a query, a path is traversed in the tree from the root to some leaf node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If there are K search-key values in the file, the path is not longer than log(n/2)(K). (The degree of a node is no less than n/2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A node has generally the same size of a disk block, typically 4 kilobytes, and n is typically around 100 (40 bytes per index entry)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With 1 million search key values and n/2 = 50, at most log50(1,000,000) = 4 nodes are accessed in a lookup&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Contrast this with a balanced binary tree with 1 million search key values — around 20 nodes are accessed in a lookup&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(log2(1,000,000) ~= 20)&lt;/li&gt;
&lt;li&gt;above difference is significant since every node access may need a disk I/O, costing around 10 milliseconds!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Similar result for a binary search of an ordered sequential file&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;range-queries&#34;&gt;Range Queries&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find all records with a search-key value between k and m (k&amp;lt;m)
&lt;ul&gt;
&lt;li&gt;Start with the root node
&lt;ul&gt;
&lt;li&gt;Examine the node for the smallest search-key value &amp;gt; k&lt;/li&gt;
&lt;li&gt;If such a value exists, assume it is Kj
&lt;ul&gt;
&lt;li&gt;Then follow Pi to the child node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Otherwise k &amp;gt;= Kn–1, where there are n pointers in the node
&lt;ul&gt;
&lt;li&gt;Then follow Pn to the child node.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If the node reached by following the pointer above is not a leaf node, repeat the above procedure on the node, and follow the corresponding pointer&lt;/li&gt;
&lt;li&gt;Eventually reach a leaf node.  If for some i, k &amp;lt;= Ki &amp;lt;= m follow pointer Pi  to the desired record. Continue with next entry Ki+1, while Ki+1 &amp;lt;= m. If at end of leaf node follow pointer to next node, until Ki &amp;gt;m or end of index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Range_Query.png&#34; alt=&#34;B_Plus_Tree_Range_Query&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;insertion&#34;&gt;Insertion&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the leaf node in which the search-key value to be inserted  would appear&lt;/li&gt;
&lt;li&gt;If the search-key value is already there in the leaf node, record is added to file and if necessary one more pointer is associated with the search key value&lt;/li&gt;
&lt;li&gt;If the search-key value is not there, then add the record to the main file. Then
&lt;ul&gt;
&lt;li&gt;If there is room in the leaf node, insert (key-value, pointer) pair in the leaf node&lt;/li&gt;
&lt;li&gt;Otherwise, split the node (along with the new (key-value, pointer) entry) as discussed in the next slides&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_Insertion.png&#34; alt=&#34;B_Plus_Tree_Insertion&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;splitting&#34;&gt;Splitting&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Splitting a node
&lt;ul&gt;
&lt;li&gt;take the (search-key value, pointer) pairs (including the one being inserted) in sorted order.  Place the first n/2 in the original node, and the rest in a new node&lt;/li&gt;
&lt;li&gt;let the new node be p, and let k be the least key value in p.  Insert (k,p) in the parent of the node being split. If the parent is full, split it and propagate the split further up&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The splitting of nodes proceeds upwards till a node that is not full is found.  In the worst case the root node may be split increasing the height of the tree by 1&lt;/li&gt;
&lt;li&gt;Non-leaf node splitting
&lt;ul&gt;
&lt;li&gt;Overflown node has n+1 pointers and n values&lt;/li&gt;
&lt;li&gt;Leave first n/2 key values and n/2+1 pointers to original node&lt;/li&gt;
&lt;li&gt;Move last n/2 key values and n/2+1 pointers to new node&lt;/li&gt;
&lt;li&gt;insert (middle key value, pointer to new node) to parent node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_splitting.png&#34; alt=&#34;B_Plus_Tree_splitting&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;deletion&#34;&gt;Deletion&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Find the record to be deleted, and remove it from the relation file&lt;/li&gt;
&lt;li&gt;Remove (search-key value, record-id) of deleted record from the leaf node of the B+-tree&lt;/li&gt;
&lt;li&gt;If the node has too few entries due to the removal, and the entries in the node and a sibling fit into a single node, then
&lt;ul&gt;
&lt;li&gt;Insert all the search-key values in the two nodes into a single node (the one on the left), and delete the other node. (Deletion triggers a merge)&lt;/li&gt;
&lt;li&gt;Delete the pair (Ki–1, Pi), where Pi is the pointer to the deleted node, from its parent, recursively using the above procedure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Otherwise, if the node has too few entries due to the removal, and the entries in the node and a sibling does not fit into a single node, then
&lt;ul&gt;
&lt;li&gt;Redistribute the pointers between the node and a sibling such that both have more than the minimum number of entries. (Deletion and rebalancing)&lt;/li&gt;
&lt;li&gt;Update the corresponding search-key value in the parent of the node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The node deletions may cascade upwards until a node which has n/2 or more pointers is found.  If the root node has only one pointer after deletion, it is deleted and the sole child becomes the root&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/B_Plus_Tree_deletion.png&#34; alt=&#34;B_Plus_Tree_deletion&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;static-hashing&#34;&gt;Static Hashing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A bucket is a unit of storage containing one or more records (a bucket is typically a disk block)&lt;/li&gt;
&lt;li&gt;In a hash file organization we obtain the bucket of a record directly from its search-key value using a hash function&lt;/li&gt;
&lt;li&gt;Hash function h is a function from the set of all search-key values K to the set of all bucket addresses B&lt;/li&gt;
&lt;li&gt;Hash function is used to locate records for access, insertion as well as deletion&lt;/li&gt;
&lt;li&gt;Records with different search-key values may be mapped to the same bucket; thus entire bucket has to be searched sequentially to locate a record. (Collision)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/indexing_hashing.png&#34; alt=&#34;indexing_hashing&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;hash-function&#34;&gt;Hash Function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Worst case has function maps all search-key values to the same bucket; this makes access time proportional to the number of search-key values in the file&lt;/li&gt;
&lt;li&gt;An ideal hash function is uniform, i.e., each bucket is assigned the same number of search-key values from the set of all possible values&lt;/li&gt;
&lt;li&gt;Ideal hash function is random, so each bucket will have the same number of records assigned to it irrespective of the actual distribution of search-key values in the file&lt;/li&gt;
&lt;li&gt;Typical hash functions perform computation on the internal binary representation of the search-key
&lt;ul&gt;
&lt;li&gt;For example, for a string search-key, the binary representations of all the characters in the string could be added and the sum modulo the number of buckets could be returned&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;handling-of-bucket-overflows&#34;&gt;Handling of Bucket Overflows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Bucket overflow can occur because of
&lt;ul&gt;
&lt;li&gt;Insufficient buckets&lt;/li&gt;
&lt;li&gt;Skew in distribution of records.  This can occur due to two reasons
&lt;ul&gt;
&lt;li&gt;multiple records have same search-key value&lt;/li&gt;
&lt;li&gt;chosen hash function produces non-uniform distribution of key values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Although the probability of bucket overflow can be reduced, it cannot be eliminated; it is handled by using overflow buckets&lt;/li&gt;
&lt;li&gt;Overflow chaining / closed hashing – the overflow buckets of a given bucket are chained together in a linked list&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hash-indices&#34;&gt;Hash Indices&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Hashing can be used not only for file organization, but also for index-structure creation&lt;/li&gt;
&lt;li&gt;A hash index organizes the search keys, with their associated record pointers, into a hash file structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/Hash_Index.png&#34; alt=&#34;Hash_Index&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;deficiencies-of-static-hashing&#34;&gt;Deficiencies of Static Hashing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;In static hashing, function h maps search-key values to a fixed set of B of bucket addresses
&lt;ul&gt;
&lt;li&gt;Databases grow with time.  If initial number of buckets is too small, performance will degrade due to too much overflows&lt;/li&gt;
&lt;li&gt;If file size at some point in the future is anticipated and number of buckets allocated accordingly, significant amount of space will be wasted initially&lt;/li&gt;
&lt;li&gt;If database shrinks, again space will be wasted&lt;/li&gt;
&lt;li&gt;One option is periodic re-organization of the file with a new hash function, but it is very expensive.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;These problems can be avoided by using techniques that allow the number of buckets to be modified dynamically (dynamic hashing)&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7103 Topic 1 Introduction</title>
      <link>https://www.pseudoyu.com/zh/2021/01/28/comp7103_topic1/</link>
      <pubDate>Thu, 28 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/28/comp7103_topic1/</guid>
      
        <description>&lt;h1 id=&#34;comp7103-data-mining&#34;&gt;COMP7103 Data Mining&lt;/h1&gt;
&lt;h2 id=&#34;topic-1-introduction&#34;&gt;Topic 1 Introduction&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Decision-Support System (DSS)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A decision-support system (DSS) is a system that assists decision makers to make important decisions for an organization or business&lt;/li&gt;
&lt;li&gt;KDD and data mining are important components in many DSS&amp;rsquo;s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data and Knowledge&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;A collecion of facts about certain group of objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pattern
&lt;ul&gt;
&lt;li&gt;Certain characteristics of data that are frequently observed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Knowledge
&lt;ul&gt;
&lt;li&gt;Some general rules about the objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Warehouse&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An integration of various departmental databases (organization-wide data)&lt;/li&gt;
&lt;li&gt;Avoids overloading local operational databases&lt;/li&gt;
&lt;li&gt;A convenient place where KDD and data mining applications are performed&lt;/li&gt;
&lt;li&gt;Provide data mining algorithms an easy access to the required data&lt;/li&gt;
&lt;li&gt;Wrappers
&lt;ul&gt;
&lt;li&gt;Extract&lt;/li&gt;
&lt;li&gt;Transform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can also be used to support other DSS tools, e.g. On-Line Analytical Processing (OLAP) - analyze large amount of data, Online Transaction Processing (OLTP)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Mining and KDD&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KDD (Knowledge Discovery in Databases)
&lt;ul&gt;
&lt;li&gt;A process of discovering useful knowledge from big collection of data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Mining
&lt;ul&gt;
&lt;li&gt;A step within the KDD process in which interesting patterns are found. Some of these patterns are then interpreted and transformed into useful knowledge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Data Mining is a step in the whole KDD process&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;KDD is a process of identifying patterns in data and deriving knowledge from them&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;valid&lt;/li&gt;
&lt;li&gt;novel&lt;/li&gt;
&lt;li&gt;potentially useful&lt;/li&gt;
&lt;li&gt;understandable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Mining&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/data_mining_system.png&#34; alt=&#34;data_mining_system&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Databases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bottom layer of the architecture&lt;/li&gt;
&lt;li&gt;Contains data sources (raw data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Traditional Database usually only provides the functions of storing and retrieving facts&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The knowledge resulting from data mining should carry certain degree of predictive ability or descriptive (explanatory) ability (or both)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Mining Engine&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Applies data mining algorithms on data&lt;/li&gt;
&lt;li&gt;Provides multiple functionality&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Evaluation Module&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow users to specify what is/isn&amp;rsquo;t interesting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Knowledge Base&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Capture domain specific knowledge&lt;/li&gt;
&lt;li&gt;Stores the rules generated by data mining&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Graphical User Interface&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Presents mined patterns and rules to users in an easy-to-visualize way&lt;/li&gt;
&lt;li&gt;Provides feedback mechanisms for the users to specify the criteria of interestingness&lt;/li&gt;
&lt;li&gt;Provides a query language or query interface for users to select and retrieve&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Challenges of Data Mining&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technical
&lt;ul&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Dimensionality&lt;/li&gt;
&lt;li&gt;Data stream&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data
&lt;ul&gt;
&lt;li&gt;Complex and heterogeneous data&lt;/li&gt;
&lt;li&gt;Data quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Privacy
&lt;ul&gt;
&lt;li&gt;Data ownership and distribution&lt;/li&gt;
&lt;li&gt;Privacy preservation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Results
&lt;ul&gt;
&lt;li&gt;Interpretation of patterns&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;The KDD Process&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/kdd_process.png&#34; alt=&#34;kdd_process&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Step 1: Goal Setting
&lt;ul&gt;
&lt;li&gt;Understand your application domain&lt;/li&gt;
&lt;li&gt;Obtain prior known knowledge&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 2: Data Collection
&lt;ul&gt;
&lt;li&gt;Characteristics&lt;/li&gt;
&lt;li&gt;Where to find&lt;/li&gt;
&lt;li&gt;How to store&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 3: Data Cleaning and Preprocessing
&lt;ul&gt;
&lt;li&gt;Missing data&lt;/li&gt;
&lt;li&gt;Incorrect data (noise)&lt;/li&gt;
&lt;li&gt;Outliers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 4: Data Reduction and Transformation (or Preparation)
&lt;ul&gt;
&lt;li&gt;Compact data into a form&lt;/li&gt;
&lt;li&gt;Improve data mining algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 5: Data Mining
&lt;ul&gt;
&lt;li&gt;Pick a data mining model&lt;/li&gt;
&lt;li&gt;Pick a data mining algorithm&lt;/li&gt;
&lt;li&gt;Apply the algorithm to the data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 6: Result Evaluation
&lt;ul&gt;
&lt;li&gt;Check the results and goals&lt;/li&gt;
&lt;li&gt;Refine and re-run (if not)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Step 7: Knowledge Consolidation
&lt;ul&gt;
&lt;li&gt;Document&lt;/li&gt;
&lt;li&gt;Report&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Iterative and Interactive&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some steps of the process need to be refined, and the whole process be repeated&lt;/li&gt;
&lt;li&gt;Certain amount of human involvement is needed to monitor and to fine tune the steps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Prediction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uses database records that describe information about past behavior to automatically generate a model (or rule) that can predict future behavior&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Derive patterns that summarize the underlying relationships in data and to describe the characteristics of data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;OLAP (On-Line Analytical Processing)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;View data in a multi-dimensional model (a data cube)&lt;/li&gt;
&lt;li&gt;Fast aggregation&lt;/li&gt;
&lt;li&gt;Summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Selection -&amp;gt; Group-by -&amp;gt; Summarization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Supervised learning&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Unseen records should be assigned a class (accuracy)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Approach
&lt;ul&gt;
&lt;li&gt;Given a training set&lt;/li&gt;
&lt;li&gt;Learn classifier&lt;/li&gt;
&lt;li&gt;Find a model&lt;/li&gt;
&lt;li&gt;Test the model using test set&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Direct Marketing
&lt;ul&gt;
&lt;li&gt;Reduce cost of mailing by targeting a set of consumers likely to buy a new cell-phone product&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Regression&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Preduct a value of numerical variable based on the values of other variables&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predicting sales amounts of new product based on advertising expenditure&lt;/li&gt;
&lt;li&gt;Predicting wind velocities as a function of temperature, humidity, air pressure, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Clustering&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of data objects with a set of attributes and similarity measure&lt;/li&gt;
&lt;li&gt;Find clusters (e.g. distance-based clustering)
&lt;ul&gt;
&lt;li&gt;Maximize the intra-cluster similarity&lt;/li&gt;
&lt;li&gt;Minimize the inter-cluster similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Objects in one cluster are more similiar to one another&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/illustrating_cluster.png&#34; alt=&#34;illustrating_cluster&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Document Clustering
&lt;ul&gt;
&lt;li&gt;To find groups of documents that are similar to each other based on the important terms they contain&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Association Rule Discovery&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a set of records each of which contains some items from a given collection&lt;/li&gt;
&lt;li&gt;Goal
&lt;ul&gt;
&lt;li&gt;Produce dependency rules which predict occurrence of an item based on occurrences of other items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Marketing and Sales Promotion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Sequence Analysis&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Given a sequence database contains sequences of events&lt;/li&gt;
&lt;li&gt;Find sequences
&lt;ul&gt;
&lt;li&gt;Interesting&lt;/li&gt;
&lt;li&gt;Frequently occurring&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Predict future behavior.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Example&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Renting movies&lt;/li&gt;
&lt;li&gt;Buying habits&lt;/li&gt;
&lt;li&gt;Web serving behavior&lt;/li&gt;
&lt;li&gt;Web log analysis&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>COMP7801 Topic 1a Relational Database</title>
      <link>https://www.pseudoyu.com/zh/2021/01/23/comp7801_topic1a/</link>
      <pubDate>Sat, 23 Jan 2021 01:18:17 +0800</pubDate>
      
      <guid>https://www.pseudoyu.com/zh/2021/01/23/comp7801_topic1a/</guid>
      
        <description>&lt;h2 id=&#34;relational-databases&#34;&gt;Relational Databases&lt;/h2&gt;
&lt;h3 id=&#34;structure-of-relational-databases&#34;&gt;Structure of Relational Databases&lt;/h3&gt;
&lt;h4 id=&#34;basic-structure&#34;&gt;Basic structure&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Given sets D1, D2, …. Dn&lt;/li&gt;
&lt;li&gt;A relation r is a subset of D1 x  D2  x … x Dn&lt;/li&gt;
&lt;li&gt;A relation is a set of n-tuples (a1, a2, …, an) where each ai  &lt;!-- raw HTML omitted --&gt; Di&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;customer-name = {Jones, Smith, Curry, Lindsay}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;customer-street = {Main, North, Park}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;customer-city = {Harrison, Rye, Pittsfield}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Then
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;r = {(Jones, Main, Harrison), (Smith, North, Rye), (Curry, North, Rye), (Lindsay, Park, Pittsfield)}&lt;/code&gt; is a relation over customer-name x customer-street x customer-city&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;attribute-types&#34;&gt;Attribute Types&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Each attribute of a relation has a name&lt;/li&gt;
&lt;li&gt;The set of allowed values for each attribute is called the domain of the attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;relation-schema&#34;&gt;Relation Schema&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A1, A2, …, An are attributes&lt;/li&gt;
&lt;li&gt;R = (A1, A2, …, An ) is a relation schema
&lt;ul&gt;
&lt;li&gt;E.g. &lt;code&gt;Account-schema = (account-number, branch-name, balance)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;r(R) is a relation on the relation schema R
&lt;ul&gt;
&lt;li&gt;E.g. &lt;code&gt;customer(Customer-schema)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;relation-instance&#34;&gt;Relation Instance&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The current values (relation instance) of a relation are specified by a table&lt;/li&gt;
&lt;li&gt;An element t of r is a tuple, represented by a row in a table&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/relation_instance.png&#34; alt=&#34;relation_instance&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;database&#34;&gt;Database&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A database consists of multiple relations which are inter-related&lt;/li&gt;
&lt;li&gt;Information about an enterprise is broken up into parts, with each relation storing one part of the information&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/database_overview.png&#34; alt=&#34;database_overview&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;query-language&#34;&gt;Query language&lt;/h4&gt;
&lt;p&gt;Language in which user requests information from the database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Categories
&lt;ul&gt;
&lt;li&gt;procedural&lt;/li&gt;
&lt;li&gt;non-procedural&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pure languages
&lt;ul&gt;
&lt;li&gt;Relational Algebra
&lt;ul&gt;
&lt;li&gt;The operators take one or more relations as inputs and give a new relation as a result&lt;/li&gt;
&lt;li&gt;Operations
&lt;ul&gt;
&lt;li&gt;select&lt;/li&gt;
&lt;li&gt;project&lt;/li&gt;
&lt;li&gt;union&lt;/li&gt;
&lt;li&gt;set-Intersection&lt;/li&gt;
&lt;li&gt;set difference&lt;/li&gt;
&lt;li&gt;cartesian product&lt;/li&gt;
&lt;li&gt;rename&lt;/li&gt;
&lt;li&gt;Natural Join&lt;/li&gt;
&lt;li&gt;Aggregate Functions
&lt;ul&gt;
&lt;li&gt;avg:  average value&lt;/li&gt;
&lt;li&gt;min:  minimum value&lt;/li&gt;
&lt;li&gt;max:  maximum value&lt;/li&gt;
&lt;li&gt;sum:  sum of values&lt;/li&gt;
&lt;li&gt;count:  number of values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Relational Calculus&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SQL is based on set and relational operations with certain modifications and enhancements&lt;/li&gt;
&lt;li&gt;A typical SQL query has the form
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select A1, A2, ..., Anfrom r1, r2, ..., rm where P&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The result of an SQL query is a multiset of tuples&lt;/li&gt;
&lt;li&gt;Clauses
&lt;ul&gt;
&lt;li&gt;select
&lt;ul&gt;
&lt;li&gt;To force the elimination of duplicates, insert the keyword &lt;code&gt;distinct&lt;/code&gt; after &lt;code&gt;select&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;where
&lt;ul&gt;
&lt;li&gt;The where clause specifies conditions that the result must satisfy
&lt;ul&gt;
&lt;li&gt;Comparison results can be combined using the logical connectives and, or, and not&lt;/li&gt;
&lt;li&gt;Comparisons can be applied to results of arithmetic expressions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;from
&lt;ul&gt;
&lt;li&gt;The from clause lists the relations involved in the query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aggregate Functions
&lt;ul&gt;
&lt;li&gt;Group By
&lt;ul&gt;
&lt;li&gt;Find the number of depositors for each branch
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;select branch-name,count (distinct customer-name)from depositor,account where depositor.account-number = account.account-numbergroup by branch-name&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Having
&lt;ul&gt;
&lt;li&gt;formation of groups whereas predicates in the where clause are applied before forming groups&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Query Evaluation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basic operations
&lt;ul&gt;
&lt;li&gt;Selections&lt;/li&gt;
&lt;li&gt;Joins&lt;/li&gt;
&lt;li&gt;Other operations (projection, aggregation)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Transformation of queries into a tree of operations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Query Optimizationh&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Many equivalent expressions to the original query can be derived&lt;/li&gt;
&lt;li&gt;The query optimizer uses statistical data and appropriate algorithms to compute an expression of low evaluation cost&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;storage-of-databases&#34;&gt;Storage of databases&lt;/h3&gt;
&lt;h4 id=&#34;physical-storage-media&#34;&gt;Physical Storage Media&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Cache
&lt;ul&gt;
&lt;li&gt;fastest and most costly form of storage&lt;/li&gt;
&lt;li&gt;volatile&lt;/li&gt;
&lt;li&gt;managed by the computer system hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Main memory
&lt;ul&gt;
&lt;li&gt;fast access&lt;/li&gt;
&lt;li&gt;generally too small (or too expensive) to store the entire database&lt;/li&gt;
&lt;li&gt;Volatile
&lt;ul&gt;
&lt;li&gt;contents of main memory are usually lost if a power failure or system crash occurs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Magnetic-disk
&lt;ul&gt;
&lt;li&gt;Data is stored on spinning disk, and read/written magnetically&lt;/li&gt;
&lt;li&gt;Primary medium for the long-term storage of data&lt;/li&gt;
&lt;li&gt;typically stores entire database&lt;/li&gt;
&lt;li&gt;Data must be moved from disk to main memory for access, and written back for storage
&lt;ul&gt;
&lt;li&gt;Much slower access than main memory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;direct-access –  possible to read data on disk in any order, unlike magnetic tape&lt;/li&gt;
&lt;li&gt;Capacities range up to several TB currently&lt;/li&gt;
&lt;li&gt;Survives power failures and system crashes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;storage-hierarchy&#34;&gt;Storage Hierarchy&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Primary storage
&lt;ul&gt;
&lt;li&gt;Fastest media but volatile (cache, main memory).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary storage&lt;/li&gt;
&lt;li&gt;Next level in hierarchy, non-volatile, moderately fast access time
&lt;ul&gt;
&lt;li&gt;Also called on-line storage, E.g. flash memory, magnetic disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tertiary storage: lowest level in hierarchy, non-volatile, slow access time
&lt;ul&gt;
&lt;li&gt;Also called off-line storage, E.g. magnetic tape, optical storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/memory_hierarchy.png&#34; alt=&#34;memory_hierarchy&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;magnetic-disks&#34;&gt;Magnetic Disks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Read-write head
&lt;ul&gt;
&lt;li&gt;Positioned very close to the platter surface (almost touching it)&lt;/li&gt;
&lt;li&gt;Reads or writes magnetically encoded information.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Surface of platter divided into circular tracks
&lt;ul&gt;
&lt;li&gt;Over 16,000 tracks per platter on typical hard disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each track is divided into sectors
&lt;ul&gt;
&lt;li&gt;A sector is the smallest unit of data that can be read or written&lt;/li&gt;
&lt;li&gt;Sector size typically 512 bytes&lt;/li&gt;
&lt;li&gt;Typical sectors per track: 200 (on inner tracks) to 400 (on outer tracks)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To read/write a sector
&lt;ul&gt;
&lt;li&gt;disk arm swings to position head on right track&lt;/li&gt;
&lt;li&gt;platter spins continually; data is read/written as sector passes under head&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Head-disk assemblies
&lt;ul&gt;
&lt;li&gt;multiple disk platters on a single spindle (typically 2 to 4)&lt;/li&gt;
&lt;li&gt;one head per platter, mounted on a common arm.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cylinder i consists of ith track of all the platters&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/magnetic_hard_disk.png&#34; alt=&#34;magnetic_hard_disk&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;performance-measures-of-disks&#34;&gt;Performance Measures of Disks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Access time – the time it takes from when a read or write request is issued to when data transfer begins
&lt;ul&gt;
&lt;li&gt;Seek time – time it takes to reposition the arm over the correct track
&lt;ul&gt;
&lt;li&gt;Average seek time is 1/2 the worst case seek time
&lt;ul&gt;
&lt;li&gt;Would be 1/3 if all tracks had the same number of sectors, and we ignore the time to start and stop arm movement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;4 to 10 milliseconds on typical disks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rotational latency – time it takes for the sector to be accessed to appear under the head
&lt;ul&gt;
&lt;li&gt;Average latency is 1/2 of the worst case latency&lt;/li&gt;
&lt;li&gt;4 to 11 milliseconds on typical disks (5400 to 15000 r.p.m.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data-transfer rate – the rate at which data can be retrieved from or stored to the disk
&lt;ul&gt;
&lt;li&gt;4 to 8 MB per second is typical&lt;/li&gt;
&lt;li&gt;Multiple disks may share a controller, so rate that controller can handle is also important&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;optimization-of-disk-block-access&#34;&gt;Optimization of Disk-Block Access&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Block – a contiguous sequence of sectors from a single track
&lt;ul&gt;
&lt;li&gt;data is transferred between disk and main memory in blocks&lt;/li&gt;
&lt;li&gt;sizes range from 512 bytes to several kilobytes
&lt;ul&gt;
&lt;li&gt;Smaller blocks: more transfers from disk&lt;/li&gt;
&lt;li&gt;Larger blocks:  more space wasted due to partially filled blocks&lt;/li&gt;
&lt;li&gt;Typical block sizes today range from 4 to 16 kilobytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Disk-arm-scheduling algorithms order pending accesses to tracks so that disk arm movement is minimized&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;storage-access&#34;&gt;Storage Access&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;A database file is partitioned into fixed-length storage units called blocks.  Blocks are units of both storage allocation and data transfer. Typical size of a block ranges between 4Kb-16Kb&lt;/li&gt;
&lt;li&gt;Database system seeks to minimize the number of block transfers between the disk and memory.  We can reduce the number of disk accesses by keeping as many blocks as possible in main memory&lt;/li&gt;
&lt;li&gt;Buffer
&lt;ul&gt;
&lt;li&gt;portion of main memory available to store copies of disk blocks.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Buffer manager
&lt;ul&gt;
&lt;li&gt;subsystem responsible for allocating buffer space in main memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/pseudoyu/image_hosting/master/hugo_images/storage_access.png&#34; alt=&#34;storage_access&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;buffer-manager&#34;&gt;Buffer manager&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Programs call on the buffer manager when they need a block from disk
&lt;ul&gt;
&lt;li&gt;If the block is already in the buffer, the requesting program is given the address of the block in main memory&lt;/li&gt;
&lt;li&gt;If the block is not in the buffer
&lt;ul&gt;
&lt;li&gt;the buffer manager allocates space in the buffer for the block, replacing (throwing out) some other block, if required, to make space for the new block&lt;/li&gt;
&lt;li&gt;The block that is thrown out is written back to disk only if it was modified since the most recent time that it was written to/fetched from the disk&lt;/li&gt;
&lt;li&gt;Once space is allocated in the buffer, the buffer manager reads the block from the disk to the buffer, and passes the address of the block in main memory to requester&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Buffer-Replacement Policies&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Most operating systems replace the block least recently used (LRU strategy)&lt;/li&gt;
&lt;li&gt;Idea behind LRU – use past pattern of block references as a predictor of future references. If a block has not been recently used, then it is unlikely that it will be used in the near future&lt;/li&gt;
&lt;li&gt;This replacement policy is also used at different applications. A proxy server keeps in the most recently used web pages in a local cache. If a user requests again a page he has seen, it does not need to be downloaded again in the future&lt;/li&gt;
&lt;li&gt;LRU works well for unpredicted access patterns&lt;/li&gt;
&lt;li&gt;However, queries have well-defined access patterns (such as sequential scans), and a database system can use the information in a user’s query to predict future references&lt;/li&gt;
&lt;li&gt;LRU can be a bad strategy for certain access patterns involving repeated scans of data. Mixed strategy with hints on replacement strategy provided by the query optimizer is preferable&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;file-organization&#34;&gt;File Organization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The database is stored as a collection of files. Each file is a sequence of records. A record is a sequence of fields&lt;/li&gt;
&lt;li&gt;Each record has an address in the file, which is called record pointer or record id (simply rid)&lt;/li&gt;
&lt;li&gt;A simple approach
&lt;ul&gt;
&lt;li&gt;assume record size is fixed&lt;/li&gt;
&lt;li&gt;each file has records of one particular type only&lt;/li&gt;
&lt;li&gt;different files are used for different relations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Organization of Records in Files&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Heap
&lt;ul&gt;
&lt;li&gt;a record can be placed anywhere in the file where there is space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential
&lt;ul&gt;
&lt;li&gt;store records in sequential order, based on the value of the search key of each record&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hashing
&lt;ul&gt;
&lt;li&gt;a hash function computed on some attribute of each record; the result specifies in which block of the file the record should be placed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Records of each relation may be stored in a separate file. In a  clustered file organization  records of several different relations can be stored in the same file
&lt;ul&gt;
&lt;li&gt;Motivation: store related records on the same block to minimize I/O&lt;/li&gt;
&lt;li&gt;However, not good for queries accessing only a few relations&lt;/li&gt;
&lt;li&gt;In general, this representation is barely used&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>
